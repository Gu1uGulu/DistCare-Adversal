{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:55:29.996921Z",
     "start_time": "2021-02-10T14:55:28.704721Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle5 as pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import logging\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:55:52.924543Z",
     "start_time": "2021-02-10T14:55:52.918220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "# Select the target dataset: PD dataset\n",
    "target_dataset = 'PD' # 'PD'\n",
    "\n",
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() == True else 'cpu')\n",
    "print(\"available device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:39:43,177 - INFO - 这是希望输出的info内容\n",
      "2023-11-08 11:39:43,181 - WARNING - 这是希望输出的warning内容\n"
     ]
    }
   ],
   "source": [
    "def get_logger(name):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # 以下两行是为了在jupyter notebook 中不重复输出日志\n",
    "    if logger.root.handlers:\n",
    "        logger.root.handlers[0].setLevel(logging.WARNING)\n",
    " \n",
    "    handler_stdout = logging.StreamHandler()\n",
    "    handler_stdout.setLevel(logging.INFO)\n",
    "    handler_stdout.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler_stdout)\n",
    " \n",
    "    handler_file = logging.FileHandler('log_file_lstm_pd.log', encoding='utf-8')\n",
    "    handler_file.setLevel(logging.DEBUG)\n",
    "    handler_file.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler_file)\n",
    " \n",
    "    return logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "logger.debug('这是希望输出的debug内容')\n",
    "logger.info('这是希望输出的info内容')\n",
    "logger.warning('这是希望输出的warning内容')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Source Data & Model: \n",
    "#### Teacher Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T14:55:32.579746Z",
     "start_time": "2021-02-10T14:55:32.571939Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = './data/Challenge/'\n",
    "small_part = False\n",
    "arg_timestep = 1.0\n",
    "batch_size = 256\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T04:27:29.073353Z",
     "start_time": "2021-01-30T04:27:12.159717Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:40:03,372 - INFO - [[-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.34587251014597875, -0.2371260510881844, 0.3051487380880145, 0.029264930048844468, -0.3160730875843661, -0.3766591890459441, -0.1935716453287135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.05532679134287014, -0.2815944741293343, -0.32211134163582006, -0.0899704549996704, -0.06645805008034258, -0.33684497792590695, -0.14828727498338712, -0.24435830491350327, -0.14487324959363315], [-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.34587251014597875, -0.2371260510881844, 0.3051487380880145, 0.029264930048844468, -0.3160730875843661, -0.3766591890459441, -0.1935716453287135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.05532679134287014, -0.2815944741293343, -0.32211134163582006, -0.0899704549996704, -0.06645805008034258, -0.33684497792590695, -0.14828727498338712, -0.24435830491350327, -0.14487324959363315], [-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.34587251014597875, -0.2371260510881844, 0.3051487380880145, 0.029264930048844468, -0.3160730875843661, -0.3766591890459441, -0.1935716453287135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.05532679134287014, -0.2815944741293343, -0.32211134163582006, -0.0899704549996704, -0.06645805008034258, -0.33684497792590695, -0.14828727498338712, -0.24435830491350327, -0.14487324959363315], [-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6013515009242577, 0.6149447909519286, -1.009369603802189, 1.38817852813712, 1.2605692444279462, 0.585371321489137, 0.6420908338073934, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, -0.4065324680479176, -1.009369603802189, 1.043819195154697, 0.9546043520029015, 0.2987563180527675, 0.6420908338073934, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.8899478598202222, -0.747024887714533, -1.009369603802189, 1.38817852813712, 1.0769903089729194, 0.4420638197709522, 0.8382388140070928, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [1.0631056751578007, -0.747024887714533, -1.009369603802189, 1.4742683613827257, 1.566534136852991, 1.803485086093707, 0.8382388140070928, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7745093162618364, 0.6149447909519286, -1.2691053032588202, 0.44119036243545645, 0.46506052412282983, -0.05951243624269434, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.3704744138074862, 0.2744523712853132, -1.2691053032588202, 0.6564149455494709, 0.281481588667803, -0.2744736888199714, 0.24979487340799464, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.8899478598202222, 0.9554372106185439, -1.2691053032588202, 0.09683102945303342, 0.8934113735178925, 0.9436400757845987, 1.4266827546061909, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.3127551420282933, -0.4065324680479176, -1.2691053032588202, 0.613370028926668, 0.46506052412282983, -0.05951243624269434, 0.24979487340799464, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.5053978624091442, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.4281936855866791, 0.6149447909519286, -0.48989820488893626, 0.613370028926668, 0.46506052412282983, -0.05951243624269434, 0.24979487340799464, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.5053978624091442, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.4281936855866791, 0.6149447909519286, -0.48989820488893626, 0.613370028926668, 0.46506052412282983, -0.05951243624269434, 0.24979487340799464, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.5053978624091442, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.3981454458126536, 0.46506052412282983, -0.05951243624269434, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.5053978624091442, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.3981454458126536, 0.46506052412282983, -0.05951243624269434, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, 0.6149447909519286, -0.48989820488893626, -0.07534863703817811, 0.22028861018279403, -0.2744736888199714, -0.5347970473908028, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, -1.4280097270477636, -0.48989820488893626, -0.07534863703817811, 0.22028861018279403, -0.2744736888199714, -0.5347970473908028, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, -1.4280097270477636, -0.48989820488893626, -0.07534863703817811, 0.22028861018279403, -0.2744736888199714, -0.5347970473908028, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, -1.4280097270477636, -0.48989820488893626, -0.07534863703817811, 0.22028861018279403, -0.2744736888199714, -0.5347970473908028, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7745093162618364, 0.2744523712853132, -0.3600303551606207, -0.37666305339779826, -0.26925521769727756, -0.5610886922563408, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7167900444826435, 0.2744523712853132, -0.3600303551606207, -0.37666305339779826, -0.26925521769727756, -0.5610886922563408, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7745093162618364, -0.0660400483813022, -0.3600303551606207, 1.1299090284003026, 1.0157973304879104, 0.585371321489137, 0.44594285360769403, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7745093162618364, -0.0660400483813022, -0.3600303551606207, 1.1299090284003026, 1.0157973304879104, 0.585371321489137, 0.44594285360769403, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.9577293619090911, 0.6486394595778567, 0.08379506547549039, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.9577293619090911, 0.6486394595778567, 0.08379506547549039, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.9577293619090911, 0.6486394595778567, 0.08379506547549039, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.9577293619090911, 0.6486394595778567, 0.08379506547549039, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.043819195154697, 1.627727115338, 1.373562580939153, 1.6228307348058901, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.043819195154697, 1.627727115338, 1.373562580939153, 1.6228307348058901, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.043819195154697, 1.627727115338, 1.373562580939153, 1.6228307348058901, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.043819195154697, 1.627727115338, 1.373562580939153, 1.6228307348058901, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.7855496954178796, 0.8934113735178925, 0.2271025671936751, 1.2305347744064914, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.7855496954178796, 0.8934113735178925, 0.2271025671936751, 1.2305347744064914, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.7855496954178796, 0.8934113735178925, 0.2271025671936751, 1.2305347744064914, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.7855496954178796, 0.8934113735178925, 0.2271025671936751, 1.2305347744064914, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.3127551420282933, 0.9554372106185439, 0.419176743209254, 0.613370028926668, 1.1993762659429372, 1.6601775843755224, -0.9270930077902015, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.3127551420282933, 0.9554372106185439, 0.419176743209254, 0.613370028926668, 1.1993762659429372, 1.6601775843755224, -0.9270930077902015, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:40:03,376 - INFO - [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "2023-11-08 11:40:03,378 - INFO - 110609\n",
      "2023-11-08 11:40:03,379 - INFO - [[-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.8962118618028821, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.8617355345389544, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.8272592072750267, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.7927828800110989, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.7583065527471711, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.7238302254832434, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.6893538982193156, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.6548775709553878, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.62040124369146, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.5859249164275323, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.5514485891636045, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.5169722618996767, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.48249593463574897, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.4480196073718212, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.41354328010789343, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.3790669528439657, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.3445906255800379, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.31011429831611015, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.27563797105218235, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.2411616437882546, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.20668531652432684, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.17220898926039907, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.1377326619964713, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.10325633473254354, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.06878000746861578, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.034303680204688006, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.0001726470592397616, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.034648974323167527, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.06912530158709529, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.10360162885102306, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.13807795611495083, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.1725542833788786, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.20703061064280637, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.24150693790673414, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.2759832651706619, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.31045959243458965, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.34493591969851745, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.3794122469624452, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.413888574226373, '0']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.34587251014597875, -0.2371260510881844, 0.3051487380880145, 0.029264930048844468, -0.3160730875843661, -0.3766591890459441, -0.1935716453287135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.05532679134287014, -0.2815944741293343, -0.32211134163582006, -0.0899704549996704, -0.06645805008034258, -0.33684497792590695, -0.14828727498338712, -0.24435830491350327, -0.14487324959363315], [-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.34587251014597875, -0.2371260510881844, 0.3051487380880145, 0.029264930048844468, -0.3160730875843661, -0.3766591890459441, -0.1935716453287135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.05532679134287014, -0.2815944741293343, -0.32211134163582006, -0.0899704549996704, -0.06645805008034258, -0.33684497792590695, -0.14828727498338712, -0.24435830491350327, -0.14487324959363315], [-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.34587251014597875, -0.2371260510881844, 0.3051487380880145, 0.029264930048844468, -0.3160730875843661, -0.3766591890459441, -0.1935716453287135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.05532679134287014, -0.2815944741293343, -0.32211134163582006, -0.0899704549996704, -0.06645805008034258, -0.33684497792590695, -0.14828727498338712, -0.24435830491350327, -0.14487324959363315], [-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [-0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.11839355366098099, -0.14686926072725967, -0.1311661871017867, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6013515009242577, 0.6149447909519286, -1.009369603802189, 1.38817852813712, 1.2605692444279462, 0.585371321489137, 0.6420908338073934, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, -0.4065324680479176, -1.009369603802189, 1.043819195154697, 0.9546043520029015, 0.2987563180527675, 0.6420908338073934, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.8899478598202222, -0.747024887714533, -1.009369603802189, 1.38817852813712, 1.0769903089729194, 0.4420638197709522, 0.8382388140070928, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [1.0631056751578007, -0.747024887714533, -1.009369603802189, 1.4742683613827257, 1.566534136852991, 1.803485086093707, 0.8382388140070928, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7745093162618364, 0.6149447909519286, -1.2691053032588202, 0.44119036243545645, 0.46506052412282983, -0.05951243624269434, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.3704744138074862, 0.2744523712853132, -1.2691053032588202, 0.6564149455494709, 0.281481588667803, -0.2744736888199714, 0.24979487340799464, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.8899478598202222, 0.9554372106185439, -1.2691053032588202, 0.09683102945303342, 0.8934113735178925, 0.9436400757845987, 1.4266827546061909, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.6223326938143058, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.3127551420282933, -0.4065324680479176, -1.2691053032588202, 0.613370028926668, 0.46506052412282983, -0.05951243624269434, 0.24979487340799464, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.5053978624091442, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.4281936855866791, 0.6149447909519286, -0.48989820488893626, 0.613370028926668, 0.46506052412282983, -0.05951243624269434, 0.24979487340799464, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.5053978624091442, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.4281936855866791, 0.6149447909519286, -0.48989820488893626, 0.613370028926668, 0.46506052412282983, -0.05951243624269434, 0.24979487340799464, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.5053978624091442, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.3981454458126536, 0.46506052412282983, -0.05951243624269434, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.5053978624091442, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.3981454458126536, 0.46506052412282983, -0.05951243624269434, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, 0.6149447909519286, -0.48989820488893626, -0.07534863703817811, 0.22028861018279403, -0.2744736888199714, -0.5347970473908028, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, -1.4280097270477636, -0.48989820488893626, -0.07534863703817811, 0.22028861018279403, -0.2744736888199714, -0.5347970473908028, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, -1.4280097270477636, -0.48989820488893626, -0.07534863703817811, 0.22028861018279403, -0.2744736888199714, -0.5347970473908028, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.6590707727034506, -1.4280097270477636, -0.48989820488893626, -0.07534863703817811, 0.22028861018279403, -0.2744736888199714, -0.5347970473908028, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7745093162618364, 0.2744523712853132, -0.3600303551606207, -0.37666305339779826, -0.26925521769727756, -0.5610886922563408, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7167900444826435, 0.2744523712853132, -0.3600303551606207, -0.37666305339779826, -0.26925521769727756, -0.5610886922563408, -0.1425010869914041, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7745093162618364, -0.0660400483813022, -0.3600303551606207, 1.1299090284003026, 1.0157973304879104, 0.585371321489137, 0.44594285360769403, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.26404955735950336, 0.029264930048844468, -0.2606896206457801, -0.3766591890459441, -0.31050647673387505, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, -0.36678162470457243, -0.2815944741293343, -0.3333992081010445, -0.1992256677835492, -0.7268083069317782, -0.33684497792590695, -0.3293770132508767, -0.24435830491350327, 0.2603960082428797], [0.7745093162618364, -0.0660400483813022, -0.3600303551606207, 1.1299090284003026, 1.0157973304879104, 0.585371321489137, 0.44594285360769403, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.9577293619090911, 0.6486394595778567, 0.08379506547549039, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.9577293619090911, 0.6486394595778567, 0.08379506547549039, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.9577293619090911, 0.6486394595778567, 0.08379506547549039, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.9577293619090911, 0.6486394595778567, 0.08379506547549039, 1.0343867942067921, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.043819195154697, 1.627727115338, 1.373562580939153, 1.6228307348058901, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.043819195154697, 1.627727115338, 1.373562580939153, 1.6228307348058901, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.043819195154697, 1.627727115338, 1.373562580939153, 1.6228307348058901, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.043819195154697, 1.627727115338, 1.373562580939153, 1.6228307348058901, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.7855496954178796, 0.8934113735178925, 0.2271025671936751, 1.2305347744064914, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.7855496954178796, 0.8934113735178925, 0.2271025671936751, 1.2305347744064914, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.7855496954178796, 0.8934113735178925, 0.2271025671936751, 1.2305347744064914, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.7855496954178796, 0.8934113735178925, 0.2271025671936751, 1.2305347744064914, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.3127551420282933, 0.9554372106185439, 0.419176743209254, 0.613370028926668, 1.1993762659429372, 1.6601775843755224, -0.9270930077902015, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592], [0.3127551420282933, 0.9554372106185439, 0.419176743209254, 0.613370028926668, 1.1993762659429372, 1.6601775843755224, -0.9270930077902015, 0.005325137533142886, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.49591584998532545, -0.2371260510881844, 0.4695454610020563, 0.029264930048844468, -0.34930316774751763, -0.3766591890459441, -0.7002892480844135, -0.3351561343174943, -0.12930577851172065, -0.17160263114220592, 0.10040062533798204, -0.2815944741293343, -0.3333992081010445, 0.2742135876132575, -0.16805039728825624, -0.33684497792590695, -0.17415723759302862, -0.24435830491350327, 0.2893438123740592]]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "110609\n",
      "[[-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.8962118618028821, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.8617355345389544, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.8272592072750267, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.7927828800110989, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.7583065527471711, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.7238302254832434, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.6893538982193156, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.6548775709553878, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.62040124369146, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.5859249164275323, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.5514485891636045, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.5169722618996767, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.48249593463574897, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.4480196073718212, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.41354328010789343, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.3790669528439657, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.3445906255800379, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.31011429831611015, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.27563797105218235, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.2411616437882546, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.20668531652432684, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.17220898926039907, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.1377326619964713, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.10325633473254354, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.06878000746861578, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, -0.034303680204688006, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.0001726470592397616, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.034648974323167527, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.06912530158709529, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.10360162885102306, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.13807795611495083, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.1725542833788786, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.20703061064280637, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.24150693790673414, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.2759832651706619, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.31045959243458965, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.34493591969851745, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.3794122469624452, '0'], [-1.1264803265802585, -0.9931656033414253, 0.9931656033414252, 0.11854736004896246, 0.413888574226373, '0']]\n"
     ]
    }
   ],
   "source": [
    "all_x = pickle.load(open(data_path + 'new_x_front_fill.dat', 'rb'))\n",
    "all_y = pickle.load(open(data_path + 'new_y_front_fill.dat', 'rb'))\n",
    "all_names = pickle.load(open(data_path + 'new_name.dat', 'rb'))\n",
    "static = pickle.load(open(data_path + 'new_demo_front_fill.dat', 'rb'))\n",
    "mask_x = pickle.load(open(data_path + 'new_mask_x.dat', 'rb'))\n",
    "mask_demo = pickle.load(open(data_path + 'new_mask_demo.dat', 'rb'))\n",
    "all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "print(all_x[0])\n",
    "print(mask_x[0])\n",
    "print(all_names[0])\n",
    "print(static[0])\n",
    "logger.info(all_x[0])\n",
    "logger.info(mask_x[0])\n",
    "logger.info(all_names[0])\n",
    "logger.info(static[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T04:27:41.051036Z",
     "start_time": "2021-01-30T04:27:29.075798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:40:22,844 - INFO - [[-0.14828727498338712, -0.06645805008034258, -0.0899704549996704, -0.14487324959363315, -0.05532679134287014, 0.029264930048844468, 0.005325137533142886, -0.1935716453287135, -0.2371260510881844, -0.34587251014597875, -0.3160730875843661, 0.3051487380880145, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.32211134163582006, -0.33684497792590695, -0.24435830491350327], [-0.14828727498338712, -0.06645805008034258, -0.0899704549996704, -0.14487324959363315, -0.05532679134287014, 0.029264930048844468, 0.005325137533142886, -0.1935716453287135, -0.2371260510881844, -0.34587251014597875, -0.3160730875843661, 0.3051487380880145, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.32211134163582006, -0.33684497792590695, -0.24435830491350327], [-0.14828727498338712, -0.06645805008034258, -0.0899704549996704, -0.14487324959363315, -0.05532679134287014, 0.029264930048844468, 0.005325137533142886, -0.1935716453287135, -0.2371260510881844, -0.34587251014597875, -0.3160730875843661, 0.3051487380880145, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.32211134163582006, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.38817852813712, 0.585371321489137, 0.6013515009242577, 0.6149447909519286, -1.009369603802189, 1.2605692444279462, 0.6420908338073934, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.043819195154697, 0.2987563180527675, 0.6590707727034506, -0.4065324680479176, -1.009369603802189, 0.9546043520029015, 0.6420908338073934, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.38817852813712, 0.4420638197709522, 0.8899478598202222, -0.747024887714533, -1.009369603802189, 1.0769903089729194, 0.8382388140070928, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.4742683613827257, 1.803485086093707, 1.0631056751578007, -0.747024887714533, -1.009369603802189, 1.566534136852991, 0.8382388140070928, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.44119036243545645, -0.05951243624269434, 0.7745093162618364, 0.6149447909519286, -1.2691053032588202, 0.46506052412282983, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.6564149455494709, -0.2744736888199714, 0.3704744138074862, 0.2744523712853132, -1.2691053032588202, 0.281481588667803, 0.24979487340799464, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.09683102945303342, 0.9436400757845987, 0.8899478598202222, 0.9554372106185439, -1.2691053032588202, 0.8934113735178925, 1.4266827546061909, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.5053978624091442, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.613370028926668, -0.05951243624269434, 0.3127551420282933, -0.4065324680479176, -1.2691053032588202, 0.46506052412282983, 0.24979487340799464, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.5053978624091442, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.613370028926668, -0.05951243624269434, 0.4281936855866791, 0.6149447909519286, -0.48989820488893626, 0.46506052412282983, 0.24979487340799464, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.5053978624091442, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.613370028926668, -0.05951243624269434, 0.4281936855866791, 0.6149447909519286, -0.48989820488893626, 0.46506052412282983, 0.24979487340799464, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.5053978624091442, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.3981454458126536, -0.05951243624269434, 0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.46506052412282983, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.3981454458126536, -0.05951243624269434, 0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.46506052412282983, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.07534863703817811, -0.2744736888199714, 0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.22028861018279403, -0.5347970473908028, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.07534863703817811, -0.2744736888199714, 0.6590707727034506, -1.4280097270477636, -0.48989820488893626, 0.22028861018279403, -0.5347970473908028, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.07534863703817811, -0.2744736888199714, 0.6590707727034506, -1.4280097270477636, -0.48989820488893626, 0.22028861018279403, -0.5347970473908028, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.07534863703817811, -0.2744736888199714, 0.6590707727034506, -1.4280097270477636, -0.48989820488893626, 0.22028861018279403, -0.5347970473908028, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.37666305339779826, -0.5610886922563408, 0.7745093162618364, 0.2744523712853132, -0.3600303551606207, -0.26925521769727756, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.37666305339779826, -0.5610886922563408, 0.7167900444826435, 0.2744523712853132, -0.3600303551606207, -0.26925521769727756, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.1299090284003026, 0.585371321489137, 0.7745093162618364, -0.0660400483813022, -0.3600303551606207, 1.0157973304879104, 0.44594285360769403, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.1299090284003026, 0.585371321489137, 0.7745093162618364, -0.0660400483813022, -0.3600303551606207, 1.0157973304879104, 0.44594285360769403, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.9577293619090911, 0.08379506547549039, 0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.6486394595778567, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.9577293619090911, 0.08379506547549039, 0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.6486394595778567, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.9577293619090911, 0.08379506547549039, 0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.6486394595778567, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.9577293619090911, 0.08379506547549039, 0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.6486394595778567, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.043819195154697, 1.373562580939153, 0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.627727115338, 1.6228307348058901, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.043819195154697, 1.373562580939153, 0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.627727115338, 1.6228307348058901, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.043819195154697, 1.373562580939153, 0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.627727115338, 1.6228307348058901, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.043819195154697, 1.373562580939153, 0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.627727115338, 1.6228307348058901, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.7855496954178796, 0.2271025671936751, 0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.8934113735178925, 1.2305347744064914, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.7855496954178796, 0.2271025671936751, 0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.8934113735178925, 1.2305347744064914, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.7855496954178796, 0.2271025671936751, 0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.8934113735178925, 1.2305347744064914, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.7855496954178796, 0.2271025671936751, 0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.8934113735178925, 1.2305347744064914, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.613370028926668, 1.6601775843755224, 0.3127551420282933, 0.9554372106185439, 0.419176743209254, 1.1993762659429372, -0.9270930077902015, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.613370028926668, 1.6601775843755224, 0.3127551420282933, 0.9554372106185439, 0.419176743209254, 1.1993762659429372, -0.9270930077902015, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:40:22,851 - INFO - [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "2023-11-08 11:40:22,853 - INFO - 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14828727498338712, -0.06645805008034258, -0.0899704549996704, -0.14487324959363315, -0.05532679134287014, 0.029264930048844468, 0.005325137533142886, -0.1935716453287135, -0.2371260510881844, -0.34587251014597875, -0.3160730875843661, 0.3051487380880145, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.32211134163582006, -0.33684497792590695, -0.24435830491350327], [-0.14828727498338712, -0.06645805008034258, -0.0899704549996704, -0.14487324959363315, -0.05532679134287014, 0.029264930048844468, 0.005325137533142886, -0.1935716453287135, -0.2371260510881844, -0.34587251014597875, -0.3160730875843661, 0.3051487380880145, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.32211134163582006, -0.33684497792590695, -0.24435830491350327], [-0.14828727498338712, -0.06645805008034258, -0.0899704549996704, -0.14487324959363315, -0.05532679134287014, 0.029264930048844468, 0.005325137533142886, -0.1935716453287135, -0.2371260510881844, -0.34587251014597875, -0.3160730875843661, 0.3051487380880145, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.32211134163582006, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.11839355366098099, -0.1311661871017867, -0.06242012453646045, 0.2744523712853132, 0.02957319402431667, -0.14686926072725967, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.38817852813712, 0.585371321489137, 0.6013515009242577, 0.6149447909519286, -1.009369603802189, 1.2605692444279462, 0.6420908338073934, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.043819195154697, 0.2987563180527675, 0.6590707727034506, -0.4065324680479176, -1.009369603802189, 0.9546043520029015, 0.6420908338073934, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.38817852813712, 0.4420638197709522, 0.8899478598202222, -0.747024887714533, -1.009369603802189, 1.0769903089729194, 0.8382388140070928, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.4742683613827257, 1.803485086093707, 1.0631056751578007, -0.747024887714533, -1.009369603802189, 1.566534136852991, 0.8382388140070928, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.44119036243545645, -0.05951243624269434, 0.7745093162618364, 0.6149447909519286, -1.2691053032588202, 0.46506052412282983, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.6564149455494709, -0.2744736888199714, 0.3704744138074862, 0.2744523712853132, -1.2691053032588202, 0.281481588667803, 0.24979487340799464, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.6223326938143058, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.09683102945303342, 0.9436400757845987, 0.8899478598202222, 0.9554372106185439, -1.2691053032588202, 0.8934113735178925, 1.4266827546061909, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.5053978624091442, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.613370028926668, -0.05951243624269434, 0.3127551420282933, -0.4065324680479176, -1.2691053032588202, 0.46506052412282983, 0.24979487340799464, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.5053978624091442, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.613370028926668, -0.05951243624269434, 0.4281936855866791, 0.6149447909519286, -0.48989820488893626, 0.46506052412282983, 0.24979487340799464, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.5053978624091442, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.613370028926668, -0.05951243624269434, 0.4281936855866791, 0.6149447909519286, -0.48989820488893626, 0.46506052412282983, 0.24979487340799464, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.5053978624091442, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.3981454458126536, -0.05951243624269434, 0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.46506052412282983, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 0.3981454458126536, -0.05951243624269434, 0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.46506052412282983, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.07534863703817811, -0.2744736888199714, 0.6590707727034506, 0.6149447909519286, -0.48989820488893626, 0.22028861018279403, -0.5347970473908028, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.07534863703817811, -0.2744736888199714, 0.6590707727034506, -1.4280097270477636, -0.48989820488893626, 0.22028861018279403, -0.5347970473908028, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.07534863703817811, -0.2744736888199714, 0.6590707727034506, -1.4280097270477636, -0.48989820488893626, 0.22028861018279403, -0.5347970473908028, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.07534863703817811, -0.2744736888199714, 0.6590707727034506, -1.4280097270477636, -0.48989820488893626, 0.22028861018279403, -0.5347970473908028, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.37666305339779826, -0.5610886922563408, 0.7745093162618364, 0.2744523712853132, -0.3600303551606207, -0.26925521769727756, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, -0.37666305339779826, -0.5610886922563408, 0.7167900444826435, 0.2744523712853132, -0.3600303551606207, -0.26925521769727756, -0.1425010869914041, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.3293770132508767, -0.7268083069317782, -0.1992256677835492, 0.2603960082428797, -0.36678162470457243, 0.029264930048844468, 0.005325137533142886, -0.31050647673387505, -0.2371260510881844, -0.49591584998532545, -0.2606896206457801, 0.26404955735950336, -0.17160263114220592, 1.1299090284003026, 0.585371321489137, 0.7745093162618364, -0.0660400483813022, -0.3600303551606207, 1.0157973304879104, 0.44594285360769403, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.1299090284003026, 0.585371321489137, 0.7745093162618364, -0.0660400483813022, -0.3600303551606207, 1.0157973304879104, 0.44594285360769403, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.9577293619090911, 0.08379506547549039, 0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.6486394595778567, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.9577293619090911, 0.08379506547549039, 0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.6486394595778567, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.9577293619090911, 0.08379506547549039, 0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.6486394595778567, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.9577293619090911, 0.08379506547549039, 0.6590707727034506, 0.2744523712853132, -0.6197660546172518, 0.6486394595778567, 1.0343867942067921, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.043819195154697, 1.373562580939153, 0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.627727115338, 1.6228307348058901, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.043819195154697, 1.373562580939153, 0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.627727115338, 1.6228307348058901, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.043819195154697, 1.373562580939153, 0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.627727115338, 1.6228307348058901, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 1.043819195154697, 1.373562580939153, 0.4281936855866791, 0.9554372106185439, -0.48989820488893626, 1.627727115338, 1.6228307348058901, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.7855496954178796, 0.2271025671936751, 0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.8934113735178925, 1.2305347744064914, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.7855496954178796, 0.2271025671936751, 0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.8934113735178925, 1.2305347744064914, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.7855496954178796, 0.2271025671936751, 0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.8934113735178925, 1.2305347744064914, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.7855496954178796, 0.2271025671936751, 0.19731659846990754, 0.9554372106185439, -0.2301625054323144, 0.8934113735178925, 1.2305347744064914, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.613370028926668, 1.6601775843755224, 0.3127551420282933, 0.9554372106185439, 0.419176743209254, 1.1993762659429372, -0.9270930077902015, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327], [-0.17415723759302862, -0.16805039728825624, 0.2742135876132575, 0.2893438123740592, 0.10040062533798204, 0.029264930048844468, 0.005325137533142886, -0.7002892480844135, -0.2371260510881844, -0.49591584998532545, -0.34930316774751763, 0.4695454610020563, -0.17160263114220592, 0.613370028926668, 1.6601775843755224, 0.3127551420282933, 0.9554372106185439, 0.419176743209254, 1.1993762659429372, -0.9270930077902015, 0.16066034068876195, -0.01724690479013476, -0.004930129148398766, 0.014295447077977357, -0.11026740609348425, 0.39895882324044557, -0.2561829490343818, -0.3766591890459441, -0.3351561343174943, -0.12930577851172065, -0.2815944741293343, -0.3333992081010445, -0.33684497792590695, -0.24435830491350327]]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "if target_dataset == 'PD':\n",
    "    subset_idx = [31, 29, 28, 33, 25, 18, 7, 21, 16, 15, 19, 17, 24, 3, 5, 0]\n",
    "\n",
    "subset_cnt = len(subset_idx)\n",
    "other_idx = []\n",
    "for i in range(len(all_x[0][0])):\n",
    "    if i not in subset_idx:\n",
    "        other_idx.append(i)\n",
    "\n",
    "for i in range(len(all_x)):\n",
    "    cur = np.array(all_x[i], dtype=float)\n",
    "    cur_mask = np.array(mask_x[i])\n",
    "    cur_subset = cur[:, subset_idx]\n",
    "    cur_other = cur[:, other_idx]\n",
    "    cur_mask_subset = cur_mask[:, subset_idx]\n",
    "    cur_mask_other = cur_mask[:, other_idx]\n",
    "    all_x[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "    mask_x[i] = np.concatenate((cur_mask_subset, cur_mask_other), axis=1).tolist()\n",
    "print(all_x[0])\n",
    "print(mask_x[0])\n",
    "print(len(all_x[0][0]))\n",
    "logger.info(all_x[0])\n",
    "logger.info(mask_x[0])\n",
    "logger.info(len(all_x[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T04:28:59.378928Z",
     "start_time": "2021-01-30T04:28:57.102580Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:40:24,742 - INFO - 32269\n",
      "2023-11-08 11:40:24,744 - INFO - 4034\n",
      "2023-11-08 11:40:24,745 - INFO - 4033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32269\n",
      "4034\n",
      "4033\n"
     ]
    }
   ],
   "source": [
    "train_num =int( len(all_x) * 0.8) + 1\n",
    "print(train_num)\n",
    "logger.info(train_num)\n",
    "dev_num =int( len(all_x) * 0.1) + 1\n",
    "print(dev_num)\n",
    "logger.info(dev_num)\n",
    "test_num =int( len(all_x) * 0.1)\n",
    "print(test_num)\n",
    "logger.info(test_num)\n",
    "assert(train_num+dev_num+test_num == len(all_x))\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "train_names = []\n",
    "train_static = []\n",
    "train_x_len = []\n",
    "train_mask_x = []\n",
    "for idx in range(train_num):\n",
    "    train_x.append(all_x[idx])\n",
    "    train_y.append(int(all_y[idx][-1]))\n",
    "    train_names.append(all_names[idx])\n",
    "    train_static.append(static[idx])\n",
    "    train_x_len.append(all_x_len[idx])\n",
    "    train_mask_x.append(mask_x[idx])\n",
    "\n",
    "dev_x = []\n",
    "dev_y = []\n",
    "dev_names = []\n",
    "dev_static = []\n",
    "dev_x_len = []\n",
    "dev_mask_x = []\n",
    "for idx in range(train_num, train_num + dev_num):\n",
    "    dev_x.append(all_x[idx])\n",
    "    dev_y.append(int(all_y[idx][-1]))\n",
    "    dev_names.append(all_names[idx])\n",
    "    dev_static.append(static[idx])\n",
    "    dev_x_len.append(all_x_len[idx])\n",
    "    dev_mask_x.append(mask_x[idx])\n",
    "\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "test_names = []\n",
    "test_static = []\n",
    "test_x_len = []\n",
    "test_mask_x = []\n",
    "for idx in range(train_num + dev_num, train_num + dev_num + test_num):\n",
    "    test_x.append(all_x[idx])\n",
    "    test_y.append(int(all_y[idx][-1]))\n",
    "    test_names.append(all_names[idx])\n",
    "    test_static.append(static[idx])\n",
    "    test_x_len.append(all_x_len[idx])\n",
    "    test_mask_x.append(mask_x[idx])\n",
    "\n",
    "\n",
    "assert(len(train_x) == train_num)\n",
    "assert(len(dev_x) == dev_num)\n",
    "assert(len(test_x) == test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T04:29:02.456915Z",
     "start_time": "2021-01-30T04:29:02.443296Z"
    }
   },
   "outputs": [],
   "source": [
    "long_x = all_x\n",
    "long_y = [y[-1] for y in all_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:38.783950Z",
     "start_time": "2021-02-10T15:05:38.778517Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(y_pred, y_true):\n",
    "    loss = torch.nn.BCELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:39.004588Z",
     "start_time": "2021-02-10T15:05:38.999638Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_re_loss(y_pred, y_true):\n",
    "    loss = torch.nn.MSELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:39.151905Z",
     "start_time": "2021-02-10T15:05:39.147577Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_kl_loss(x_pred, x_target):\n",
    "    loss = torch.nn.KLDivLoss(reduce=True, size_average=True)\n",
    "    return loss(x_pred, x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:39.322887Z",
     "start_time": "2021-02-10T15:05:39.313036Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wass_dist(x_pred, x_target):\n",
    "    m1 = torch.mean(x_pred, dim=0)\n",
    "    m2 = torch.mean(x_target, dim=0)\n",
    "    v1 = torch.var(x_pred, dim=0)\n",
    "    v2 = torch.var(x_target, dim=0)\n",
    "    p1 = torch.sum(torch.pow((m1 - m2), 2))\n",
    "    p2 = torch.sum(torch.pow(torch.pow(v1, 1/2) - torch.pow(v2, 1/2), 2))\n",
    "    return torch.pow(p1+p2, 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:41.142115Z",
     "start_time": "2021-02-10T15:05:41.134517Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "\n",
    "    sents_padded = []\n",
    "\n",
    "    max_length = max([len(_) for _ in sents])\n",
    "    for i in sents:\n",
    "        padded = list(i) + [pad_token]*(max_length-len(i))\n",
    "        sents_padded.append(np.array(padded))\n",
    "\n",
    "\n",
    "    return np.array(sents_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:41.301945Z",
     "start_time": "2021-02-10T15:05:41.287538Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_iter(x, y, mask, lens, batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        \n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx], mask[idx], lens[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "        batch_mask_x = [e[2] for e in examples]\n",
    "#         batch_name = [e[2] for e in examples]\n",
    "        batch_lens = [e[3] for e in examples]\n",
    "\n",
    "        yield batch_x, batch_y, batch_mask_x, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:41.394432Z",
     "start_time": "2021-02-10T15:05:41.386828Z"
    }
   },
   "outputs": [],
   "source": [
    "def length_to_mask(length, max_len=None, dtype=None):\n",
    "    \"\"\"length: B.\n",
    "    return B x max_len.\n",
    "    If max_len is None, then max of length will be used.\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1, 'Length shape should be 1 dimensional.'\n",
    "    max_len = max_len or length.max().item()\n",
    "    mask = torch.arange(max_len, device=length.device,\n",
    "                        dtype=length.dtype).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "    if dtype is not None:\n",
    "        mask = torch.as_tensor(mask, dtype=dtype, device=length.device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:41.786588Z",
     "start_time": "2021-02-10T15:05:41.673200Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleAttention(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', demographic_dim=12, time_aware=False, use_demographic=False):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "        self.use_demographic = use_demographic\n",
    "        self.demographic_dim = demographic_dim\n",
    "        self.time_aware = time_aware\n",
    "\n",
    "        # batch_time = torch.arange(0, batch_mask.size()[1], dtype=torch.float32).reshape(1, batch_mask.size()[1], 1)\n",
    "        # batch_time = batch_time.repeat(batch_mask.size()[0], 1, 1)\n",
    "        \n",
    "        if attention_type == 'add':\n",
    "            if self.time_aware == True:\n",
    "                # self.Wx = nn.Parameter(torch.randn(attention_input_dim+1, attention_hidden_dim))\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "                self.Wtime_aware = nn.Parameter(torch.randn(1, attention_hidden_dim))\n",
    "                nn.init.kaiming_uniform_(self.Wtime_aware, a=math.sqrt(5))\n",
    "            else:\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wd = nn.Parameter(torch.randn(demographic_dim, attention_hidden_dim))\n",
    "            self.bh = nn.Parameter(torch.zeros(attention_hidden_dim,))\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wd, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'mul':\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_input_dim, attention_input_dim))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'concat':\n",
    "            if self.time_aware == True:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim+1, attention_hidden_dim))\n",
    "            else:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        else:\n",
    "            raise RuntimeError('Wrong attention type.')\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "    \n",
    "    def forward(self, input, demo=None):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * time_step * hidden_dim(i)\n",
    "        time_decays = torch.tensor(range(time_step-1,-1,-1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device)# 1*t*1\n",
    "        b_time_decays = time_decays.repeat(batch_size,1,1)# b t 1\n",
    "        \n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
    "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            if self.time_aware == True:\n",
    "                # k_input = torch.cat((input, time), dim=-1)\n",
    "                k = torch.matmul(input, self.Wx)#b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "                time_hidden = torch.matmul(b_time_decays, self.Wtime_aware)#  b t h\n",
    "            else:\n",
    "                k = torch.matmul(input, self.Wx)# b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "            if self.use_demographic == True:\n",
    "                d = torch.matmul(demo, self.Wd) #B*H\n",
    "                d = torch.reshape(d, (batch_size, 1, self.attention_hidden_dim)) # b 1 h\n",
    "            h = q + k + self.bh # b t h\n",
    "            if self.time_aware == True:\n",
    "                h += time_hidden\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "        elif self.attention_type == 'mul':\n",
    "            e = torch.matmul(input[:,-1,:], self.Wa)#b i\n",
    "            e = torch.matmul(e.unsqueeze(1), input.permute(0,2,1)).squeeze() + self.ba #b t\n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input[:,-1,:].unsqueeze(1).repeat(1,time_step,1)# b t i\n",
    "            k = input\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            if self.time_aware == True:\n",
    "                c = torch.cat((c, b_time_decays), dim=-1) #B*T*2I+1\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "        \n",
    "        a = self.softmax(e) #B*T\n",
    "        v = torch.matmul(a.unsqueeze(1), input).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "class FinalAttentionQKV(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', dropout=None):\n",
    "        super(FinalAttentionQKV, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "\n",
    "\n",
    "        self.W_q = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_k = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_v = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "\n",
    "        self.W_out = nn.Linear(attention_hidden_dim, 1)\n",
    "\n",
    "        self.b_in = nn.Parameter(torch.zeros(1,))\n",
    "        self.b_out = nn.Parameter(torch.zeros(1,))\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.W_q.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_k.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_v.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_out.weight, a=math.sqrt(5))\n",
    "\n",
    "        self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "        self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "        self.ba = nn.Parameter(torch.zeros(1,))\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, input):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * input_dim + 1 * hidden_dim(i)\n",
    "        input_q = self.W_q(torch.mean(input, dim=1)) # b h\n",
    "        input_k = self.W_k(input)# b t h\n",
    "        input_v = self.W_v(input)# b t h\n",
    "\n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "\n",
    "            q = torch.reshape(input_q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            h = q + input_k + self.b_in # b t h\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = self.W_out(h) # b t 1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "\n",
    "        elif self.attention_type == 'mul':\n",
    "            q = torch.reshape(input_q, (batch_size, self.attention_hidden_dim, 1)) #B*h 1\n",
    "            e = torch.matmul(input_k, q).squeeze()#b t\n",
    "            \n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input_q.unsqueeze(1).repeat(1,time_step,1)# b t h\n",
    "            k = input_k\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "        \n",
    "        a = self.softmax(e) #B*T\n",
    "        if self.dropout is not None:\n",
    "            a = self.dropout(a)\n",
    "        v = torch.matmul(a.unsqueeze(1), input_v).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)])).to(device)\n",
    "    return torch.index_select(a, dim, order_index).to(device)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module): # new added\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x)))), None\n",
    "\n",
    "    \n",
    "class PositionalEncoding(nn.Module): # new added / not use anymore\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=400):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0 \n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)# b h t d_k\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k) # b h t t\n",
    "    if mask is not None:# 1 1 t t\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)# b h t t \n",
    "    p_attn = F.softmax(scores, dim = -1)# b h t t\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn # b h t v (d_k) \n",
    "    \n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, self.d_k * self.h), 3)\n",
    "        self.final_linear = nn.Linear(d_model, d_model)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1) # 1 1 t t\n",
    "\n",
    "        nbatches = query.size(0)# b\n",
    "        input_dim = query.size(1)# i+1\n",
    "        feature_dim = query.size(-1)# i+1\n",
    "\n",
    "        #input size -> # batch_size * d_input * hidden_dim\n",
    "        \n",
    "        # d_model => h * d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))] # b num_head d_input d_k\n",
    "        \n",
    "       \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
    "        \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)# batch_size * d_input * hidden_dim\n",
    "\n",
    "        #DeCov \n",
    "        DeCov_contexts = x.transpose(0, 1).transpose(1, 2) # I+1 H B\n",
    "#         print(DeCov_contexts.shape)\n",
    "        Covs = cov(DeCov_contexts[0,:,:])\n",
    "        DeCov_loss = 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
    "        for i in range(11 -1):\n",
    "            Covs = cov(DeCov_contexts[i+1,:,:])\n",
    "            DeCov_loss += 0.5 * (torch.norm(Covs, p = 'fro')**2 - torch.norm(torch.diag(Covs))**2 ) \n",
    "\n",
    "\n",
    "        return self.final_linear(x), DeCov_loss\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-7):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "def cov(m, y=None):\n",
    "    if y is not None:\n",
    "        m = torch.cat((m, y), dim=0)\n",
    "    m_exp = torch.mean(m, dim=1)\n",
    "    x = m - m_exp[:, None]\n",
    "    cov = 1 / (x.size(1) - 1) * x.mm(x.t())\n",
    "    return cov\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        returned_value = sublayer(self.norm(x))\n",
    "        return x + self.dropout(returned_value[0]) , returned_value[1]\n",
    "\n",
    "class distcare_teacher(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(distcare_teacher, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
    "\n",
    "        self.LSTMs = clones(nn.LSTM(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 8, attention_type='concat', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
    "        \n",
    "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
    "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.Linear = nn.Linear(self.hidden_dim, 1)\n",
    "        self.output = nn.Linear(self.input_dim, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, lens):\n",
    "        lens = lens.to('cpu')\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "#         demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "        \n",
    "        LSTM_embeded_input = self.LSTMs[0](pack_padded_sequence(input[:,:,0].unsqueeze(-1), lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "#         print(LSTM_embeded_input.shape)\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.LSTMs[i+1](pack_padded_sequence(input[:,:,i+1].unsqueeze(-1), lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "            LSTM_embeded_input = torch.cat((LSTM_embeded_input, embeded_input), 1)\n",
    "\n",
    "#         LSTM_embeded_input = torch.cat((LSTM_embeded_input, demo_main), 1)# b i+1 h\n",
    "        posi_input = self.dropout(LSTM_embeded_input) # batch_size * d_input * hidden_dim\n",
    "\n",
    "\n",
    "#         #mask = subsequent_mask(time_step).to(device) # 1 t t \n",
    "#         contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
    "    \n",
    "#         DeCov_loss = contexts[1]\n",
    "#         contexts = contexts[0]\n",
    "\n",
    "#         contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
    "#         #contexts = contexts.view(batch_size, feature_dim * self.hidden_dim)#\n",
    "#         # contexts = torch.matmul(self.Wproj, contexts) + self.bproj\n",
    "#         # contexts = contexts.squeeze()\n",
    "#         # demo_key = self.demo_proj(demo_input)# b hidden_dim\n",
    "#         # demo_key = self.relu(demo_key)\n",
    "#         # input_dim_scores = torch.matmul(contexts, demo_key.unsqueeze(-1)).squeeze() # b i\n",
    "#         # input_dim_scores = self.dropout(self.sigmoid(input_dim_scores)).unsqueeze(1)# b i\n",
    "        \n",
    "#         # weighted_contexts = torch.matmul(input_dim_scores, contexts).squeeze()\n",
    "# #         print(contexts.shape)\n",
    "\n",
    "#         weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
    "        contexts = self.Linear(posi_input).squeeze()# b i\n",
    "        output = self.output(self.dropout(contexts))# b 1\n",
    "        output = self.sigmoid(output)\n",
    "#         print(weighted_contexts.shape)\n",
    "          \n",
    "        return output, None, contexts\n",
    "    #, self.MultiHeadedAttention.attn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:05:51.991644Z",
     "start_time": "2021-02-10T15:05:42.504740Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 43\n",
    "np.random.seed(RANDOM_SEED) #numpy\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED) # cpu\n",
    "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
    "torch.backends.cudnn.deterministic=True # cudnn\n",
    "    \n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "input_dim = 34\n",
    "hidden_dim = 32\n",
    "d_model = 32\n",
    "MHD_num_head = 4\n",
    "d_ff = 64\n",
    "output_dim = 1\n",
    "\n",
    "model = distcare_teacher(input_dim = input_dim, hidden_dim = hidden_dim, d_model=d_model, MHD_num_head=MHD_num_head, d_ff=d_ff, output_dim = output_dim).to(device)\n",
    "# input_dim, d_model, d_k, d_v, MHD_num_head, d_ff, output_dim\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T09:16:04.789735Z",
     "start_time": "2021-01-30T04:30:23.650979Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:40:33,710 - INFO - Epoch 0 Batch 0: Train Loss = 0.6808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 0: Train Loss = 0.6808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:40:46,183 - INFO - Epoch 0 Batch 20: Train Loss = 0.4999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 20: Train Loss = 0.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:40:58,978 - INFO - Epoch 0 Batch 40: Train Loss = 0.2446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 40: Train Loss = 0.2446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:41:11,901 - INFO - Epoch 0 Batch 60: Train Loss = 0.2429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 60: Train Loss = 0.2429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:41:24,679 - INFO - Epoch 0 Batch 80: Train Loss = 0.2754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 80: Train Loss = 0.2754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:41:37,387 - INFO - Epoch 0 Batch 100: Train Loss = 0.2965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 100: Train Loss = 0.2965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:41:50,539 - INFO - Epoch 0 Batch 120: Train Loss = 0.2876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 120: Train Loss = 0.2876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "2023-11-08 11:42:00,621 - INFO - Epoch 0: Loss = 0.3324 Valid loss = 0.2427 roc = 0.7840\n",
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.3324 Valid loss = 0.2427 roc = 0.7840\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 292    0]]\n",
      "accuracy = 0.9276152849197388\n",
      "precision class 0 = 0.9276152849197388\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.7840086247922509\n",
      "AUC of PRC = 0.3275657272465735\n",
      "min(+P, Se) = 0.3651877133105802\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7840 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:42:01,462 - INFO - Epoch 1 Batch 0: Train Loss = 0.1582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0: Train Loss = 0.1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:42:14,411 - INFO - Epoch 1 Batch 20: Train Loss = 0.2439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 20: Train Loss = 0.2439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:42:27,416 - INFO - Epoch 1 Batch 40: Train Loss = 0.2760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 40: Train Loss = 0.2760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:42:39,931 - INFO - Epoch 1 Batch 60: Train Loss = 0.2402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 60: Train Loss = 0.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:42:53,054 - INFO - Epoch 1 Batch 80: Train Loss = 0.2449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 80: Train Loss = 0.2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:43:06,564 - INFO - Epoch 1 Batch 100: Train Loss = 0.2678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 100: Train Loss = 0.2678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:43:20,390 - INFO - Epoch 1 Batch 120: Train Loss = 0.2198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 120: Train Loss = 0.2198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "2023-11-08 11:43:30,614 - INFO - Epoch 1: Loss = 0.2463 Valid loss = 0.2316 roc = 0.7967\n",
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.2463 Valid loss = 0.2316 roc = 0.7967\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 292    0]]\n",
      "accuracy = 0.9276152849197388\n",
      "precision class 0 = 0.9276152849197388\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.7966666788692589\n",
      "AUC of PRC = 0.3732740342057184\n",
      "min(+P, Se) = 0.3767123287671233\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7967 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:43:31,350 - INFO - Epoch 2 Batch 0: Train Loss = 0.1713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 0: Train Loss = 0.1713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:43:43,942 - INFO - Epoch 2 Batch 20: Train Loss = 0.2360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 20: Train Loss = 0.2360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:43:56,534 - INFO - Epoch 2 Batch 40: Train Loss = 0.3260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 40: Train Loss = 0.3260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:44:09,215 - INFO - Epoch 2 Batch 60: Train Loss = 0.2090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 60: Train Loss = 0.2090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:44:22,335 - INFO - Epoch 2 Batch 80: Train Loss = 0.2575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 80: Train Loss = 0.2575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:44:36,610 - INFO - Epoch 2 Batch 100: Train Loss = 0.2657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 100: Train Loss = 0.2657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:44:51,192 - INFO - Epoch 2 Batch 120: Train Loss = 0.2165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 120: Train Loss = 0.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "2023-11-08 11:45:00,662 - INFO - Epoch 2: Loss = 0.2377 Valid loss = 0.2251 roc = 0.8182\n",
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.2377 Valid loss = 0.2251 roc = 0.8182\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 292    0]]\n",
      "accuracy = 0.9276152849197388\n",
      "precision class 0 = 0.9276152849197388\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.8182204227466083\n",
      "AUC of PRC = 0.37863989105548346\n",
      "min(+P, Se) = 0.4061433447098976\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.8182 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:45:01,491 - INFO - Epoch 3 Batch 0: Train Loss = 0.2491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 0: Train Loss = 0.2491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:45:14,806 - INFO - Epoch 3 Batch 20: Train Loss = 0.2855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 20: Train Loss = 0.2855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:45:28,513 - INFO - Epoch 3 Batch 40: Train Loss = 0.2296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 40: Train Loss = 0.2296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:45:42,110 - INFO - Epoch 3 Batch 60: Train Loss = 0.2714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 60: Train Loss = 0.2714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:45:57,801 - INFO - Epoch 3 Batch 80: Train Loss = 0.2521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 80: Train Loss = 0.2521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:46:13,047 - INFO - Epoch 3 Batch 100: Train Loss = 0.2506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 100: Train Loss = 0.2506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:46:27,097 - INFO - Epoch 3 Batch 120: Train Loss = 0.1608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 120: Train Loss = 0.1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "2023-11-08 11:46:37,610 - INFO - Epoch 3: Loss = 0.2359 Valid loss = 0.2130 roc = 0.8437\n",
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.2359 Valid loss = 0.2130 roc = 0.8437\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 292    0]]\n",
      "accuracy = 0.9276152849197388\n",
      "precision class 0 = 0.9276152849197388\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.8437149938132855\n",
      "AUC of PRC = 0.4094803368458997\n",
      "min(+P, Se) = 0.4041095890410959\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.8437 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:46:38,342 - INFO - Epoch 4 Batch 0: Train Loss = 0.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 0: Train Loss = 0.1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:46:53,245 - INFO - Epoch 4 Batch 20: Train Loss = 0.2392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 20: Train Loss = 0.2392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:47:06,659 - INFO - Epoch 4 Batch 40: Train Loss = 0.2199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 40: Train Loss = 0.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:47:20,553 - INFO - Epoch 4 Batch 60: Train Loss = 0.2691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 60: Train Loss = 0.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:47:34,181 - INFO - Epoch 4 Batch 80: Train Loss = 0.2417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 80: Train Loss = 0.2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:47:48,534 - INFO - Epoch 4 Batch 100: Train Loss = 0.2220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 100: Train Loss = 0.2220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:48:02,189 - INFO - Epoch 4 Batch 120: Train Loss = 0.2499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 120: Train Loss = 0.2499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:48:12,890 - INFO - Epoch 4: Loss = 0.2276 Valid loss = 0.2039 roc = 0.8561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.2276 Valid loss = 0.2039 roc = 0.8561\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 290    2]]\n",
      "accuracy = 0.9281110763549805\n",
      "precision class 0 = 0.92807537317276\n",
      "precision class 1 = 1.0\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.006849315017461777\n",
      "AUC of ROC = 0.8560902528133076\n",
      "AUC of PRC = 0.44346120007787027\n",
      "min(+P, Se) = 0.4349315068493151\n",
      "f1_score = 0.013605442428567911\n",
      "------------ Save best model - AUROC: 0.8561 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:48:13,628 - INFO - Epoch 5 Batch 0: Train Loss = 0.2781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 0: Train Loss = 0.2781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:48:27,499 - INFO - Epoch 5 Batch 20: Train Loss = 0.2354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 20: Train Loss = 0.2354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:48:41,157 - INFO - Epoch 5 Batch 40: Train Loss = 0.2568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 40: Train Loss = 0.2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:48:55,020 - INFO - Epoch 5 Batch 60: Train Loss = 0.2312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 60: Train Loss = 0.2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:49:08,215 - INFO - Epoch 5 Batch 80: Train Loss = 0.2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 80: Train Loss = 0.2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:49:20,950 - INFO - Epoch 5 Batch 100: Train Loss = 0.2164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 100: Train Loss = 0.2164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:49:33,356 - INFO - Epoch 5 Batch 120: Train Loss = 0.1825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 120: Train Loss = 0.1825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:49:43,901 - INFO - Epoch 5: Loss = 0.2180 Valid loss = 0.1930 roc = 0.8853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.2180 Valid loss = 0.1930 roc = 0.8853\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 286    6]]\n",
      "accuracy = 0.9291025996208191\n",
      "precision class 0 = 0.9289970397949219\n",
      "precision class 1 = 1.0\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.02054794505238533\n",
      "AUC of ROC = 0.8852758029915877\n",
      "AUC of PRC = 0.5073122422260751\n",
      "min(+P, Se) = 0.5\n",
      "f1_score = 0.040268454464951836\n",
      "------------ Save best model - AUROC: 0.8853 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:49:44,550 - INFO - Epoch 6 Batch 0: Train Loss = 0.2449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 0: Train Loss = 0.2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:49:58,515 - INFO - Epoch 6 Batch 20: Train Loss = 0.2428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 20: Train Loss = 0.2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:50:12,164 - INFO - Epoch 6 Batch 40: Train Loss = 0.2123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 40: Train Loss = 0.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:50:25,301 - INFO - Epoch 6 Batch 60: Train Loss = 0.2073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 60: Train Loss = 0.2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:50:38,860 - INFO - Epoch 6 Batch 80: Train Loss = 0.3216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 80: Train Loss = 0.3216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:50:52,476 - INFO - Epoch 6 Batch 100: Train Loss = 0.2235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 100: Train Loss = 0.2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:51:06,015 - INFO - Epoch 6 Batch 120: Train Loss = 0.1941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 120: Train Loss = 0.1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:51:16,255 - INFO - Epoch 6: Loss = 0.2114 Valid loss = 0.1864 roc = 0.8846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 0.2114 Valid loss = 0.1864 roc = 0.8846\n",
      "confusion matrix:\n",
      "[[3741    1]\n",
      " [ 274   18]]\n",
      "accuracy = 0.9318294525146484\n",
      "precision class 0 = 0.9317559003829956\n",
      "precision class 1 = 0.9473684430122375\n",
      "recall class 0 = 0.9997327923774719\n",
      "recall class 1 = 0.06164383515715599\n",
      "AUC of ROC = 0.8846452340335181\n",
      "AUC of PRC = 0.5451171029569886\n",
      "min(+P, Se) = 0.5171232876712328\n",
      "f1_score = 0.11575563277438888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:51:16,901 - INFO - Epoch 7 Batch 0: Train Loss = 0.2285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 0: Train Loss = 0.2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:51:30,753 - INFO - Epoch 7 Batch 20: Train Loss = 0.1803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 20: Train Loss = 0.1803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:51:43,456 - INFO - Epoch 7 Batch 40: Train Loss = 0.2132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 40: Train Loss = 0.2132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:51:55,915 - INFO - Epoch 7 Batch 60: Train Loss = 0.1914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 60: Train Loss = 0.1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:52:09,201 - INFO - Epoch 7 Batch 80: Train Loss = 0.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 80: Train Loss = 0.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:52:22,609 - INFO - Epoch 7 Batch 100: Train Loss = 0.2247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 100: Train Loss = 0.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:52:35,315 - INFO - Epoch 7 Batch 120: Train Loss = 0.2422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 120: Train Loss = 0.2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:52:45,129 - INFO - Epoch 7: Loss = 0.2019 Valid loss = 0.1765 roc = 0.9029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 0.2019 Valid loss = 0.1765 roc = 0.9029\n",
      "confusion matrix:\n",
      "[[3741    1]\n",
      " [ 266   26]]\n",
      "accuracy = 0.9338126182556152\n",
      "precision class 0 = 0.9336161613464355\n",
      "precision class 1 = 0.9629629850387573\n",
      "recall class 0 = 0.9997327923774719\n",
      "recall class 1 = 0.0890410989522934\n",
      "AUC of ROC = 0.9028932956517282\n",
      "AUC of PRC = 0.6150689596739772\n",
      "min(+P, Se) = 0.5616438356164384\n",
      "f1_score = 0.16300940752706525\n",
      "------------ Save best model - AUROC: 0.9029 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:52:45,710 - INFO - Epoch 8 Batch 0: Train Loss = 0.2371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 0: Train Loss = 0.2371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:52:59,051 - INFO - Epoch 8 Batch 20: Train Loss = 0.1523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 20: Train Loss = 0.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:53:12,550 - INFO - Epoch 8 Batch 40: Train Loss = 0.1752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 40: Train Loss = 0.1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:53:24,807 - INFO - Epoch 8 Batch 60: Train Loss = 0.1609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 60: Train Loss = 0.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:53:36,952 - INFO - Epoch 8 Batch 80: Train Loss = 0.2099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 80: Train Loss = 0.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:53:50,736 - INFO - Epoch 8 Batch 100: Train Loss = 0.2223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 100: Train Loss = 0.2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:54:04,421 - INFO - Epoch 8 Batch 120: Train Loss = 0.2348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 120: Train Loss = 0.2348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:54:15,805 - INFO - Epoch 8: Loss = 0.1981 Valid loss = 0.1683 roc = 0.9039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 0.1981 Valid loss = 0.1683 roc = 0.9039\n",
      "confusion matrix:\n",
      "[[3735    7]\n",
      " [ 236   56]]\n",
      "accuracy = 0.9397619962692261\n",
      "precision class 0 = 0.9405691027641296\n",
      "precision class 1 = 0.8888888955116272\n",
      "recall class 0 = 0.9981293678283691\n",
      "recall class 1 = 0.19178082048892975\n",
      "AUC of ROC = 0.9039036702957175\n",
      "AUC of PRC = 0.632160011212004\n",
      "min(+P, Se) = 0.6075085324232082\n",
      "f1_score = 0.31549294317934556\n",
      "------------ Save best model - AUROC: 0.9039 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:54:16,706 - INFO - Epoch 9 Batch 0: Train Loss = 0.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 0: Train Loss = 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:54:31,974 - INFO - Epoch 9 Batch 20: Train Loss = 0.2142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 20: Train Loss = 0.2142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:54:46,804 - INFO - Epoch 9 Batch 40: Train Loss = 0.1987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 40: Train Loss = 0.1987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:55:03,288 - INFO - Epoch 9 Batch 60: Train Loss = 0.2035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 60: Train Loss = 0.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:55:17,413 - INFO - Epoch 9 Batch 80: Train Loss = 0.1700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 80: Train Loss = 0.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:55:30,545 - INFO - Epoch 9 Batch 100: Train Loss = 0.1498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 100: Train Loss = 0.1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:55:43,702 - INFO - Epoch 9 Batch 120: Train Loss = 0.1345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 120: Train Loss = 0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:55:53,665 - INFO - Epoch 9: Loss = 0.1932 Valid loss = 0.1725 roc = 0.9011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 0.1932 Valid loss = 0.1725 roc = 0.9011\n",
      "confusion matrix:\n",
      "[[3738    4]\n",
      " [ 246   46]]\n",
      "accuracy = 0.9380267858505249\n",
      "precision class 0 = 0.9382529854774475\n",
      "precision class 1 = 0.9200000166893005\n",
      "recall class 0 = 0.9989310503005981\n",
      "recall class 1 = 0.15753424167633057\n",
      "AUC of ROC = 0.9011397831355294\n",
      "AUC of PRC = 0.6192776417692069\n",
      "min(+P, Se) = 0.5856164383561644\n",
      "f1_score = 0.2690058564043933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:55:54,372 - INFO - Epoch 10 Batch 0: Train Loss = 0.1341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 0: Train Loss = 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:56:09,038 - INFO - Epoch 10 Batch 20: Train Loss = 0.2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 20: Train Loss = 0.2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:56:22,314 - INFO - Epoch 10 Batch 40: Train Loss = 0.1331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 40: Train Loss = 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:56:35,289 - INFO - Epoch 10 Batch 60: Train Loss = 0.2376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 60: Train Loss = 0.2376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:56:47,237 - INFO - Epoch 10 Batch 80: Train Loss = 0.2369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 80: Train Loss = 0.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:56:59,101 - INFO - Epoch 10 Batch 100: Train Loss = 0.1186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 100: Train Loss = 0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:57:11,945 - INFO - Epoch 10 Batch 120: Train Loss = 0.1720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 120: Train Loss = 0.1720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:57:21,754 - INFO - Epoch 10: Loss = 0.1885 Valid loss = 0.1660 roc = 0.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 0.1885 Valid loss = 0.1660 roc = 0.8912\n",
      "confusion matrix:\n",
      "[[3737    5]\n",
      " [ 214   78]]\n",
      "accuracy = 0.9457114338874817\n",
      "precision class 0 = 0.9458364844322205\n",
      "precision class 1 = 0.9397590160369873\n",
      "recall class 0 = 0.9986638426780701\n",
      "recall class 1 = 0.267123281955719\n",
      "AUC of ROC = 0.8911540967763191\n",
      "AUC of PRC = 0.6216152729721999\n",
      "min(+P, Se) = 0.5787671232876712\n",
      "f1_score = 0.4160000116441525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:57:22,442 - INFO - Epoch 11 Batch 0: Train Loss = 0.1261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 0: Train Loss = 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:57:34,638 - INFO - Epoch 11 Batch 20: Train Loss = 0.1907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 20: Train Loss = 0.1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:57:46,888 - INFO - Epoch 11 Batch 40: Train Loss = 0.2247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 40: Train Loss = 0.2247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:57:59,610 - INFO - Epoch 11 Batch 60: Train Loss = 0.1740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 60: Train Loss = 0.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:58:12,564 - INFO - Epoch 11 Batch 80: Train Loss = 0.2186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 80: Train Loss = 0.2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:58:25,825 - INFO - Epoch 11 Batch 100: Train Loss = 0.1970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 100: Train Loss = 0.1970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:58:38,902 - INFO - Epoch 11 Batch 120: Train Loss = 0.1989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 120: Train Loss = 0.1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:58:48,868 - INFO - Epoch 11: Loss = 0.1860 Valid loss = 0.1590 roc = 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss = 0.1860 Valid loss = 0.1590 roc = 0.9053\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 199   93]]\n",
      "accuracy = 0.948438286781311\n",
      "precision class 0 = 0.949389636516571\n",
      "precision class 1 = 0.9117646813392639\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.31849315762519836\n",
      "AUC of ROC = 0.9053341191802786\n",
      "AUC of PRC = 0.639779501464525\n",
      "min(+P, Se) = 0.5836177474402731\n",
      "f1_score = 0.4720812111723599\n",
      "------------ Save best model - AUROC: 0.9053 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:58:49,673 - INFO - Epoch 12 Batch 0: Train Loss = 0.3109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 0: Train Loss = 0.3109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:59:02,730 - INFO - Epoch 12 Batch 20: Train Loss = 0.1454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 20: Train Loss = 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:59:15,760 - INFO - Epoch 12 Batch 40: Train Loss = 0.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 40: Train Loss = 0.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:59:28,255 - INFO - Epoch 12 Batch 60: Train Loss = 0.1977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 60: Train Loss = 0.1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:59:41,833 - INFO - Epoch 12 Batch 80: Train Loss = 0.1376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 80: Train Loss = 0.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 11:59:54,721 - INFO - Epoch 12 Batch 100: Train Loss = 0.1977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 100: Train Loss = 0.1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:00:07,482 - INFO - Epoch 12 Batch 120: Train Loss = 0.1945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 120: Train Loss = 0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:00:17,639 - INFO - Epoch 12: Loss = 0.1865 Valid loss = 0.1610 roc = 0.9019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss = 0.1865 Valid loss = 0.1610 roc = 0.9019\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 204   88]]\n",
      "accuracy = 0.9471988081932068\n",
      "precision class 0 = 0.9481838941574097\n",
      "precision class 1 = 0.907216489315033\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.30136987566947937\n",
      "AUC of ROC = 0.9018820058133149\n",
      "AUC of PRC = 0.6417010707740759\n",
      "min(+P, Se) = 0.587248322147651\n",
      "f1_score = 0.45244218411414994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:00:18,184 - INFO - Epoch 13 Batch 0: Train Loss = 0.2058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 0: Train Loss = 0.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:00:30,707 - INFO - Epoch 13 Batch 20: Train Loss = 0.2137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 20: Train Loss = 0.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:00:43,990 - INFO - Epoch 13 Batch 40: Train Loss = 0.1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 40: Train Loss = 0.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:00:58,249 - INFO - Epoch 13 Batch 60: Train Loss = 0.1794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 60: Train Loss = 0.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:01:11,898 - INFO - Epoch 13 Batch 80: Train Loss = 0.1908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 80: Train Loss = 0.1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:01:25,562 - INFO - Epoch 13 Batch 100: Train Loss = 0.2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 100: Train Loss = 0.2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:01:37,891 - INFO - Epoch 13 Batch 120: Train Loss = 0.2336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 120: Train Loss = 0.2336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:01:47,840 - INFO - Epoch 13: Loss = 0.1940 Valid loss = 0.1618 roc = 0.9073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss = 0.1940 Valid loss = 0.1618 roc = 0.9073\n",
      "confusion matrix:\n",
      "[[3736    6]\n",
      " [ 222   70]]\n",
      "accuracy = 0.9434804320335388\n",
      "precision class 0 = 0.943911075592041\n",
      "precision class 1 = 0.9210526347160339\n",
      "recall class 0 = 0.9983965754508972\n",
      "recall class 1 = 0.2397260218858719\n",
      "AUC of ROC = 0.9073310734132358\n",
      "AUC of PRC = 0.6463891975588211\n",
      "min(+P, Se) = 0.5938566552901023\n",
      "f1_score = 0.3804347808199929\n",
      "------------ Save best model - AUROC: 0.9073 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:01:48,583 - INFO - Epoch 14 Batch 0: Train Loss = 0.1541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 0: Train Loss = 0.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:02:01,441 - INFO - Epoch 14 Batch 20: Train Loss = 0.2563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 20: Train Loss = 0.2563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:02:14,084 - INFO - Epoch 14 Batch 40: Train Loss = 0.2016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 40: Train Loss = 0.2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:02:27,094 - INFO - Epoch 14 Batch 60: Train Loss = 0.2101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 60: Train Loss = 0.2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:02:40,307 - INFO - Epoch 14 Batch 80: Train Loss = 0.1961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 80: Train Loss = 0.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:02:53,602 - INFO - Epoch 14 Batch 100: Train Loss = 0.1995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 100: Train Loss = 0.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:03:06,131 - INFO - Epoch 14 Batch 120: Train Loss = 0.1404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 120: Train Loss = 0.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:03:16,764 - INFO - Epoch 14: Loss = 0.1930 Valid loss = 0.1574 roc = 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss = 0.1930 Valid loss = 0.1574 roc = 0.9111\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 198   94]]\n",
      "accuracy = 0.9486861824989319\n",
      "precision class 0 = 0.9496311545372009\n",
      "precision class 1 = 0.9126213788986206\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.3219178020954132\n",
      "AUC of ROC = 0.9111089959951092\n",
      "AUC of PRC = 0.6577890770292267\n",
      "min(+P, Se) = 0.6061643835616438\n",
      "f1_score = 0.47594937456091546\n",
      "------------ Save best model - AUROC: 0.9111 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:03:17,424 - INFO - Epoch 15 Batch 0: Train Loss = 0.2595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 0: Train Loss = 0.2595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:03:30,441 - INFO - Epoch 15 Batch 20: Train Loss = 0.2258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 20: Train Loss = 0.2258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:03:43,115 - INFO - Epoch 15 Batch 40: Train Loss = 0.2414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 40: Train Loss = 0.2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:03:55,574 - INFO - Epoch 15 Batch 60: Train Loss = 0.2082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 60: Train Loss = 0.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:04:09,028 - INFO - Epoch 15 Batch 80: Train Loss = 0.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 80: Train Loss = 0.1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:04:23,979 - INFO - Epoch 15 Batch 100: Train Loss = 0.2478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 100: Train Loss = 0.2478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:04:39,579 - INFO - Epoch 15 Batch 120: Train Loss = 0.1594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 120: Train Loss = 0.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:04:51,525 - INFO - Epoch 15: Loss = 0.1918 Valid loss = 0.1624 roc = 0.9125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss = 0.1918 Valid loss = 0.1624 roc = 0.9125\n",
      "confusion matrix:\n",
      "[[3737    5]\n",
      " [ 221   71]]\n",
      "accuracy = 0.9439762234687805\n",
      "precision class 0 = 0.9441637396812439\n",
      "precision class 1 = 0.9342105388641357\n",
      "recall class 0 = 0.9986638426780701\n",
      "recall class 1 = 0.24315068125724792\n",
      "AUC of ROC = 0.9125165650190727\n",
      "AUC of PRC = 0.6479334724348089\n",
      "min(+P, Se) = 0.6075085324232082\n",
      "f1_score = 0.38586955189366906\n",
      "------------ Save best model - AUROC: 0.9125 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:04:52,405 - INFO - Epoch 16 Batch 0: Train Loss = 0.2613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 0: Train Loss = 0.2613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:05:08,019 - INFO - Epoch 16 Batch 20: Train Loss = 0.2168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 20: Train Loss = 0.2168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:05:22,146 - INFO - Epoch 16 Batch 40: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 40: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:05:34,587 - INFO - Epoch 16 Batch 60: Train Loss = 0.1643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 60: Train Loss = 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:05:48,007 - INFO - Epoch 16 Batch 80: Train Loss = 0.2665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 80: Train Loss = 0.2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:06:00,523 - INFO - Epoch 16 Batch 100: Train Loss = 0.1348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 100: Train Loss = 0.1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:06:13,169 - INFO - Epoch 16 Batch 120: Train Loss = 0.1934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 120: Train Loss = 0.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:06:23,660 - INFO - Epoch 16: Loss = 0.1921 Valid loss = 0.1576 roc = 0.9090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss = 0.1921 Valid loss = 0.1576 roc = 0.9090\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 199   93]]\n",
      "accuracy = 0.948438286781311\n",
      "precision class 0 = 0.949389636516571\n",
      "precision class 1 = 0.9117646813392639\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.31849315762519836\n",
      "AUC of ROC = 0.9090113703755227\n",
      "AUC of PRC = 0.6550995368021446\n",
      "min(+P, Se) = 0.6061643835616438\n",
      "f1_score = 0.4720812111723599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:06:24,252 - INFO - Epoch 17 Batch 0: Train Loss = 0.1813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 0: Train Loss = 0.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:06:38,731 - INFO - Epoch 17 Batch 20: Train Loss = 0.1758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 20: Train Loss = 0.1758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:06:51,796 - INFO - Epoch 17 Batch 40: Train Loss = 0.1693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 40: Train Loss = 0.1693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:07:04,209 - INFO - Epoch 17 Batch 60: Train Loss = 0.1643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 60: Train Loss = 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:07:15,924 - INFO - Epoch 17 Batch 80: Train Loss = 0.1533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 80: Train Loss = 0.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:07:28,784 - INFO - Epoch 17 Batch 100: Train Loss = 0.2085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 100: Train Loss = 0.2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:07:41,722 - INFO - Epoch 17 Batch 120: Train Loss = 0.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 120: Train Loss = 0.2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:07:51,563 - INFO - Epoch 17: Loss = 0.1916 Valid loss = 0.1586 roc = 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss = 0.1916 Valid loss = 0.1586 roc = 0.9074\n",
      "confusion matrix:\n",
      "[[3734    8]\n",
      " [ 201   91]]\n",
      "accuracy = 0.9481903910636902\n",
      "precision class 0 = 0.948919951915741\n",
      "precision class 1 = 0.9191918969154358\n",
      "recall class 0 = 0.9978621006011963\n",
      "recall class 1 = 0.3116438388824463\n",
      "AUC of ROC = 0.9073676811901921\n",
      "AUC of PRC = 0.6470860305745173\n",
      "min(+P, Se) = 0.5938566552901023\n",
      "f1_score = 0.4654731691078978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:07:52,016 - INFO - Epoch 18 Batch 0: Train Loss = 0.2329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 0: Train Loss = 0.2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:08:04,562 - INFO - Epoch 18 Batch 20: Train Loss = 0.2777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 20: Train Loss = 0.2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:08:18,373 - INFO - Epoch 18 Batch 40: Train Loss = 0.1320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 40: Train Loss = 0.1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:08:30,293 - INFO - Epoch 18 Batch 60: Train Loss = 0.1897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 60: Train Loss = 0.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:08:42,706 - INFO - Epoch 18 Batch 80: Train Loss = 0.1385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 80: Train Loss = 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:08:55,962 - INFO - Epoch 18 Batch 100: Train Loss = 0.1755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 100: Train Loss = 0.1755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:09:09,065 - INFO - Epoch 18 Batch 120: Train Loss = 0.1679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 120: Train Loss = 0.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:09:18,968 - INFO - Epoch 18: Loss = 0.1863 Valid loss = 0.1590 roc = 0.9101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss = 0.1863 Valid loss = 0.1590 roc = 0.9101\n",
      "confusion matrix:\n",
      "[[3735    7]\n",
      " [ 212   80]]\n",
      "accuracy = 0.9457114338874817\n",
      "precision class 0 = 0.9462883472442627\n",
      "precision class 1 = 0.9195402264595032\n",
      "recall class 0 = 0.9981293678283691\n",
      "recall class 1 = 0.27397260069847107\n",
      "AUC of ROC = 0.9101031973232394\n",
      "AUC of PRC = 0.6500850415287236\n",
      "min(+P, Se) = 0.5993150684931506\n",
      "f1_score = 0.4221635961476825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:09:19,470 - INFO - Epoch 19 Batch 0: Train Loss = 0.1713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 0: Train Loss = 0.1713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:09:32,589 - INFO - Epoch 19 Batch 20: Train Loss = 0.1965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 20: Train Loss = 0.1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:09:45,145 - INFO - Epoch 19 Batch 40: Train Loss = 0.2154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 40: Train Loss = 0.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:09:59,001 - INFO - Epoch 19 Batch 60: Train Loss = 0.1909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 60: Train Loss = 0.1909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:10:14,162 - INFO - Epoch 19 Batch 80: Train Loss = 0.2065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 80: Train Loss = 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:10:28,843 - INFO - Epoch 19 Batch 100: Train Loss = 0.2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 100: Train Loss = 0.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:10:43,442 - INFO - Epoch 19 Batch 120: Train Loss = 0.2421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 120: Train Loss = 0.2421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:10:54,738 - INFO - Epoch 19: Loss = 0.1849 Valid loss = 0.1556 roc = 0.9099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss = 0.1849 Valid loss = 0.1556 roc = 0.9099\n",
      "confusion matrix:\n",
      "[[3732   10]\n",
      " [ 191  101]]\n",
      "accuracy = 0.9501734972000122\n",
      "precision class 0 = 0.951312780380249\n",
      "precision class 1 = 0.9099099040031433\n",
      "recall class 0 = 0.9973276257514954\n",
      "recall class 1 = 0.3458904027938843\n",
      "AUC of ROC = 0.9098835506615025\n",
      "AUC of PRC = 0.6474462510868402\n",
      "min(+P, Se) = 0.590443686006826\n",
      "f1_score = 0.501240709110287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:10:55,538 - INFO - Epoch 20 Batch 0: Train Loss = 0.1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 0: Train Loss = 0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:11:09,522 - INFO - Epoch 20 Batch 20: Train Loss = 0.2116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 20: Train Loss = 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:11:23,471 - INFO - Epoch 20 Batch 40: Train Loss = 0.1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 40: Train Loss = 0.1445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:11:38,135 - INFO - Epoch 20 Batch 60: Train Loss = 0.2213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 60: Train Loss = 0.2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:11:53,035 - INFO - Epoch 20 Batch 80: Train Loss = 0.1932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 80: Train Loss = 0.1932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:12:07,428 - INFO - Epoch 20 Batch 100: Train Loss = 0.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 100: Train Loss = 0.1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:12:21,511 - INFO - Epoch 20 Batch 120: Train Loss = 0.1407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 120: Train Loss = 0.1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:12:32,043 - INFO - Epoch 20: Loss = 0.1844 Valid loss = 0.1595 roc = 0.9112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss = 0.1844 Valid loss = 0.1595 roc = 0.9112\n",
      "confusion matrix:\n",
      "[[3736    6]\n",
      " [ 207   85]]\n",
      "accuracy = 0.9471988081932068\n",
      "precision class 0 = 0.9475018978118896\n",
      "precision class 1 = 0.9340659379959106\n",
      "recall class 0 = 0.9983965754508972\n",
      "recall class 1 = 0.29109588265419006\n",
      "AUC of ROC = 0.9111730596047822\n",
      "AUC of PRC = 0.6516298396866008\n",
      "min(+P, Se) = 0.5938566552901023\n",
      "f1_score = 0.4438642319884696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:12:32,656 - INFO - Epoch 21 Batch 0: Train Loss = 0.1671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 0: Train Loss = 0.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:12:46,464 - INFO - Epoch 21 Batch 20: Train Loss = 0.2223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 20: Train Loss = 0.2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:13:00,397 - INFO - Epoch 21 Batch 40: Train Loss = 0.1499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 40: Train Loss = 0.1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:13:13,557 - INFO - Epoch 21 Batch 60: Train Loss = 0.1695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 60: Train Loss = 0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:13:26,612 - INFO - Epoch 21 Batch 80: Train Loss = 0.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 80: Train Loss = 0.1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:13:40,471 - INFO - Epoch 21 Batch 100: Train Loss = 0.1451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 100: Train Loss = 0.1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:13:53,687 - INFO - Epoch 21 Batch 120: Train Loss = 0.2684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 120: Train Loss = 0.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:14:04,295 - INFO - Epoch 21: Loss = 0.1837 Valid loss = 0.1554 roc = 0.9081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Loss = 0.1837 Valid loss = 0.1554 roc = 0.9081\n",
      "confusion matrix:\n",
      "[[3730   12]\n",
      " [ 186  106]]\n",
      "accuracy = 0.9509171843528748\n",
      "precision class 0 = 0.9525025486946106\n",
      "precision class 1 = 0.8983050584793091\n",
      "recall class 0 = 0.9967931509017944\n",
      "recall class 1 = 0.36301368474960327\n",
      "AUC of ROC = 0.9080742112854454\n",
      "AUC of PRC = 0.6514984799910307\n",
      "min(+P, Se) = 0.5856164383561644\n",
      "f1_score = 0.5170731767340131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:14:04,895 - INFO - Epoch 22 Batch 0: Train Loss = 0.2226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 0: Train Loss = 0.2226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:14:18,269 - INFO - Epoch 22 Batch 20: Train Loss = 0.2353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 20: Train Loss = 0.2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:14:32,166 - INFO - Epoch 22 Batch 40: Train Loss = 0.1256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 40: Train Loss = 0.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:14:46,111 - INFO - Epoch 22 Batch 60: Train Loss = 0.1670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 60: Train Loss = 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:14:59,523 - INFO - Epoch 22 Batch 80: Train Loss = 0.1866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 80: Train Loss = 0.1866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:15:13,325 - INFO - Epoch 22 Batch 100: Train Loss = 0.1613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 100: Train Loss = 0.1613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:15:27,802 - INFO - Epoch 22 Batch 120: Train Loss = 0.1813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 120: Train Loss = 0.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:15:39,034 - INFO - Epoch 22: Loss = 0.1846 Valid loss = 0.1550 roc = 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Loss = 0.1846 Valid loss = 0.1550 roc = 0.9130\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 193   99]]\n",
      "accuracy = 0.9499256610870361\n",
      "precision class 0 = 0.9508405327796936\n",
      "precision class 1 = 0.9166666865348816\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.3390410840511322\n",
      "AUC of ROC = 0.9130190067577957\n",
      "AUC of PRC = 0.6630195785035872\n",
      "min(+P, Se) = 0.6075085324232082\n",
      "f1_score = 0.4950000020265576\n",
      "------------ Save best model - AUROC: 0.9130 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:15:39,955 - INFO - Epoch 23 Batch 0: Train Loss = 0.1993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 0: Train Loss = 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:15:55,149 - INFO - Epoch 23 Batch 20: Train Loss = 0.2041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 20: Train Loss = 0.2041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:16:08,715 - INFO - Epoch 23 Batch 40: Train Loss = 0.1823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 40: Train Loss = 0.1823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:16:22,593 - INFO - Epoch 23 Batch 60: Train Loss = 0.2057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 60: Train Loss = 0.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:16:36,830 - INFO - Epoch 23 Batch 80: Train Loss = 0.2710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 80: Train Loss = 0.2710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:16:49,721 - INFO - Epoch 23 Batch 100: Train Loss = 0.2262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 100: Train Loss = 0.2262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:17:03,031 - INFO - Epoch 23 Batch 120: Train Loss = 0.1497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 120: Train Loss = 0.1497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:17:13,916 - INFO - Epoch 23: Loss = 0.1828 Valid loss = 0.1584 roc = 0.9078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Loss = 0.1828 Valid loss = 0.1584 roc = 0.9078\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 204   88]]\n",
      "accuracy = 0.9471988081932068\n",
      "precision class 0 = 0.9481838941574097\n",
      "precision class 1 = 0.907216489315033\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.30136987566947937\n",
      "AUC of ROC = 0.9077786034865246\n",
      "AUC of PRC = 0.6483881383624795\n",
      "min(+P, Se) = 0.5972696245733788\n",
      "f1_score = 0.45244218411414994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:17:14,531 - INFO - Epoch 24 Batch 0: Train Loss = 0.1743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 0: Train Loss = 0.1743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:17:28,924 - INFO - Epoch 24 Batch 20: Train Loss = 0.1444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 20: Train Loss = 0.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:17:43,007 - INFO - Epoch 24 Batch 40: Train Loss = 0.1735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 40: Train Loss = 0.1735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:17:58,487 - INFO - Epoch 24 Batch 60: Train Loss = 0.2271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 60: Train Loss = 0.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:18:13,783 - INFO - Epoch 24 Batch 80: Train Loss = 0.2426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 80: Train Loss = 0.2426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:18:27,378 - INFO - Epoch 24 Batch 100: Train Loss = 0.2060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 100: Train Loss = 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:18:40,986 - INFO - Epoch 24 Batch 120: Train Loss = 0.1841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 120: Train Loss = 0.1841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:18:51,688 - INFO - Epoch 24: Loss = 0.1805 Valid loss = 0.1523 roc = 0.9169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Loss = 0.1805 Valid loss = 0.1523 roc = 0.9169\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 189  103]]\n",
      "accuracy = 0.9509171843528748\n",
      "precision class 0 = 0.9518103003501892\n",
      "precision class 1 = 0.9196428656578064\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.35273972153663635\n",
      "AUC of ROC = 0.9169159046147762\n",
      "AUC of PRC = 0.6676567948399078\n",
      "min(+P, Se) = 0.6006825938566553\n",
      "f1_score = 0.5099009747727694\n",
      "------------ Save best model - AUROC: 0.9169 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:18:52,814 - INFO - Epoch 25 Batch 0: Train Loss = 0.1738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 0: Train Loss = 0.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:19:06,117 - INFO - Epoch 25 Batch 20: Train Loss = 0.2032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 20: Train Loss = 0.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:19:20,867 - INFO - Epoch 25 Batch 40: Train Loss = 0.1768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 40: Train Loss = 0.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:19:34,715 - INFO - Epoch 25 Batch 60: Train Loss = 0.1730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 60: Train Loss = 0.1730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:19:49,241 - INFO - Epoch 25 Batch 80: Train Loss = 0.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 80: Train Loss = 0.2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:20:03,350 - INFO - Epoch 25 Batch 100: Train Loss = 0.1957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 100: Train Loss = 0.1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:20:16,674 - INFO - Epoch 25 Batch 120: Train Loss = 0.1453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 120: Train Loss = 0.1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:20:27,015 - INFO - Epoch 25: Loss = 0.1841 Valid loss = 0.1542 roc = 0.9115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Loss = 0.1841 Valid loss = 0.1542 roc = 0.9115\n",
      "confusion matrix:\n",
      "[[3734    8]\n",
      " [ 196   96]]\n",
      "accuracy = 0.9494298696517944\n",
      "precision class 0 = 0.9501272439956665\n",
      "precision class 1 = 0.9230769276618958\n",
      "recall class 0 = 0.9978621006011963\n",
      "recall class 1 = 0.3287671208381653\n",
      "AUC of ROC = 0.9115171727081701\n",
      "AUC of PRC = 0.6737898751249679\n",
      "min(+P, Se) = 0.5933333333333334\n",
      "f1_score = 0.4848484828172685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:20:27,717 - INFO - Epoch 26 Batch 0: Train Loss = 0.1741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 0: Train Loss = 0.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:20:41,567 - INFO - Epoch 26 Batch 20: Train Loss = 0.1477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 20: Train Loss = 0.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:20:55,729 - INFO - Epoch 26 Batch 40: Train Loss = 0.1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 40: Train Loss = 0.1583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:21:09,397 - INFO - Epoch 26 Batch 60: Train Loss = 0.1650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 60: Train Loss = 0.1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:21:23,365 - INFO - Epoch 26 Batch 80: Train Loss = 0.2349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 80: Train Loss = 0.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:21:36,814 - INFO - Epoch 26 Batch 100: Train Loss = 0.1916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 100: Train Loss = 0.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:21:51,066 - INFO - Epoch 26 Batch 120: Train Loss = 0.1982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 120: Train Loss = 0.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:22:01,619 - INFO - Epoch 26: Loss = 0.1822 Valid loss = 0.1516 roc = 0.9128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Loss = 0.1822 Valid loss = 0.1516 roc = 0.9128\n",
      "confusion matrix:\n",
      "[[3725   17]\n",
      " [ 178  114]]\n",
      "accuracy = 0.9516608715057373\n",
      "precision class 0 = 0.9543940424919128\n",
      "precision class 1 = 0.8702290058135986\n",
      "recall class 0 = 0.9954569935798645\n",
      "recall class 1 = 0.3904109597206116\n",
      "AUC of ROC = 0.9128496957893736\n",
      "AUC of PRC = 0.6700941335504434\n",
      "min(+P, Se) = 0.6061643835616438\n",
      "f1_score = 0.539007118112574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:22:02,372 - INFO - Epoch 27 Batch 0: Train Loss = 0.1590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 0: Train Loss = 0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:22:16,354 - INFO - Epoch 27 Batch 20: Train Loss = 0.1885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 20: Train Loss = 0.1885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:22:30,710 - INFO - Epoch 27 Batch 40: Train Loss = 0.1729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 40: Train Loss = 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:22:44,866 - INFO - Epoch 27 Batch 60: Train Loss = 0.1401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 60: Train Loss = 0.1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:22:58,525 - INFO - Epoch 27 Batch 80: Train Loss = 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 80: Train Loss = 0.2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:23:12,559 - INFO - Epoch 27 Batch 100: Train Loss = 0.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 100: Train Loss = 0.1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:23:26,895 - INFO - Epoch 27 Batch 120: Train Loss = 0.1845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 120: Train Loss = 0.1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:23:37,289 - INFO - Epoch 27: Loss = 0.1821 Valid loss = 0.1516 roc = 0.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Loss = 0.1821 Valid loss = 0.1516 roc = 0.9153\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 183  109]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9532686471939087\n",
      "precision class 1 = 0.9237288236618042\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.3732876777648926\n",
      "AUC of ROC = 0.9153069928175541\n",
      "AUC of PRC = 0.6742907338583114\n",
      "min(+P, Se) = 0.6027397260273972\n",
      "f1_score = 0.5317073253731441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:23:38,283 - INFO - Epoch 28 Batch 0: Train Loss = 0.1861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 0: Train Loss = 0.1861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:23:52,963 - INFO - Epoch 28 Batch 20: Train Loss = 0.0862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 20: Train Loss = 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:24:06,023 - INFO - Epoch 28 Batch 40: Train Loss = 0.1870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 40: Train Loss = 0.1870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:24:19,721 - INFO - Epoch 28 Batch 60: Train Loss = 0.1750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 60: Train Loss = 0.1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:24:33,000 - INFO - Epoch 28 Batch 80: Train Loss = 0.2891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 80: Train Loss = 0.2891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:24:46,367 - INFO - Epoch 28 Batch 100: Train Loss = 0.1972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 100: Train Loss = 0.1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:25:01,546 - INFO - Epoch 28 Batch 120: Train Loss = 0.1711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 120: Train Loss = 0.1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:25:11,641 - INFO - Epoch 28: Loss = 0.1757 Valid loss = 0.1483 roc = 0.9125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Loss = 0.1757 Valid loss = 0.1483 roc = 0.9125\n",
      "confusion matrix:\n",
      "[[3729   13]\n",
      " [ 171  121]]\n",
      "accuracy = 0.9543877243995667\n",
      "precision class 0 = 0.9561538696289062\n",
      "precision class 1 = 0.9029850959777832\n",
      "recall class 0 = 0.9965259432792664\n",
      "recall class 1 = 0.41438356041908264\n",
      "AUC of ROC = 0.912542190462942\n",
      "AUC of PRC = 0.6809644767906241\n",
      "min(+P, Se) = 0.613013698630137\n",
      "f1_score = 0.5680751332964691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:25:12,249 - INFO - Epoch 29 Batch 0: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 0: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:25:25,070 - INFO - Epoch 29 Batch 20: Train Loss = 0.2363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 20: Train Loss = 0.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:25:38,589 - INFO - Epoch 29 Batch 40: Train Loss = 0.2268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 40: Train Loss = 0.2268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:25:52,636 - INFO - Epoch 29 Batch 60: Train Loss = 0.1830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 60: Train Loss = 0.1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:26:07,083 - INFO - Epoch 29 Batch 80: Train Loss = 0.1871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 80: Train Loss = 0.1871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:26:20,722 - INFO - Epoch 29 Batch 100: Train Loss = 0.1116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 100: Train Loss = 0.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:26:34,785 - INFO - Epoch 29 Batch 120: Train Loss = 0.1486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 120: Train Loss = 0.1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:26:45,373 - INFO - Epoch 29: Loss = 0.1755 Valid loss = 0.1515 roc = 0.9119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Loss = 0.1755 Valid loss = 0.1515 roc = 0.9119\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 178  114]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9544873237609863\n",
      "precision class 1 = 0.9268292784690857\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.3904109597206116\n",
      "AUC of ROC = 0.9118631162004056\n",
      "AUC of PRC = 0.6712611897871588\n",
      "min(+P, Se) = 0.6075085324232082\n",
      "f1_score = 0.5493975929577822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:26:46,119 - INFO - Epoch 30 Batch 0: Train Loss = 0.1761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 0: Train Loss = 0.1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:26:59,829 - INFO - Epoch 30 Batch 20: Train Loss = 0.1897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 20: Train Loss = 0.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:27:13,674 - INFO - Epoch 30 Batch 40: Train Loss = 0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 40: Train Loss = 0.1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:27:27,869 - INFO - Epoch 30 Batch 60: Train Loss = 0.1251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 60: Train Loss = 0.1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:27:42,338 - INFO - Epoch 30 Batch 80: Train Loss = 0.2020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 80: Train Loss = 0.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:27:56,362 - INFO - Epoch 30 Batch 100: Train Loss = 0.1817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 100: Train Loss = 0.1817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:28:10,529 - INFO - Epoch 30 Batch 120: Train Loss = 0.1841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 120: Train Loss = 0.1841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:28:21,108 - INFO - Epoch 30: Loss = 0.1749 Valid loss = 0.1535 roc = 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss = 0.1749 Valid loss = 0.1535 roc = 0.9057\n",
      "confusion matrix:\n",
      "[[3733    9]\n",
      " [ 188  104]]\n",
      "accuracy = 0.9511650800704956\n",
      "precision class 0 = 0.9520530700683594\n",
      "precision class 1 = 0.9203540086746216\n",
      "recall class 0 = 0.9975948929786682\n",
      "recall class 1 = 0.3561643958091736\n",
      "AUC of ROC = 0.9056764018948186\n",
      "AUC of PRC = 0.660082783319882\n",
      "min(+P, Se) = 0.6109215017064846\n",
      "f1_score = 0.513580287733633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:28:21,639 - INFO - Epoch 31 Batch 0: Train Loss = 0.2152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 0: Train Loss = 0.2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:28:34,917 - INFO - Epoch 31 Batch 20: Train Loss = 0.2044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 20: Train Loss = 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:28:49,592 - INFO - Epoch 31 Batch 40: Train Loss = 0.1927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 40: Train Loss = 0.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:29:04,185 - INFO - Epoch 31 Batch 60: Train Loss = 0.1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 60: Train Loss = 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:29:19,030 - INFO - Epoch 31 Batch 80: Train Loss = 0.1396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 80: Train Loss = 0.1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:29:33,083 - INFO - Epoch 31 Batch 100: Train Loss = 0.1996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 100: Train Loss = 0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:29:47,149 - INFO - Epoch 31 Batch 120: Train Loss = 0.0999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 120: Train Loss = 0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:29:57,433 - INFO - Epoch 31: Loss = 0.1726 Valid loss = 0.1491 roc = 0.9119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Loss = 0.1726 Valid loss = 0.1491 roc = 0.9119\n",
      "confusion matrix:\n",
      "[[3728   14]\n",
      " [ 173  119]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9556524157524109\n",
      "precision class 1 = 0.8947368264198303\n",
      "recall class 0 = 0.9962586760520935\n",
      "recall class 1 = 0.40753424167633057\n",
      "AUC of ROC = 0.9119491444762525\n",
      "AUC of PRC = 0.6720548575305457\n",
      "min(+P, Se) = 0.6027397260273972\n",
      "f1_score = 0.5599999666715587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:29:58,111 - INFO - Epoch 32 Batch 0: Train Loss = 0.1374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 0: Train Loss = 0.1374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:30:12,147 - INFO - Epoch 32 Batch 20: Train Loss = 0.1629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 20: Train Loss = 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:30:25,794 - INFO - Epoch 32 Batch 40: Train Loss = 0.1501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 40: Train Loss = 0.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:30:39,550 - INFO - Epoch 32 Batch 60: Train Loss = 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 60: Train Loss = 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:30:53,196 - INFO - Epoch 32 Batch 80: Train Loss = 0.2318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 80: Train Loss = 0.2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:31:06,644 - INFO - Epoch 32 Batch 100: Train Loss = 0.1532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 100: Train Loss = 0.1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:31:20,996 - INFO - Epoch 32 Batch 120: Train Loss = 0.1526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 120: Train Loss = 0.1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:31:31,625 - INFO - Epoch 32: Loss = 0.1736 Valid loss = 0.1493 roc = 0.9107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Loss = 0.1736 Valid loss = 0.1493 roc = 0.9107\n",
      "confusion matrix:\n",
      "[[3730   12]\n",
      " [ 174  118]]\n",
      "accuracy = 0.953891932964325\n",
      "precision class 0 = 0.9554303288459778\n",
      "precision class 1 = 0.9076923131942749\n",
      "recall class 0 = 0.9967931509017944\n",
      "recall class 1 = 0.4041095972061157\n",
      "AUC of ROC = 0.9106788546158746\n",
      "AUC of PRC = 0.6718340319675404\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.559241715023983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:31:32,316 - INFO - Epoch 33 Batch 0: Train Loss = 0.0973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 0: Train Loss = 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:31:46,212 - INFO - Epoch 33 Batch 20: Train Loss = 0.1705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 20: Train Loss = 0.1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:31:59,871 - INFO - Epoch 33 Batch 40: Train Loss = 0.1479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 40: Train Loss = 0.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:32:14,327 - INFO - Epoch 33 Batch 60: Train Loss = 0.2133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 60: Train Loss = 0.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:32:28,358 - INFO - Epoch 33 Batch 80: Train Loss = 0.1973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 80: Train Loss = 0.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:32:42,642 - INFO - Epoch 33 Batch 100: Train Loss = 0.1546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 100: Train Loss = 0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:32:56,729 - INFO - Epoch 33 Batch 120: Train Loss = 0.1689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 120: Train Loss = 0.1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:33:07,288 - INFO - Epoch 33: Loss = 0.1731 Valid loss = 0.1502 roc = 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Loss = 0.1731 Valid loss = 0.1502 roc = 0.9149\n",
      "confusion matrix:\n",
      "[[3730   12]\n",
      " [ 180  112]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9539641737937927\n",
      "precision class 1 = 0.9032257795333862\n",
      "recall class 0 = 0.9967931509017944\n",
      "recall class 1 = 0.3835616409778595\n",
      "AUC of ROC = 0.9149015616877649\n",
      "AUC of PRC = 0.6691886470296857\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.5384615433330723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:33:08,193 - INFO - Epoch 34 Batch 0: Train Loss = 0.1262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 0: Train Loss = 0.1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:33:22,177 - INFO - Epoch 34 Batch 20: Train Loss = 0.2572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 20: Train Loss = 0.2572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:33:35,853 - INFO - Epoch 34 Batch 40: Train Loss = 0.0931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 40: Train Loss = 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:33:49,655 - INFO - Epoch 34 Batch 60: Train Loss = 0.1724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 60: Train Loss = 0.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:34:03,210 - INFO - Epoch 34 Batch 80: Train Loss = 0.1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 80: Train Loss = 0.1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:34:16,446 - INFO - Epoch 34 Batch 100: Train Loss = 0.1487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 100: Train Loss = 0.1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:34:30,713 - INFO - Epoch 34 Batch 120: Train Loss = 0.1317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 120: Train Loss = 0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:34:41,705 - INFO - Epoch 34: Loss = 0.1697 Valid loss = 0.1472 roc = 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Loss = 0.1697 Valid loss = 0.1472 roc = 0.9157\n",
      "confusion matrix:\n",
      "[[3726   16]\n",
      " [ 167  125]]\n",
      "accuracy = 0.9546356201171875\n",
      "precision class 0 = 0.9571024775505066\n",
      "precision class 1 = 0.8865247964859009\n",
      "recall class 0 = 0.9957242012023926\n",
      "recall class 1 = 0.4280821979045868\n",
      "AUC of ROC = 0.9156529363097896\n",
      "AUC of PRC = 0.6770287612428932\n",
      "min(+P, Se) = 0.6109215017064846\n",
      "f1_score = 0.5773671924651755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:34:42,365 - INFO - Epoch 35 Batch 0: Train Loss = 0.1578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 0: Train Loss = 0.1578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:34:56,545 - INFO - Epoch 35 Batch 20: Train Loss = 0.1818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 20: Train Loss = 0.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:35:11,129 - INFO - Epoch 35 Batch 40: Train Loss = 0.2183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 40: Train Loss = 0.2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:35:25,192 - INFO - Epoch 35 Batch 60: Train Loss = 0.1532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 60: Train Loss = 0.1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:35:39,288 - INFO - Epoch 35 Batch 80: Train Loss = 0.1388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 80: Train Loss = 0.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:35:53,118 - INFO - Epoch 35 Batch 100: Train Loss = 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 100: Train Loss = 0.1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:36:06,939 - INFO - Epoch 35 Batch 120: Train Loss = 0.1874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 120: Train Loss = 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:36:18,472 - INFO - Epoch 35: Loss = 0.1707 Valid loss = 0.1482 roc = 0.9144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Loss = 0.1707 Valid loss = 0.1482 roc = 0.9144\n",
      "confusion matrix:\n",
      "[[3728   14]\n",
      " [ 169  123]]\n",
      "accuracy = 0.9546356201171875\n",
      "precision class 0 = 0.9566333293914795\n",
      "precision class 1 = 0.8978102207183838\n",
      "recall class 0 = 0.9962586760520935\n",
      "recall class 1 = 0.4212328791618347\n",
      "AUC of ROC = 0.9144174238375201\n",
      "AUC of PRC = 0.6726620132555502\n",
      "min(+P, Se) = 0.6203389830508474\n",
      "f1_score = 0.573426550139305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:36:19,318 - INFO - Epoch 36 Batch 0: Train Loss = 0.0789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 0: Train Loss = 0.0789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:36:33,588 - INFO - Epoch 36 Batch 20: Train Loss = 0.2401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 20: Train Loss = 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:36:47,308 - INFO - Epoch 36 Batch 40: Train Loss = 0.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 40: Train Loss = 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:37:00,601 - INFO - Epoch 36 Batch 60: Train Loss = 0.1952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 60: Train Loss = 0.1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:37:14,306 - INFO - Epoch 36 Batch 80: Train Loss = 0.2365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 80: Train Loss = 0.2365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:37:28,353 - INFO - Epoch 36 Batch 100: Train Loss = 0.1492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 100: Train Loss = 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:37:42,673 - INFO - Epoch 36 Batch 120: Train Loss = 0.2077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 120: Train Loss = 0.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:37:54,270 - INFO - Epoch 36: Loss = 0.1713 Valid loss = 0.1481 roc = 0.9154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Loss = 0.1713 Valid loss = 0.1481 roc = 0.9154\n",
      "confusion matrix:\n",
      "[[3725   17]\n",
      " [ 169  123]]\n",
      "accuracy = 0.953891932964325\n",
      "precision class 0 = 0.9565998911857605\n",
      "precision class 1 = 0.8785714507102966\n",
      "recall class 0 = 0.9954569935798645\n",
      "recall class 1 = 0.4212328791618347\n",
      "AUC of ROC = 0.9154232225093899\n",
      "AUC of PRC = 0.6775044745801495\n",
      "min(+P, Se) = 0.6198630136986302\n",
      "f1_score = 0.5694444513329099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:37:54,993 - INFO - Epoch 37 Batch 0: Train Loss = 0.1678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 0: Train Loss = 0.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:38:09,925 - INFO - Epoch 37 Batch 20: Train Loss = 0.1279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 20: Train Loss = 0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:38:23,341 - INFO - Epoch 37 Batch 40: Train Loss = 0.1259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 40: Train Loss = 0.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:38:37,064 - INFO - Epoch 37 Batch 60: Train Loss = 0.1768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 60: Train Loss = 0.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:38:51,171 - INFO - Epoch 37 Batch 80: Train Loss = 0.2601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 80: Train Loss = 0.2601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:39:05,499 - INFO - Epoch 37 Batch 100: Train Loss = 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 100: Train Loss = 0.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:39:18,975 - INFO - Epoch 37 Batch 120: Train Loss = 0.1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 120: Train Loss = 0.1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:39:29,494 - INFO - Epoch 37: Loss = 0.1686 Valid loss = 0.1454 roc = 0.9131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Loss = 0.1686 Valid loss = 0.1454 roc = 0.9131\n",
      "confusion matrix:\n",
      "[[3724   18]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9556271433830261\n",
      "precision class 0 = 0.9585585594177246\n",
      "precision class 1 = 0.8791946172714233\n",
      "recall class 0 = 0.9951897263526917\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.9131233389221206\n",
      "AUC of PRC = 0.6781892313866236\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.59410430752207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:39:30,142 - INFO - Epoch 38 Batch 0: Train Loss = 0.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 0: Train Loss = 0.1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:39:43,636 - INFO - Epoch 38 Batch 20: Train Loss = 0.2368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 20: Train Loss = 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:39:56,309 - INFO - Epoch 38 Batch 40: Train Loss = 0.1205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 40: Train Loss = 0.1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:40:10,547 - INFO - Epoch 38 Batch 60: Train Loss = 0.1775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 60: Train Loss = 0.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:40:25,215 - INFO - Epoch 38 Batch 80: Train Loss = 0.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 80: Train Loss = 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:40:38,497 - INFO - Epoch 38 Batch 100: Train Loss = 0.1705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 100: Train Loss = 0.1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:40:52,359 - INFO - Epoch 38 Batch 120: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 120: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:41:03,249 - INFO - Epoch 38: Loss = 0.1697 Valid loss = 0.1458 roc = 0.9129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Loss = 0.1697 Valid loss = 0.1458 roc = 0.9129\n",
      "confusion matrix:\n",
      "[[3722   20]\n",
      " [ 164  128]]\n",
      "accuracy = 0.9543877243995667\n",
      "precision class 0 = 0.9577972292900085\n",
      "precision class 1 = 0.8648648858070374\n",
      "recall class 0 = 0.9946552515029907\n",
      "recall class 1 = 0.4383561611175537\n",
      "AUC of ROC = 0.9129270297181934\n",
      "AUC of PRC = 0.6731352588503088\n",
      "min(+P, Se) = 0.621160409556314\n",
      "f1_score = 0.581818210290484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:41:03,931 - INFO - Epoch 39 Batch 0: Train Loss = 0.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 0: Train Loss = 0.1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:41:18,073 - INFO - Epoch 39 Batch 20: Train Loss = 0.1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 20: Train Loss = 0.1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:41:31,121 - INFO - Epoch 39 Batch 40: Train Loss = 0.1552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 40: Train Loss = 0.1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:41:44,225 - INFO - Epoch 39 Batch 60: Train Loss = 0.1470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 60: Train Loss = 0.1470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:41:57,892 - INFO - Epoch 39 Batch 80: Train Loss = 0.1773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 80: Train Loss = 0.1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:42:11,015 - INFO - Epoch 39 Batch 100: Train Loss = 0.1657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 100: Train Loss = 0.1657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:42:24,432 - INFO - Epoch 39 Batch 120: Train Loss = 0.2029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 120: Train Loss = 0.2029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:42:34,283 - INFO - Epoch 39: Loss = 0.1706 Valid loss = 0.1465 roc = 0.9147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Loss = 0.1706 Valid loss = 0.1465 roc = 0.9147\n",
      "confusion matrix:\n",
      "[[3723   19]\n",
      " [ 165  127]]\n",
      "accuracy = 0.9543877243995667\n",
      "precision class 0 = 0.957561731338501\n",
      "precision class 1 = 0.8698630332946777\n",
      "recall class 0 = 0.9949225187301636\n",
      "recall class 1 = 0.43493151664733887\n",
      "AUC of ROC = 0.9146993037200822\n",
      "AUC of PRC = 0.6749568964221069\n",
      "min(+P, Se) = 0.613013698630137\n",
      "f1_score = 0.5799086888631185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:42:35,067 - INFO - Epoch 40 Batch 0: Train Loss = 0.1540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 0: Train Loss = 0.1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:42:48,257 - INFO - Epoch 40 Batch 20: Train Loss = 0.1285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 20: Train Loss = 0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:43:01,066 - INFO - Epoch 40 Batch 40: Train Loss = 0.1329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 40: Train Loss = 0.1329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:43:14,119 - INFO - Epoch 40 Batch 60: Train Loss = 0.1737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 60: Train Loss = 0.1737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:43:27,963 - INFO - Epoch 40 Batch 80: Train Loss = 0.1205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 80: Train Loss = 0.1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:43:41,959 - INFO - Epoch 40 Batch 100: Train Loss = 0.1452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 100: Train Loss = 0.1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:43:55,598 - INFO - Epoch 40 Batch 120: Train Loss = 0.1582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 120: Train Loss = 0.1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:44:05,998 - INFO - Epoch 40: Loss = 0.1707 Valid loss = 0.1478 roc = 0.9169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Loss = 0.1707 Valid loss = 0.1478 roc = 0.9169\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 170  122]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.95630943775177\n",
      "precision class 1 = 0.8531468510627747\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.4178082048892975\n",
      "AUC of ROC = 0.9169332933088306\n",
      "AUC of PRC = 0.6714410964228154\n",
      "min(+P, Se) = 0.6114864864864865\n",
      "f1_score = 0.5609195137496419\n",
      "------------ Save best model - AUROC: 0.9169 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:44:06,791 - INFO - Epoch 41 Batch 0: Train Loss = 0.2057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 0: Train Loss = 0.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:44:20,810 - INFO - Epoch 41 Batch 20: Train Loss = 0.1738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 20: Train Loss = 0.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:44:35,324 - INFO - Epoch 41 Batch 40: Train Loss = 0.1150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 40: Train Loss = 0.1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:44:49,506 - INFO - Epoch 41 Batch 60: Train Loss = 0.1678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 60: Train Loss = 0.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:45:03,120 - INFO - Epoch 41 Batch 80: Train Loss = 0.1989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 80: Train Loss = 0.1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:45:15,938 - INFO - Epoch 41 Batch 100: Train Loss = 0.1117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 100: Train Loss = 0.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:45:30,213 - INFO - Epoch 41 Batch 120: Train Loss = 0.1454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 120: Train Loss = 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:45:40,542 - INFO - Epoch 41: Loss = 0.1698 Valid loss = 0.1475 roc = 0.9117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Loss = 0.1698 Valid loss = 0.1475 roc = 0.9117\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 162  130]]\n",
      "accuracy = 0.9546356201171875\n",
      "precision class 0 = 0.9582796692848206\n",
      "precision class 1 = 0.860927164554596\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.4452054798603058\n",
      "AUC of ROC = 0.9117102787316137\n",
      "AUC of PRC = 0.6744103019775084\n",
      "min(+P, Se) = 0.6027397260273972\n",
      "f1_score = 0.5869074390164993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:45:41,337 - INFO - Epoch 42 Batch 0: Train Loss = 0.1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 0: Train Loss = 0.1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:45:55,522 - INFO - Epoch 42 Batch 20: Train Loss = 0.2091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 20: Train Loss = 0.2091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:46:10,432 - INFO - Epoch 42 Batch 40: Train Loss = 0.1616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 40: Train Loss = 0.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:46:24,644 - INFO - Epoch 42 Batch 60: Train Loss = 0.2111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 60: Train Loss = 0.2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:46:39,182 - INFO - Epoch 42 Batch 80: Train Loss = 0.1903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 80: Train Loss = 0.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:46:53,381 - INFO - Epoch 42 Batch 100: Train Loss = 0.1813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 100: Train Loss = 0.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:47:07,388 - INFO - Epoch 42 Batch 120: Train Loss = 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 120: Train Loss = 0.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:47:17,055 - INFO - Epoch 42: Loss = 0.1709 Valid loss = 0.1481 roc = 0.9104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Loss = 0.1709 Valid loss = 0.1481 roc = 0.9104\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.9587734937667847\n",
      "precision class 1 = 0.8627451062202454\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.910438158482388\n",
      "AUC of PRC = 0.6672088544044306\n",
      "min(+P, Se) = 0.6061643835616438\n",
      "f1_score = 0.5932584324161176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:47:17,763 - INFO - Epoch 43 Batch 0: Train Loss = 0.1688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 0: Train Loss = 0.1688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:47:30,559 - INFO - Epoch 43 Batch 20: Train Loss = 0.1935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 20: Train Loss = 0.1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:47:44,570 - INFO - Epoch 43 Batch 40: Train Loss = 0.1635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 40: Train Loss = 0.1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:47:59,238 - INFO - Epoch 43 Batch 60: Train Loss = 0.1537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 60: Train Loss = 0.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:48:12,981 - INFO - Epoch 43 Batch 80: Train Loss = 0.1180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 80: Train Loss = 0.1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:48:26,401 - INFO - Epoch 43 Batch 100: Train Loss = 0.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 100: Train Loss = 0.1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:48:39,760 - INFO - Epoch 43 Batch 120: Train Loss = 0.1996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 120: Train Loss = 0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:48:49,806 - INFO - Epoch 43: Loss = 0.1722 Valid loss = 0.1491 roc = 0.9113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Loss = 0.1722 Valid loss = 0.1491 roc = 0.9113\n",
      "confusion matrix:\n",
      "[[3725   17]\n",
      " [ 166  126]]\n",
      "accuracy = 0.9546356201171875\n",
      "precision class 0 = 0.9573374390602112\n",
      "precision class 1 = 0.881118893623352\n",
      "recall class 0 = 0.9954569935798645\n",
      "recall class 1 = 0.43150684237480164\n",
      "AUC of ROC = 0.9112865437133464\n",
      "AUC of PRC = 0.6615833898169097\n",
      "min(+P, Se) = 0.589041095890411\n",
      "f1_score = 0.5793103281228513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:48:50,520 - INFO - Epoch 44 Batch 0: Train Loss = 0.2005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 0: Train Loss = 0.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:49:03,891 - INFO - Epoch 44 Batch 20: Train Loss = 0.1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 20: Train Loss = 0.1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:49:18,408 - INFO - Epoch 44 Batch 40: Train Loss = 0.1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 40: Train Loss = 0.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:49:32,456 - INFO - Epoch 44 Batch 60: Train Loss = 0.1948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 60: Train Loss = 0.1948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:49:45,327 - INFO - Epoch 44 Batch 80: Train Loss = 0.1383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 80: Train Loss = 0.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:49:59,380 - INFO - Epoch 44 Batch 100: Train Loss = 0.1319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 100: Train Loss = 0.1319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:50:12,568 - INFO - Epoch 44 Batch 120: Train Loss = 0.1594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 120: Train Loss = 0.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:50:22,651 - INFO - Epoch 44: Loss = 0.1711 Valid loss = 0.1463 roc = 0.9150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Loss = 0.1711 Valid loss = 0.1463 roc = 0.9150\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 163  129]]\n",
      "accuracy = 0.9543877243995667\n",
      "precision class 0 = 0.9580329656600952\n",
      "precision class 1 = 0.8600000143051147\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.44178083539009094\n",
      "AUC of ROC = 0.9149921659357313\n",
      "AUC of PRC = 0.6782741827471905\n",
      "min(+P, Se) = 0.613013698630137\n",
      "f1_score = 0.5837104356576192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:50:23,280 - INFO - Epoch 45 Batch 0: Train Loss = 0.1576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 0: Train Loss = 0.1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:50:37,260 - INFO - Epoch 45 Batch 20: Train Loss = 0.1628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 20: Train Loss = 0.1628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:50:50,777 - INFO - Epoch 45 Batch 40: Train Loss = 0.1403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 40: Train Loss = 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:51:03,916 - INFO - Epoch 45 Batch 60: Train Loss = 0.1741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 60: Train Loss = 0.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:51:17,230 - INFO - Epoch 45 Batch 80: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 80: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:51:31,317 - INFO - Epoch 45 Batch 100: Train Loss = 0.1550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 100: Train Loss = 0.1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:51:44,993 - INFO - Epoch 45 Batch 120: Train Loss = 0.1442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 120: Train Loss = 0.1442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:51:55,493 - INFO - Epoch 45: Loss = 0.1685 Valid loss = 0.1469 roc = 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Loss = 0.1685 Valid loss = 0.1469 roc = 0.9167\n",
      "confusion matrix:\n",
      "[[3723   19]\n",
      " [ 169  123]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9565775990486145\n",
      "precision class 1 = 0.8661971688270569\n",
      "recall class 0 = 0.9949225187301636\n",
      "recall class 1 = 0.4212328791618347\n",
      "AUC of ROC = 0.9167163922303654\n",
      "AUC of PRC = 0.6780451593558416\n",
      "min(+P, Se) = 0.6232876712328768\n",
      "f1_score = 0.5668202756597448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:51:56,159 - INFO - Epoch 46 Batch 0: Train Loss = 0.2382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 0: Train Loss = 0.2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:52:10,461 - INFO - Epoch 46 Batch 20: Train Loss = 0.1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 20: Train Loss = 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:52:24,539 - INFO - Epoch 46 Batch 40: Train Loss = 0.2215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 40: Train Loss = 0.2215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:52:38,226 - INFO - Epoch 46 Batch 60: Train Loss = 0.1210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 60: Train Loss = 0.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:52:52,274 - INFO - Epoch 46 Batch 80: Train Loss = 0.1099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 80: Train Loss = 0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:53:05,065 - INFO - Epoch 46 Batch 100: Train Loss = 0.1592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 100: Train Loss = 0.1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:53:19,415 - INFO - Epoch 46 Batch 120: Train Loss = 0.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 120: Train Loss = 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:53:30,615 - INFO - Epoch 46: Loss = 0.1654 Valid loss = 0.1439 roc = 0.9169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Loss = 0.1654 Valid loss = 0.1439 roc = 0.9169\n",
      "confusion matrix:\n",
      "[[3713   29]\n",
      " [ 152  140]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.9606726765632629\n",
      "precision class 1 = 0.8284023404121399\n",
      "recall class 0 = 0.9922501444816589\n",
      "recall class 1 = 0.4794520437717438\n",
      "AUC of ROC = 0.9168994311151462\n",
      "AUC of PRC = 0.678048845447712\n",
      "min(+P, Se) = 0.6075085324232082\n",
      "f1_score = 0.6073752413547848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:53:31,356 - INFO - Epoch 47 Batch 0: Train Loss = 0.2134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 0: Train Loss = 0.2134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:53:44,444 - INFO - Epoch 47 Batch 20: Train Loss = 0.1327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 20: Train Loss = 0.1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:53:58,103 - INFO - Epoch 47 Batch 40: Train Loss = 0.2104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 40: Train Loss = 0.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:54:12,549 - INFO - Epoch 47 Batch 60: Train Loss = 0.1171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 60: Train Loss = 0.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:54:26,565 - INFO - Epoch 47 Batch 80: Train Loss = 0.1997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 80: Train Loss = 0.1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:54:40,223 - INFO - Epoch 47 Batch 100: Train Loss = 0.1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 100: Train Loss = 0.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:54:53,872 - INFO - Epoch 47 Batch 120: Train Loss = 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 120: Train Loss = 0.1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:55:03,861 - INFO - Epoch 47: Loss = 0.1675 Valid loss = 0.1452 roc = 0.9186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Loss = 0.1675 Valid loss = 0.1452 roc = 0.9186\n",
      "confusion matrix:\n",
      "[[3718   24]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9548835158348083\n",
      "precision class 0 = 0.9592363238334656\n",
      "precision class 1 = 0.8481012582778931\n",
      "recall class 0 = 0.9935863018035889\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.9185522722447157\n",
      "AUC of PRC = 0.6760340044017956\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.5955555466475311\n",
      "------------ Save best model - AUROC: 0.9186 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:55:04,762 - INFO - Epoch 48 Batch 0: Train Loss = 0.1463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 0: Train Loss = 0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:55:18,514 - INFO - Epoch 48 Batch 20: Train Loss = 0.1519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 20: Train Loss = 0.1519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:55:32,718 - INFO - Epoch 48 Batch 40: Train Loss = 0.1814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 40: Train Loss = 0.1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:55:46,179 - INFO - Epoch 48 Batch 60: Train Loss = 0.1572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 60: Train Loss = 0.1572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:55:59,382 - INFO - Epoch 48 Batch 80: Train Loss = 0.1945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 80: Train Loss = 0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:56:13,131 - INFO - Epoch 48 Batch 100: Train Loss = 0.1802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 100: Train Loss = 0.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:56:26,917 - INFO - Epoch 48 Batch 120: Train Loss = 0.1270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 120: Train Loss = 0.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:56:37,713 - INFO - Epoch 48: Loss = 0.1673 Valid loss = 0.1468 roc = 0.9141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Loss = 0.1673 Valid loss = 0.1468 roc = 0.9141\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.9587734937667847\n",
      "precision class 1 = 0.8627451062202454\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.9140632435954693\n",
      "AUC of PRC = 0.6691221562774763\n",
      "min(+P, Se) = 0.5958904109589042\n",
      "f1_score = 0.5932584324161176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:56:38,334 - INFO - Epoch 49 Batch 0: Train Loss = 0.1296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 0: Train Loss = 0.1296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:56:53,110 - INFO - Epoch 49 Batch 20: Train Loss = 0.2149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 20: Train Loss = 0.2149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:57:06,761 - INFO - Epoch 49 Batch 40: Train Loss = 0.1448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 40: Train Loss = 0.1448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:57:21,426 - INFO - Epoch 49 Batch 60: Train Loss = 0.1468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 60: Train Loss = 0.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:57:36,183 - INFO - Epoch 49 Batch 80: Train Loss = 0.1678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 80: Train Loss = 0.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:57:50,957 - INFO - Epoch 49 Batch 100: Train Loss = 0.1229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 100: Train Loss = 0.1229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:58:04,818 - INFO - Epoch 49 Batch 120: Train Loss = 0.1768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 120: Train Loss = 0.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:58:15,324 - INFO - Epoch 49: Loss = 0.1702 Valid loss = 0.1449 roc = 0.9163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Loss = 0.1702 Valid loss = 0.1449 roc = 0.9163\n",
      "confusion matrix:\n",
      "[[3720   22]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.9590100646018982\n",
      "precision class 1 = 0.8580645322799683\n",
      "recall class 0 = 0.9941207766532898\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.9162935724065221\n",
      "AUC of PRC = 0.6757305750718936\n",
      "min(+P, Se) = 0.6216216216216216\n",
      "f1_score = 0.5950782689920842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:58:15,979 - INFO - Epoch 50 Batch 0: Train Loss = 0.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 0: Train Loss = 0.2289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:58:31,116 - INFO - Epoch 50 Batch 20: Train Loss = 0.1479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 20: Train Loss = 0.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:58:45,277 - INFO - Epoch 50 Batch 40: Train Loss = 0.1891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 40: Train Loss = 0.1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:58:58,959 - INFO - Epoch 50 Batch 60: Train Loss = 0.2568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 60: Train Loss = 0.2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:59:13,732 - INFO - Epoch 50 Batch 80: Train Loss = 0.1412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 80: Train Loss = 0.1412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:59:28,215 - INFO - Epoch 50 Batch 100: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 100: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:59:42,327 - INFO - Epoch 50 Batch 120: Train Loss = 0.1419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 120: Train Loss = 0.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:59:52,683 - INFO - Epoch 50: Loss = 0.1632 Valid loss = 0.1452 roc = 0.9173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Loss = 0.1632 Valid loss = 0.1452 roc = 0.9173\n",
      "confusion matrix:\n",
      "[[3718   24]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.9594838619232178\n",
      "precision class 1 = 0.849056601524353\n",
      "recall class 0 = 0.9935863018035889\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.9172636784958597\n",
      "AUC of PRC = 0.6753793737962068\n",
      "min(+P, Se) = 0.6177474402730375\n",
      "f1_score = 0.5986696044459616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 12:59:53,364 - INFO - Epoch 51 Batch 0: Train Loss = 0.1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 0: Train Loss = 0.1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:00:08,709 - INFO - Epoch 51 Batch 20: Train Loss = 0.1818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 20: Train Loss = 0.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:00:22,259 - INFO - Epoch 51 Batch 40: Train Loss = 0.1812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 40: Train Loss = 0.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:00:36,541 - INFO - Epoch 51 Batch 60: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 60: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:00:49,853 - INFO - Epoch 51 Batch 80: Train Loss = 0.1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 80: Train Loss = 0.1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:01:03,358 - INFO - Epoch 51 Batch 100: Train Loss = 0.1738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 100: Train Loss = 0.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:01:17,403 - INFO - Epoch 51 Batch 120: Train Loss = 0.1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 120: Train Loss = 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:01:28,993 - INFO - Epoch 51: Loss = 0.1652 Valid loss = 0.1455 roc = 0.9155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Loss = 0.1652 Valid loss = 0.1455 roc = 0.9155\n",
      "confusion matrix:\n",
      "[[3723   19]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9561229348182678\n",
      "precision class 0 = 0.9592888355255127\n",
      "precision class 1 = 0.8758170008659363\n",
      "recall class 0 = 0.9949225187301636\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.9155303002569866\n",
      "AUC of PRC = 0.6768078517577664\n",
      "min(+P, Se) = 0.6177474402730375\n",
      "f1_score = 0.6022472128881952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:01:29,707 - INFO - Epoch 52 Batch 0: Train Loss = 0.1395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 0: Train Loss = 0.1395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:01:42,942 - INFO - Epoch 52 Batch 20: Train Loss = 0.1774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 20: Train Loss = 0.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:01:57,590 - INFO - Epoch 52 Batch 40: Train Loss = 0.1840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 40: Train Loss = 0.1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:02:11,758 - INFO - Epoch 52 Batch 60: Train Loss = 0.1816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 60: Train Loss = 0.1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:02:24,704 - INFO - Epoch 52 Batch 80: Train Loss = 0.0824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 80: Train Loss = 0.0824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:02:37,222 - INFO - Epoch 52 Batch 100: Train Loss = 0.1359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 100: Train Loss = 0.1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:02:50,689 - INFO - Epoch 52 Batch 120: Train Loss = 0.1367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 120: Train Loss = 0.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:03:01,579 - INFO - Epoch 52: Loss = 0.1643 Valid loss = 0.1458 roc = 0.9186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Loss = 0.1643 Valid loss = 0.1458 roc = 0.9186\n",
      "confusion matrix:\n",
      "[[3723   19]\n",
      " [ 167  125]]\n",
      "accuracy = 0.953891932964325\n",
      "precision class 0 = 0.9570693969726562\n",
      "precision class 1 = 0.8680555820465088\n",
      "recall class 0 = 0.9949225187301636\n",
      "recall class 1 = 0.4280821979045868\n",
      "AUC of ROC = 0.918643791687106\n",
      "AUC of PRC = 0.6768048386961539\n",
      "min(+P, Se) = 0.613013698630137\n",
      "f1_score = 0.5733944935014421\n",
      "------------ Save best model - AUROC: 0.9186 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:03:02,377 - INFO - Epoch 53 Batch 0: Train Loss = 0.1586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 0: Train Loss = 0.1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:03:15,367 - INFO - Epoch 53 Batch 20: Train Loss = 0.2078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 20: Train Loss = 0.2078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:03:28,577 - INFO - Epoch 53 Batch 40: Train Loss = 0.1433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 40: Train Loss = 0.1433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:03:41,684 - INFO - Epoch 53 Batch 60: Train Loss = 0.1477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 60: Train Loss = 0.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:03:54,578 - INFO - Epoch 53 Batch 80: Train Loss = 0.1845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 80: Train Loss = 0.1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:04:07,547 - INFO - Epoch 53 Batch 100: Train Loss = 0.1525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 100: Train Loss = 0.1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:04:20,530 - INFO - Epoch 53 Batch 120: Train Loss = 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 120: Train Loss = 0.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:04:30,359 - INFO - Epoch 53: Loss = 0.1644 Valid loss = 0.1435 roc = 0.9169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Loss = 0.1644 Valid loss = 0.1435 roc = 0.9169\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 155  137]]\n",
      "accuracy = 0.9563708305358887\n",
      "precision class 0 = 0.960010290145874\n",
      "precision class 1 = 0.8670886158943176\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.46917808055877686\n",
      "AUC of ROC = 0.9168866183932114\n",
      "AUC of PRC = 0.681695654913394\n",
      "min(+P, Se) = 0.613013698630137\n",
      "f1_score = 0.6088888624002917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:04:31,052 - INFO - Epoch 54 Batch 0: Train Loss = 0.1626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 0: Train Loss = 0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:04:44,024 - INFO - Epoch 54 Batch 20: Train Loss = 0.1828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 20: Train Loss = 0.1828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:04:56,154 - INFO - Epoch 54 Batch 40: Train Loss = 0.2045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 40: Train Loss = 0.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:05:08,780 - INFO - Epoch 54 Batch 60: Train Loss = 0.1257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 60: Train Loss = 0.1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:05:21,428 - INFO - Epoch 54 Batch 80: Train Loss = 0.1560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 80: Train Loss = 0.1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:05:33,950 - INFO - Epoch 54 Batch 100: Train Loss = 0.1692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 100: Train Loss = 0.1692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:05:47,434 - INFO - Epoch 54 Batch 120: Train Loss = 0.1423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 120: Train Loss = 0.1423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:05:57,816 - INFO - Epoch 54: Loss = 0.1605 Valid loss = 0.1445 roc = 0.9163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Loss = 0.1605 Valid loss = 0.1445 roc = 0.9163\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 157  135]]\n",
      "accuracy = 0.955875039100647\n",
      "precision class 0 = 0.9595152139663696\n",
      "precision class 1 = 0.8653846383094788\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.916313706683848\n",
      "AUC of PRC = 0.6809054098822217\n",
      "min(+P, Se) = 0.6143344709897611\n",
      "f1_score = 0.6026785860066206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:05:58,370 - INFO - Epoch 55 Batch 0: Train Loss = 0.1472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 0: Train Loss = 0.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:06:10,365 - INFO - Epoch 55 Batch 20: Train Loss = 0.1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 20: Train Loss = 0.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:06:22,760 - INFO - Epoch 55 Batch 40: Train Loss = 0.1976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 40: Train Loss = 0.1976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:06:34,790 - INFO - Epoch 55 Batch 60: Train Loss = 0.1589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 60: Train Loss = 0.1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:06:47,334 - INFO - Epoch 55 Batch 80: Train Loss = 0.1145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 80: Train Loss = 0.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:07:00,824 - INFO - Epoch 55 Batch 100: Train Loss = 0.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 100: Train Loss = 0.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:07:13,508 - INFO - Epoch 55 Batch 120: Train Loss = 0.1723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 120: Train Loss = 0.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:07:23,048 - INFO - Epoch 55: Loss = 0.1594 Valid loss = 0.1421 roc = 0.9181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Loss = 0.1594 Valid loss = 0.1421 roc = 0.9181\n",
      "confusion matrix:\n",
      "[[3715   27]\n",
      " [ 149  143]]\n",
      "accuracy = 0.9563708305358887\n",
      "precision class 0 = 0.9614388942718506\n",
      "precision class 1 = 0.841176450252533\n",
      "recall class 0 = 0.9927846193313599\n",
      "recall class 1 = 0.4897260367870331\n",
      "AUC of ROC = 0.9180818623108293\n",
      "AUC of PRC = 0.6832157811891979\n",
      "min(+P, Se) = 0.6198630136986302\n",
      "f1_score = 0.6190476349046597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:07:23,682 - INFO - Epoch 56 Batch 0: Train Loss = 0.1744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 0: Train Loss = 0.1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:07:36,483 - INFO - Epoch 56 Batch 20: Train Loss = 0.1831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 20: Train Loss = 0.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:07:49,971 - INFO - Epoch 56 Batch 40: Train Loss = 0.1710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 40: Train Loss = 0.1710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:08:04,158 - INFO - Epoch 56 Batch 60: Train Loss = 0.1546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 60: Train Loss = 0.1546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:08:17,767 - INFO - Epoch 56 Batch 80: Train Loss = 0.0892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 80: Train Loss = 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:08:31,056 - INFO - Epoch 56 Batch 100: Train Loss = 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 100: Train Loss = 0.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:08:44,611 - INFO - Epoch 56 Batch 120: Train Loss = 0.1133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 120: Train Loss = 0.1133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:08:54,216 - INFO - Epoch 56: Loss = 0.1632 Valid loss = 0.1459 roc = 0.9191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Loss = 0.1632 Valid loss = 0.1459 roc = 0.9191\n",
      "confusion matrix:\n",
      "[[3720   22]\n",
      " [ 163  129]]\n",
      "accuracy = 0.9541398286819458\n",
      "precision class 0 = 0.9580221772193909\n",
      "precision class 1 = 0.8543046116828918\n",
      "recall class 0 = 0.9941207766532898\n",
      "recall class 1 = 0.44178083539009094\n",
      "AUC of ROC = 0.9191279295373509\n",
      "AUC of PRC = 0.6812665561841086\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.5823927692435457\n",
      "------------ Save best model - AUROC: 0.9191 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:08:54,865 - INFO - Epoch 57 Batch 0: Train Loss = 0.1552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 0: Train Loss = 0.1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:09:07,803 - INFO - Epoch 57 Batch 20: Train Loss = 0.1460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 20: Train Loss = 0.1460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:09:20,215 - INFO - Epoch 57 Batch 40: Train Loss = 0.1842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 40: Train Loss = 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:09:32,998 - INFO - Epoch 57 Batch 60: Train Loss = 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 60: Train Loss = 0.1014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:09:46,746 - INFO - Epoch 57 Batch 80: Train Loss = 0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 80: Train Loss = 0.1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:09:59,237 - INFO - Epoch 57 Batch 100: Train Loss = 0.1851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 100: Train Loss = 0.1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:10:11,915 - INFO - Epoch 57 Batch 120: Train Loss = 0.1820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 120: Train Loss = 0.1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:10:20,861 - INFO - Epoch 57: Loss = 0.1611 Valid loss = 0.1426 roc = 0.9176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Loss = 0.1611 Valid loss = 0.1426 roc = 0.9176\n",
      "confusion matrix:\n",
      "[[3718   24]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9548835158348083\n",
      "precision class 0 = 0.9592363238334656\n",
      "precision class 1 = 0.8481012582778931\n",
      "recall class 0 = 0.9935863018035889\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.9175968092661605\n",
      "AUC of PRC = 0.6834231836288779\n",
      "min(+P, Se) = 0.6095890410958904\n",
      "f1_score = 0.5955555466475311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:10:21,549 - INFO - Epoch 58 Batch 0: Train Loss = 0.1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 0: Train Loss = 0.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:10:34,709 - INFO - Epoch 58 Batch 20: Train Loss = 0.1157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 20: Train Loss = 0.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:10:47,037 - INFO - Epoch 58 Batch 40: Train Loss = 0.1679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 40: Train Loss = 0.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:11:00,463 - INFO - Epoch 58 Batch 60: Train Loss = 0.1942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 60: Train Loss = 0.1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:11:13,154 - INFO - Epoch 58 Batch 80: Train Loss = 0.1651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 80: Train Loss = 0.1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:11:24,946 - INFO - Epoch 58 Batch 100: Train Loss = 0.0897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 100: Train Loss = 0.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:11:38,337 - INFO - Epoch 58 Batch 120: Train Loss = 0.2232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 120: Train Loss = 0.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:11:48,048 - INFO - Epoch 58: Loss = 0.1611 Valid loss = 0.1424 roc = 0.9190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Loss = 0.1611 Valid loss = 0.1424 roc = 0.9190\n",
      "confusion matrix:\n",
      "[[3718   24]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.9594838619232178\n",
      "precision class 1 = 0.849056601524353\n",
      "recall class 0 = 0.9935863018035889\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.9189723464852875\n",
      "AUC of PRC = 0.6854881813007414\n",
      "min(+P, Se) = 0.6095890410958904\n",
      "f1_score = 0.5986696044459616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:11:48,519 - INFO - Epoch 59 Batch 0: Train Loss = 0.1632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 0: Train Loss = 0.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:12:01,351 - INFO - Epoch 59 Batch 20: Train Loss = 0.1235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 20: Train Loss = 0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:12:13,524 - INFO - Epoch 59 Batch 40: Train Loss = 0.1686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 40: Train Loss = 0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:12:25,733 - INFO - Epoch 59 Batch 60: Train Loss = 0.1167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 60: Train Loss = 0.1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:12:38,421 - INFO - Epoch 59 Batch 80: Train Loss = 0.1476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 80: Train Loss = 0.1476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:12:51,205 - INFO - Epoch 59 Batch 100: Train Loss = 0.1553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 100: Train Loss = 0.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:13:03,782 - INFO - Epoch 59 Batch 120: Train Loss = 0.1175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 120: Train Loss = 0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:13:13,445 - INFO - Epoch 59: Loss = 0.1605 Valid loss = 0.1408 roc = 0.9216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Loss = 0.1605 Valid loss = 0.1408 roc = 0.9216\n",
      "confusion matrix:\n",
      "[[3720   22]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9556271433830261\n",
      "precision class 0 = 0.9595047831535339\n",
      "precision class 1 = 0.8598726391792297\n",
      "recall class 0 = 0.9941207766532898\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.9215833961766838\n",
      "AUC of PRC = 0.689629799951839\n",
      "min(+P, Se) = 0.6143344709897611\n",
      "f1_score = 0.6013363187371891\n",
      "------------ Save best model - AUROC: 0.9216 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:13:14,265 - INFO - Epoch 60 Batch 0: Train Loss = 0.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 0: Train Loss = 0.1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:13:27,402 - INFO - Epoch 60 Batch 20: Train Loss = 0.1661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 20: Train Loss = 0.1661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:13:41,712 - INFO - Epoch 60 Batch 40: Train Loss = 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 40: Train Loss = 0.0979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:13:55,248 - INFO - Epoch 60 Batch 60: Train Loss = 0.1621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 60: Train Loss = 0.1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:14:07,795 - INFO - Epoch 60 Batch 80: Train Loss = 0.1101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 80: Train Loss = 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:14:20,281 - INFO - Epoch 60 Batch 100: Train Loss = 0.1806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 100: Train Loss = 0.1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:14:33,318 - INFO - Epoch 60 Batch 120: Train Loss = 0.1945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 120: Train Loss = 0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:14:43,137 - INFO - Epoch 60: Loss = 0.1621 Valid loss = 0.1442 roc = 0.9182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Loss = 0.1621 Valid loss = 0.1442 roc = 0.9182\n",
      "confusion matrix:\n",
      "[[3723   19]\n",
      " [ 163  129]]\n",
      "accuracy = 0.9548835158348083\n",
      "precision class 0 = 0.9580545425415039\n",
      "precision class 1 = 0.8716216087341309\n",
      "recall class 0 = 0.9949225187301636\n",
      "recall class 1 = 0.44178083539009094\n",
      "AUC of ROC = 0.9181889400584261\n",
      "AUC of PRC = 0.6784023365372542\n",
      "min(+P, Se) = 0.6006825938566553\n",
      "f1_score = 0.5863636586193213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:14:43,848 - INFO - Epoch 61 Batch 0: Train Loss = 0.2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 0: Train Loss = 0.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:14:55,944 - INFO - Epoch 61 Batch 20: Train Loss = 0.1314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 20: Train Loss = 0.1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:15:08,404 - INFO - Epoch 61 Batch 40: Train Loss = 0.1325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 40: Train Loss = 0.1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:15:21,431 - INFO - Epoch 61 Batch 60: Train Loss = 0.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 60: Train Loss = 0.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:15:34,951 - INFO - Epoch 61 Batch 80: Train Loss = 0.1560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 80: Train Loss = 0.1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:15:47,748 - INFO - Epoch 61 Batch 100: Train Loss = 0.1739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 100: Train Loss = 0.1739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:15:59,826 - INFO - Epoch 61 Batch 120: Train Loss = 0.2087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 120: Train Loss = 0.2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:16:09,819 - INFO - Epoch 61: Loss = 0.1621 Valid loss = 0.1425 roc = 0.9183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Loss = 0.1621 Valid loss = 0.1425 roc = 0.9183\n",
      "confusion matrix:\n",
      "[[3725   17]\n",
      " [ 163  129]]\n",
      "accuracy = 0.9553792476654053\n",
      "precision class 0 = 0.9580761194229126\n",
      "precision class 1 = 0.8835616707801819\n",
      "recall class 0 = 0.9954569935798645\n",
      "recall class 1 = 0.44178083539009094\n",
      "AUC of ROC = 0.9182676467788817\n",
      "AUC of PRC = 0.6885966050014695\n",
      "min(+P, Se) = 0.6095890410958904\n",
      "f1_score = 0.5890411006079783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:16:10,370 - INFO - Epoch 62 Batch 0: Train Loss = 0.1340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 0: Train Loss = 0.1340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:16:22,590 - INFO - Epoch 62 Batch 20: Train Loss = 0.1423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 20: Train Loss = 0.1423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:16:35,353 - INFO - Epoch 62 Batch 40: Train Loss = 0.1927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 40: Train Loss = 0.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:16:47,947 - INFO - Epoch 62 Batch 60: Train Loss = 0.1675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 60: Train Loss = 0.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:17:00,825 - INFO - Epoch 62 Batch 80: Train Loss = 0.1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 80: Train Loss = 0.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:17:13,952 - INFO - Epoch 62 Batch 100: Train Loss = 0.1630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 100: Train Loss = 0.1630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:17:27,086 - INFO - Epoch 62 Batch 120: Train Loss = 0.0978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 120: Train Loss = 0.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:17:37,204 - INFO - Epoch 62: Loss = 0.1615 Valid loss = 0.1420 roc = 0.9234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Loss = 0.1615 Valid loss = 0.1420 roc = 0.9234\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9561229348182678\n",
      "precision class 0 = 0.959762692451477\n",
      "precision class 1 = 0.8662420511245728\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.9233607037479041\n",
      "AUC of PRC = 0.6853839776104925\n",
      "min(+P, Se) = 0.6027397260273972\n",
      "f1_score = 0.6057906587053115\n",
      "------------ Save best model - AUROC: 0.9234 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:17:37,901 - INFO - Epoch 63 Batch 0: Train Loss = 0.1233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 0: Train Loss = 0.1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:17:50,320 - INFO - Epoch 63 Batch 20: Train Loss = 0.1918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 20: Train Loss = 0.1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:18:03,189 - INFO - Epoch 63 Batch 40: Train Loss = 0.1170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 40: Train Loss = 0.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:18:16,060 - INFO - Epoch 63 Batch 60: Train Loss = 0.1616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 60: Train Loss = 0.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:18:28,452 - INFO - Epoch 63 Batch 80: Train Loss = 0.1879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 80: Train Loss = 0.1879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:18:42,174 - INFO - Epoch 63 Batch 100: Train Loss = 0.2304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 100: Train Loss = 0.2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:18:55,468 - INFO - Epoch 63 Batch 120: Train Loss = 0.0852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 120: Train Loss = 0.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:07,064 - INFO - Epoch 63: Loss = 0.1611 Valid loss = 0.1424 roc = 0.9234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Loss = 0.1611 Valid loss = 0.1424 roc = 0.9234\n",
      "confusion matrix:\n",
      "[[3723   19]\n",
      " [ 165  127]]\n",
      "accuracy = 0.9543877243995667\n",
      "precision class 0 = 0.957561731338501\n",
      "precision class 1 = 0.8698630332946777\n",
      "recall class 0 = 0.9949225187301636\n",
      "recall class 1 = 0.43493151664733887\n",
      "AUC of ROC = 0.923363449331176\n",
      "AUC of PRC = 0.6900323773457119\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.5799086888631185\n",
      "------------ Save best model - AUROC: 0.9234 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:07,641 - INFO - Epoch 64 Batch 0: Train Loss = 0.2304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 0: Train Loss = 0.2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:20,756 - INFO - Epoch 64 Batch 20: Train Loss = 0.1934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 20: Train Loss = 0.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:33,512 - INFO - Epoch 64 Batch 40: Train Loss = 0.1243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 40: Train Loss = 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:46,137 - INFO - Epoch 64 Batch 60: Train Loss = 0.1682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 60: Train Loss = 0.1682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:58,599 - INFO - Epoch 64 Batch 80: Train Loss = 0.1779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 80: Train Loss = 0.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:20:10,801 - INFO - Epoch 64 Batch 100: Train Loss = 0.1193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 100: Train Loss = 0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:20:23,550 - INFO - Epoch 64 Batch 120: Train Loss = 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 120: Train Loss = 0.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:20:33,096 - INFO - Epoch 64: Loss = 0.1595 Valid loss = 0.1400 roc = 0.9221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Loss = 0.1595 Valid loss = 0.1400 roc = 0.9221\n",
      "confusion matrix:\n",
      "[[3722   20]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9563708305358887\n",
      "precision class 0 = 0.959773063659668\n",
      "precision class 1 = 0.8717948794364929\n",
      "recall class 0 = 0.9946552515029907\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.9220711948046244\n",
      "AUC of PRC = 0.6937222785362752\n",
      "min(+P, Se) = 0.6198630136986302\n",
      "f1_score = 0.6071428957642354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:20:33,707 - INFO - Epoch 65 Batch 0: Train Loss = 0.1899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 0: Train Loss = 0.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:20:46,188 - INFO - Epoch 65 Batch 20: Train Loss = 0.1691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 20: Train Loss = 0.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:20:58,323 - INFO - Epoch 65 Batch 40: Train Loss = 0.0948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 40: Train Loss = 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:10,460 - INFO - Epoch 65 Batch 60: Train Loss = 0.1257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 60: Train Loss = 0.1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:22,957 - INFO - Epoch 65 Batch 80: Train Loss = 0.1632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 80: Train Loss = 0.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:36,604 - INFO - Epoch 65 Batch 100: Train Loss = 0.1663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 100: Train Loss = 0.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:49,001 - INFO - Epoch 65 Batch 120: Train Loss = 0.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 120: Train Loss = 0.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:58,791 - INFO - Epoch 65: Loss = 0.1641 Valid loss = 0.1408 roc = 0.9212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Loss = 0.1641 Valid loss = 0.1408 roc = 0.9212\n",
      "confusion matrix:\n",
      "[[3723   19]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9563708305358887\n",
      "precision class 0 = 0.959536075592041\n",
      "precision class 1 = 0.8766233921051025\n",
      "recall class 0 = 0.9949225187301636\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.9211514244086014\n",
      "AUC of PRC = 0.6890921255097278\n",
      "min(+P, Se) = 0.6232876712328768\n",
      "f1_score = 0.6053811515865526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:59,389 - INFO - Epoch 66 Batch 0: Train Loss = 0.1795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 0: Train Loss = 0.1795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:22:12,860 - INFO - Epoch 66 Batch 20: Train Loss = 0.1706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 20: Train Loss = 0.1706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:22:25,744 - INFO - Epoch 66 Batch 40: Train Loss = 0.1434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 40: Train Loss = 0.1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:22:38,296 - INFO - Epoch 66 Batch 60: Train Loss = 0.1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 60: Train Loss = 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:22:51,206 - INFO - Epoch 66 Batch 80: Train Loss = 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 80: Train Loss = 0.2004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:23:03,947 - INFO - Epoch 66 Batch 100: Train Loss = 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 100: Train Loss = 0.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:23:16,594 - INFO - Epoch 66 Batch 120: Train Loss = 0.0954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 120: Train Loss = 0.0954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:23:27,169 - INFO - Epoch 66: Loss = 0.1616 Valid loss = 0.1415 roc = 0.9199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Loss = 0.1616 Valid loss = 0.1415 roc = 0.9199\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 154  138]]\n",
      "accuracy = 0.9566187262535095\n",
      "precision class 0 = 0.9602580666542053\n",
      "precision class 1 = 0.8679245114326477\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.4726027250289917\n",
      "AUC of ROC = 0.919943367769049\n",
      "AUC of PRC = 0.6901087798662975\n",
      "min(+P, Se) = 0.6095890410958904\n",
      "f1_score = 0.6119733487355166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:23:27,865 - INFO - Epoch 67 Batch 0: Train Loss = 0.1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 0: Train Loss = 0.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:23:40,878 - INFO - Epoch 67 Batch 20: Train Loss = 0.1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 20: Train Loss = 0.1513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:23:54,249 - INFO - Epoch 67 Batch 40: Train Loss = 0.1403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 40: Train Loss = 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:24:07,857 - INFO - Epoch 67 Batch 60: Train Loss = 0.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 60: Train Loss = 0.1933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:24:20,978 - INFO - Epoch 67 Batch 80: Train Loss = 0.1503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 80: Train Loss = 0.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:24:33,259 - INFO - Epoch 67 Batch 100: Train Loss = 0.1327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 100: Train Loss = 0.1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:24:45,897 - INFO - Epoch 67 Batch 120: Train Loss = 0.2108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 120: Train Loss = 0.2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:24:55,969 - INFO - Epoch 67: Loss = 0.1607 Valid loss = 0.1412 roc = 0.9210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Loss = 0.1607 Valid loss = 0.1412 roc = 0.9210\n",
      "confusion matrix:\n",
      "[[3724   18]\n",
      " [ 160  132]]\n",
      "accuracy = 0.955875039100647\n",
      "precision class 0 = 0.9588053822517395\n",
      "precision class 1 = 0.8799999952316284\n",
      "recall class 0 = 0.9951897263526917\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.9209674703293967\n",
      "AUC of PRC = 0.6893793825441124\n",
      "min(+P, Se) = 0.6232876712328768\n",
      "f1_score = 0.5972850436121233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:24:56,440 - INFO - Epoch 68 Batch 0: Train Loss = 0.1325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 0: Train Loss = 0.1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:25:08,649 - INFO - Epoch 68 Batch 20: Train Loss = 0.1986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 20: Train Loss = 0.1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:25:20,893 - INFO - Epoch 68 Batch 40: Train Loss = 0.1955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 40: Train Loss = 0.1955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:25:33,077 - INFO - Epoch 68 Batch 60: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 60: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:25:45,510 - INFO - Epoch 68 Batch 80: Train Loss = 0.2536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 80: Train Loss = 0.2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:25:58,126 - INFO - Epoch 68 Batch 100: Train Loss = 0.2080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 100: Train Loss = 0.2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:26:10,844 - INFO - Epoch 68 Batch 120: Train Loss = 0.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 120: Train Loss = 0.2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:26:20,477 - INFO - Epoch 68: Loss = 0.1611 Valid loss = 0.1416 roc = 0.9211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Loss = 0.1611 Valid loss = 0.1416 roc = 0.9211\n",
      "confusion matrix:\n",
      "[[3720   22]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9548835158348083\n",
      "precision class 0 = 0.9587628841400146\n",
      "precision class 1 = 0.8571428656578064\n",
      "recall class 0 = 0.9941207766532898\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.9211257989647322\n",
      "AUC of PRC = 0.6940012596408134\n",
      "min(+P, Se) = 0.6292517006802721\n",
      "f1_score = 0.5919282566513671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:26:21,254 - INFO - Epoch 69 Batch 0: Train Loss = 0.1701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 0: Train Loss = 0.1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:26:33,737 - INFO - Epoch 69 Batch 20: Train Loss = 0.1723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 20: Train Loss = 0.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:26:46,906 - INFO - Epoch 69 Batch 40: Train Loss = 0.1910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 40: Train Loss = 0.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:26:59,574 - INFO - Epoch 69 Batch 60: Train Loss = 0.1545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 60: Train Loss = 0.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:27:12,062 - INFO - Epoch 69 Batch 80: Train Loss = 0.1672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 80: Train Loss = 0.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:27:25,045 - INFO - Epoch 69 Batch 100: Train Loss = 0.1883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 100: Train Loss = 0.1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:27:37,639 - INFO - Epoch 69 Batch 120: Train Loss = 0.1291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 120: Train Loss = 0.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:27:47,482 - INFO - Epoch 69: Loss = 0.1592 Valid loss = 0.1429 roc = 0.9173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Loss = 0.1592 Valid loss = 0.1429 roc = 0.9173\n",
      "confusion matrix:\n",
      "[[3718   24]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9553792476654053\n",
      "precision class 0 = 0.9597315192222595\n",
      "precision class 1 = 0.8500000238418579\n",
      "recall class 0 = 0.9935863018035889\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.9173167597724461\n",
      "AUC of PRC = 0.6833272757663577\n",
      "min(+P, Se) = 0.6267123287671232\n",
      "f1_score = 0.6017699270205842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:27:48,092 - INFO - Epoch 70 Batch 0: Train Loss = 0.2047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 0: Train Loss = 0.2047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:28:00,658 - INFO - Epoch 70 Batch 20: Train Loss = 0.1822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 20: Train Loss = 0.1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:28:13,630 - INFO - Epoch 70 Batch 40: Train Loss = 0.1638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 40: Train Loss = 0.1638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:28:26,673 - INFO - Epoch 70 Batch 60: Train Loss = 0.1856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 60: Train Loss = 0.1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:28:39,020 - INFO - Epoch 70 Batch 80: Train Loss = 0.1845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 80: Train Loss = 0.1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:28:52,686 - INFO - Epoch 70 Batch 100: Train Loss = 0.1515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 100: Train Loss = 0.1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:05,746 - INFO - Epoch 70 Batch 120: Train Loss = 0.1205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 120: Train Loss = 0.1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:15,867 - INFO - Epoch 70: Loss = 0.1601 Valid loss = 0.1448 roc = 0.9185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Loss = 0.1601 Valid loss = 0.1448 roc = 0.9185\n",
      "confusion matrix:\n",
      "[[3727   15]\n",
      " [ 165  127]]\n",
      "accuracy = 0.9553792476654053\n",
      "precision class 0 = 0.9576053619384766\n",
      "precision class 1 = 0.8943662047386169\n",
      "recall class 0 = 0.9959914684295654\n",
      "recall class 1 = 0.43493151664733887\n",
      "AUC of ROC = 0.918512003690064\n",
      "AUC of PRC = 0.6785202459471494\n",
      "min(+P, Se) = 0.6095890410958904\n",
      "f1_score = 0.585253440467214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:16,505 - INFO - Epoch 71 Batch 0: Train Loss = 0.1434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 0: Train Loss = 0.1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:30,392 - INFO - Epoch 71 Batch 20: Train Loss = 0.1254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 20: Train Loss = 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:43,029 - INFO - Epoch 71 Batch 40: Train Loss = 0.1674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 40: Train Loss = 0.1674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:55,995 - INFO - Epoch 71 Batch 60: Train Loss = 0.1659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 60: Train Loss = 0.1659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:30:08,537 - INFO - Epoch 71 Batch 80: Train Loss = 0.1607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 80: Train Loss = 0.1607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:30:21,862 - INFO - Epoch 71 Batch 100: Train Loss = 0.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 100: Train Loss = 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:30:33,894 - INFO - Epoch 71 Batch 120: Train Loss = 0.1727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 120: Train Loss = 0.1727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:30:43,743 - INFO - Epoch 71: Loss = 0.1579 Valid loss = 0.1424 roc = 0.9226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Loss = 0.1579 Valid loss = 0.1424 roc = 0.9226\n",
      "confusion matrix:\n",
      "[[3729   13]\n",
      " [ 163  129]]\n",
      "accuracy = 0.9563708305358887\n",
      "precision class 0 = 0.9581192135810852\n",
      "precision class 1 = 0.908450722694397\n",
      "recall class 0 = 0.9965259432792664\n",
      "recall class 1 = 0.44178083539009094\n",
      "AUC of ROC = 0.9225708909600756\n",
      "AUC of PRC = 0.6938757507204767\n",
      "min(+P, Se) = 0.6177474402730375\n",
      "f1_score = 0.5944700753555402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:30:44,484 - INFO - Epoch 72 Batch 0: Train Loss = 0.1570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 0: Train Loss = 0.1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:30:57,105 - INFO - Epoch 72 Batch 20: Train Loss = 0.2115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 20: Train Loss = 0.2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:31:09,574 - INFO - Epoch 72 Batch 40: Train Loss = 0.1936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 40: Train Loss = 0.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:31:21,866 - INFO - Epoch 72 Batch 60: Train Loss = 0.1152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 60: Train Loss = 0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:31:34,540 - INFO - Epoch 72 Batch 80: Train Loss = 0.1098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 80: Train Loss = 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:31:48,281 - INFO - Epoch 72 Batch 100: Train Loss = 0.2156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 100: Train Loss = 0.2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:00,559 - INFO - Epoch 72 Batch 120: Train Loss = 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 120: Train Loss = 0.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:10,009 - INFO - Epoch 72: Loss = 0.1594 Valid loss = 0.1401 roc = 0.9212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Loss = 0.1594 Valid loss = 0.1401 roc = 0.9212\n",
      "confusion matrix:\n",
      "[[3726   16]\n",
      " [ 155  137]]\n",
      "accuracy = 0.9576103091239929\n",
      "precision class 0 = 0.9600618481636047\n",
      "precision class 1 = 0.8954248428344727\n",
      "recall class 0 = 0.9957242012023926\n",
      "recall class 1 = 0.46917808055877686\n",
      "AUC of ROC = 0.9212145728238507\n",
      "AUC of PRC = 0.6933805960197065\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.6157303371460747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:10,701 - INFO - Epoch 73 Batch 0: Train Loss = 0.1596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 0: Train Loss = 0.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:22,999 - INFO - Epoch 73 Batch 20: Train Loss = 0.1615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 20: Train Loss = 0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:34,875 - INFO - Epoch 73 Batch 40: Train Loss = 0.1794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 40: Train Loss = 0.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:47,839 - INFO - Epoch 73 Batch 60: Train Loss = 0.0939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 60: Train Loss = 0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:33:00,051 - INFO - Epoch 73 Batch 80: Train Loss = 0.1670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 80: Train Loss = 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:33:12,167 - INFO - Epoch 73 Batch 100: Train Loss = 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 100: Train Loss = 0.1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:33:24,515 - INFO - Epoch 73 Batch 120: Train Loss = 0.1509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 120: Train Loss = 0.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:33:34,423 - INFO - Epoch 73: Loss = 0.1575 Valid loss = 0.1407 roc = 0.9196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Loss = 0.1575 Valid loss = 0.1407 roc = 0.9196\n",
      "confusion matrix:\n",
      "[[3718   24]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9553792476654053\n",
      "precision class 0 = 0.9597315192222595\n",
      "precision class 1 = 0.8500000238418579\n",
      "recall class 0 = 0.9935863018035889\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.9195599013054334\n",
      "AUC of PRC = 0.6896770638931425\n",
      "min(+P, Se) = 0.613013698630137\n",
      "f1_score = 0.6017699270205842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:33:34,997 - INFO - Epoch 74 Batch 0: Train Loss = 0.1266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 0: Train Loss = 0.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:33:47,679 - INFO - Epoch 74 Batch 20: Train Loss = 0.2133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 20: Train Loss = 0.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:34:01,243 - INFO - Epoch 74 Batch 40: Train Loss = 0.1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 40: Train Loss = 0.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:34:14,467 - INFO - Epoch 74 Batch 60: Train Loss = 0.2092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 60: Train Loss = 0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:34:27,204 - INFO - Epoch 74 Batch 80: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 80: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:34:39,471 - INFO - Epoch 74 Batch 100: Train Loss = 0.1368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 100: Train Loss = 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:34:52,257 - INFO - Epoch 74 Batch 120: Train Loss = 0.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 120: Train Loss = 0.2448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:35:02,118 - INFO - Epoch 74: Loss = 0.1577 Valid loss = 0.1393 roc = 0.9251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Loss = 0.1577 Valid loss = 0.1393 roc = 0.9251\n",
      "confusion matrix:\n",
      "[[3717   25]\n",
      " [ 150  142]]\n",
      "accuracy = 0.9566187262535095\n",
      "precision class 0 = 0.9612102508544922\n",
      "precision class 1 = 0.8502994179725647\n",
      "recall class 0 = 0.9933190941810608\n",
      "recall class 1 = 0.48630136251449585\n",
      "AUC of ROC = 0.9250629653763646\n",
      "AUC of PRC = 0.6886670869401943\n",
      "min(+P, Se) = 0.6267123287671232\n",
      "f1_score = 0.6187363819354647\n",
      "------------ Save best model - AUROC: 0.9251 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:35:02,769 - INFO - Epoch 75 Batch 0: Train Loss = 0.2097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 0: Train Loss = 0.2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:35:15,573 - INFO - Epoch 75 Batch 20: Train Loss = 0.1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 20: Train Loss = 0.1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:35:28,239 - INFO - Epoch 75 Batch 40: Train Loss = 0.2322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 40: Train Loss = 0.2322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:35:40,256 - INFO - Epoch 75 Batch 60: Train Loss = 0.1260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 60: Train Loss = 0.1260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:35:53,034 - INFO - Epoch 75 Batch 80: Train Loss = 0.1259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 80: Train Loss = 0.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:05,268 - INFO - Epoch 75 Batch 100: Train Loss = 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 100: Train Loss = 0.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:17,962 - INFO - Epoch 75 Batch 120: Train Loss = 0.1385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 120: Train Loss = 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:27,570 - INFO - Epoch 75: Loss = 0.1547 Valid loss = 0.1386 roc = 0.9227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Loss = 0.1547 Valid loss = 0.1386 roc = 0.9227\n",
      "confusion matrix:\n",
      "[[3720   22]\n",
      " [ 152  140]]\n",
      "accuracy = 0.9568666219711304\n",
      "precision class 0 = 0.96074378490448\n",
      "precision class 1 = 0.8641975522041321\n",
      "recall class 0 = 0.9941207766532898\n",
      "recall class 1 = 0.4794520437717438\n",
      "AUC of ROC = 0.9226651559857376\n",
      "AUC of PRC = 0.7013801137948608\n",
      "min(+P, Se) = 0.6198630136986302\n",
      "f1_score = 0.6167400707410406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:28,131 - INFO - Epoch 76 Batch 0: Train Loss = 0.1502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 0: Train Loss = 0.1502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:40,918 - INFO - Epoch 76 Batch 20: Train Loss = 0.1455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 20: Train Loss = 0.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:53,509 - INFO - Epoch 76 Batch 40: Train Loss = 0.1775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 40: Train Loss = 0.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:37:06,264 - INFO - Epoch 76 Batch 60: Train Loss = 0.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 60: Train Loss = 0.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:37:19,075 - INFO - Epoch 76 Batch 80: Train Loss = 0.1361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 80: Train Loss = 0.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:37:32,407 - INFO - Epoch 76 Batch 100: Train Loss = 0.1334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 100: Train Loss = 0.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:37:45,334 - INFO - Epoch 76 Batch 120: Train Loss = 0.1662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 120: Train Loss = 0.1662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:37:54,438 - INFO - Epoch 76: Loss = 0.1576 Valid loss = 0.1390 roc = 0.9224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Loss = 0.1576 Valid loss = 0.1390 roc = 0.9224\n",
      "confusion matrix:\n",
      "[[3714   28]\n",
      " [ 153  139]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.9604344367980957\n",
      "precision class 1 = 0.832335352897644\n",
      "recall class 0 = 0.992517352104187\n",
      "recall class 1 = 0.47602739930152893\n",
      "AUC of ROC = 0.9223924280474144\n",
      "AUC of PRC = 0.6952028078564615\n",
      "min(+P, Se) = 0.6135593220338983\n",
      "f1_score = 0.6056645097022363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:37:54,914 - INFO - Epoch 77 Batch 0: Train Loss = 0.1159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 0: Train Loss = 0.1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:38:07,382 - INFO - Epoch 77 Batch 20: Train Loss = 0.2160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 20: Train Loss = 0.2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:38:20,478 - INFO - Epoch 77 Batch 40: Train Loss = 0.2380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 40: Train Loss = 0.2380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:38:32,691 - INFO - Epoch 77 Batch 60: Train Loss = 0.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 60: Train Loss = 0.1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:38:45,700 - INFO - Epoch 77 Batch 80: Train Loss = 0.1540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 80: Train Loss = 0.1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:38:58,813 - INFO - Epoch 77 Batch 100: Train Loss = 0.1214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 100: Train Loss = 0.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:39:12,551 - INFO - Epoch 77 Batch 120: Train Loss = 0.0855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 120: Train Loss = 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:39:22,926 - INFO - Epoch 77: Loss = 0.1552 Valid loss = 0.1385 roc = 0.9253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Loss = 0.1552 Valid loss = 0.1385 roc = 0.9253\n",
      "confusion matrix:\n",
      "[[3727   15]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9566187262535095\n",
      "precision class 0 = 0.9588371515274048\n",
      "precision class 1 = 0.8979591727256775\n",
      "recall class 0 = 0.9959914684295654\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.9252945095656121\n",
      "AUC of PRC = 0.7012533181325427\n",
      "min(+P, Se) = 0.6198630136986302\n",
      "f1_score = 0.6013667437541346\n",
      "------------ Save best model - AUROC: 0.9253 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:39:23,693 - INFO - Epoch 78 Batch 0: Train Loss = 0.0918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 0: Train Loss = 0.0918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:39:37,396 - INFO - Epoch 78 Batch 20: Train Loss = 0.1718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 20: Train Loss = 0.1718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:39:50,859 - INFO - Epoch 78 Batch 40: Train Loss = 0.2258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 40: Train Loss = 0.2258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:40:03,942 - INFO - Epoch 78 Batch 60: Train Loss = 0.1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 60: Train Loss = 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:40:16,013 - INFO - Epoch 78 Batch 80: Train Loss = 0.1976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 80: Train Loss = 0.1976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:40:28,161 - INFO - Epoch 78 Batch 100: Train Loss = 0.1201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 100: Train Loss = 0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:40:40,427 - INFO - Epoch 78 Batch 120: Train Loss = 0.1746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 120: Train Loss = 0.1746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:40:50,759 - INFO - Epoch 78: Loss = 0.1676 Valid loss = 0.1429 roc = 0.9265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Loss = 0.1676 Valid loss = 0.1429 roc = 0.9265\n",
      "confusion matrix:\n",
      "[[3729   13]\n",
      " [ 169  123]]\n",
      "accuracy = 0.9548835158348083\n",
      "precision class 0 = 0.9566444158554077\n",
      "precision class 1 = 0.904411792755127\n",
      "recall class 0 = 0.9965259432792664\n",
      "recall class 1 = 0.4212328791618347\n",
      "AUC of ROC = 0.9264751103724475\n",
      "AUC of PRC = 0.6919674564886434\n",
      "min(+P, Se) = 0.6177474402730375\n",
      "f1_score = 0.5747663372416146\n",
      "------------ Save best model - AUROC: 0.9265 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:40:51,522 - INFO - Epoch 79 Batch 0: Train Loss = 0.1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 0: Train Loss = 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:41:03,950 - INFO - Epoch 79 Batch 20: Train Loss = 0.1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 20: Train Loss = 0.1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:41:17,163 - INFO - Epoch 79 Batch 40: Train Loss = 0.1362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 40: Train Loss = 0.1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:41:29,722 - INFO - Epoch 79 Batch 60: Train Loss = 0.0942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 60: Train Loss = 0.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:41:42,064 - INFO - Epoch 79 Batch 80: Train Loss = 0.1719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 80: Train Loss = 0.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:41:54,901 - INFO - Epoch 79 Batch 100: Train Loss = 0.1897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 100: Train Loss = 0.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:42:08,746 - INFO - Epoch 79 Batch 120: Train Loss = 0.1059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 120: Train Loss = 0.1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:42:18,380 - INFO - Epoch 79: Loss = 0.1627 Valid loss = 0.1436 roc = 0.9247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Loss = 0.1627 Valid loss = 0.1436 roc = 0.9247\n",
      "confusion matrix:\n",
      "[[3730   12]\n",
      " [ 175  117]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9551856517791748\n",
      "precision class 1 = 0.9069767594337463\n",
      "recall class 0 = 0.9967931509017944\n",
      "recall class 1 = 0.4006849229335785\n",
      "AUC of ROC = 0.9246639406075426\n",
      "AUC of PRC = 0.6965458329707716\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.5558194847167358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:42:18,930 - INFO - Epoch 80 Batch 0: Train Loss = 0.1813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 0: Train Loss = 0.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:42:31,480 - INFO - Epoch 80 Batch 20: Train Loss = 0.2132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 20: Train Loss = 0.2132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:42:44,224 - INFO - Epoch 80 Batch 40: Train Loss = 0.1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 40: Train Loss = 0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:42:56,347 - INFO - Epoch 80 Batch 60: Train Loss = 0.2239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 60: Train Loss = 0.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:08,905 - INFO - Epoch 80 Batch 80: Train Loss = 0.1675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 80: Train Loss = 0.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:21,964 - INFO - Epoch 80 Batch 100: Train Loss = 0.1400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 100: Train Loss = 0.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:34,282 - INFO - Epoch 80 Batch 120: Train Loss = 0.1357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 120: Train Loss = 0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:43,927 - INFO - Epoch 80: Loss = 0.1615 Valid loss = 0.1431 roc = 0.9224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Loss = 0.1615 Valid loss = 0.1431 roc = 0.9224\n",
      "confusion matrix:\n",
      "[[3730   12]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9573624134063721\n",
      "precision class 0 = 0.9588689208030701\n",
      "precision class 1 = 0.9166666865348816\n",
      "recall class 0 = 0.9967931509017944\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.9224189686857075\n",
      "AUC of PRC = 0.6876774797004018\n",
      "min(+P, Se) = 0.6198630136986302\n",
      "f1_score = 0.6055045951527483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:44,625 - INFO - Epoch 81 Batch 0: Train Loss = 0.1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 0: Train Loss = 0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:58,090 - INFO - Epoch 81 Batch 20: Train Loss = 0.1610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 20: Train Loss = 0.1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:44:13,012 - INFO - Epoch 81 Batch 40: Train Loss = 0.1978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 40: Train Loss = 0.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:44:26,567 - INFO - Epoch 81 Batch 60: Train Loss = 0.2074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 60: Train Loss = 0.2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:44:40,276 - INFO - Epoch 81 Batch 80: Train Loss = 0.1913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 80: Train Loss = 0.1913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:44:53,165 - INFO - Epoch 81 Batch 100: Train Loss = 0.1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 100: Train Loss = 0.1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:05,514 - INFO - Epoch 81 Batch 120: Train Loss = 0.1621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 120: Train Loss = 0.1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:15,971 - INFO - Epoch 81: Loss = 0.1588 Valid loss = 0.1414 roc = 0.9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Loss = 0.1588 Valid loss = 0.1414 roc = 0.9229\n",
      "confusion matrix:\n",
      "[[3727   15]\n",
      " [ 165  127]]\n",
      "accuracy = 0.9553792476654053\n",
      "precision class 0 = 0.9576053619384766\n",
      "precision class 1 = 0.8943662047386169\n",
      "recall class 0 = 0.9959914684295654\n",
      "recall class 1 = 0.43493151664733887\n",
      "AUC of ROC = 0.9229232408132784\n",
      "AUC of PRC = 0.6882025327345331\n",
      "min(+P, Se) = 0.6177474402730375\n",
      "f1_score = 0.585253440467214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:16,503 - INFO - Epoch 82 Batch 0: Train Loss = 0.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 0: Train Loss = 0.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:29,059 - INFO - Epoch 82 Batch 20: Train Loss = 0.1331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 20: Train Loss = 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:40,924 - INFO - Epoch 82 Batch 40: Train Loss = 0.1268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 40: Train Loss = 0.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:53,218 - INFO - Epoch 82 Batch 60: Train Loss = 0.1777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 60: Train Loss = 0.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:46:05,775 - INFO - Epoch 82 Batch 80: Train Loss = 0.1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 80: Train Loss = 0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:46:17,943 - INFO - Epoch 82 Batch 100: Train Loss = 0.1385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 100: Train Loss = 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:46:30,735 - INFO - Epoch 82 Batch 120: Train Loss = 0.1632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 120: Train Loss = 0.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:46:40,941 - INFO - Epoch 82: Loss = 0.1555 Valid loss = 0.1389 roc = 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Loss = 0.1555 Valid loss = 0.1389 roc = 0.9259\n",
      "confusion matrix:\n",
      "[[3722   20]\n",
      " [ 158  134]]\n",
      "accuracy = 0.955875039100647\n",
      "precision class 0 = 0.9592783451080322\n",
      "precision class 1 = 0.8701298832893372\n",
      "recall class 0 = 0.9946552515029907\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.9259012834686602\n",
      "AUC of PRC = 0.6940452284551505\n",
      "min(+P, Se) = 0.6061643835616438\n",
      "f1_score = 0.6008968842487675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:46:41,753 - INFO - Epoch 83 Batch 0: Train Loss = 0.1695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 0: Train Loss = 0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:46:53,742 - INFO - Epoch 83 Batch 20: Train Loss = 0.1606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 20: Train Loss = 0.1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:47:06,152 - INFO - Epoch 83 Batch 40: Train Loss = 0.1537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 40: Train Loss = 0.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:47:18,966 - INFO - Epoch 83 Batch 60: Train Loss = 0.1509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 60: Train Loss = 0.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:47:31,168 - INFO - Epoch 83 Batch 80: Train Loss = 0.1671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 80: Train Loss = 0.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:47:43,943 - INFO - Epoch 83 Batch 100: Train Loss = 0.1398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 100: Train Loss = 0.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:47:56,995 - INFO - Epoch 83 Batch 120: Train Loss = 0.1335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 120: Train Loss = 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:07,364 - INFO - Epoch 83: Loss = 0.1589 Valid loss = 0.1378 roc = 0.9295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Loss = 0.1589 Valid loss = 0.1378 roc = 0.9295\n",
      "confusion matrix:\n",
      "[[3724   18]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9568666219711304\n",
      "precision class 0 = 0.9597938060760498\n",
      "precision class 1 = 0.8831169009208679\n",
      "recall class 0 = 0.9951897263526917\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.9295016583322961\n",
      "AUC of PRC = 0.7014685763756545\n",
      "min(+P, Se) = 0.6232876712328768\n",
      "f1_score = 0.6098655118461687\n",
      "------------ Save best model - AUROC: 0.9295 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:08,037 - INFO - Epoch 84 Batch 0: Train Loss = 0.1138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 0: Train Loss = 0.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:20,653 - INFO - Epoch 84 Batch 20: Train Loss = 0.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 20: Train Loss = 0.1554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:33,286 - INFO - Epoch 84 Batch 40: Train Loss = 0.1793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 40: Train Loss = 0.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:45,068 - INFO - Epoch 84 Batch 60: Train Loss = 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 60: Train Loss = 0.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:57,651 - INFO - Epoch 84 Batch 80: Train Loss = 0.1594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 80: Train Loss = 0.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:49:10,324 - INFO - Epoch 84 Batch 100: Train Loss = 0.1851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 100: Train Loss = 0.1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:49:23,917 - INFO - Epoch 84 Batch 120: Train Loss = 0.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 120: Train Loss = 0.2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:49:34,166 - INFO - Epoch 84: Loss = 0.1558 Valid loss = 0.1383 roc = 0.9254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Loss = 0.1558 Valid loss = 0.1383 roc = 0.9254\n",
      "confusion matrix:\n",
      "[[3721   21]\n",
      " [ 152  140]]\n",
      "accuracy = 0.9571145176887512\n",
      "precision class 0 = 0.9607539176940918\n",
      "precision class 1 = 0.8695651888847351\n",
      "recall class 0 = 0.9943880438804626\n",
      "recall class 1 = 0.4794520437717438\n",
      "AUC of ROC = 0.9254125696462956\n",
      "AUC of PRC = 0.7017461955756085\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.618101515237328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:49:34,691 - INFO - Epoch 85 Batch 0: Train Loss = 0.1592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 0: Train Loss = 0.1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:49:47,021 - INFO - Epoch 85 Batch 20: Train Loss = 0.1381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 20: Train Loss = 0.1381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:50:00,061 - INFO - Epoch 85 Batch 40: Train Loss = 0.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 40: Train Loss = 0.1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:50:11,677 - INFO - Epoch 85 Batch 60: Train Loss = 0.1702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 60: Train Loss = 0.1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:50:23,893 - INFO - Epoch 85 Batch 80: Train Loss = 0.1560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 80: Train Loss = 0.1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:50:36,912 - INFO - Epoch 85 Batch 100: Train Loss = 0.1651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 100: Train Loss = 0.1651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:50:49,559 - INFO - Epoch 85 Batch 120: Train Loss = 0.1956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 120: Train Loss = 0.1956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:50:59,436 - INFO - Epoch 85: Loss = 0.1581 Valid loss = 0.1424 roc = 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Loss = 0.1581 Valid loss = 0.1424 roc = 0.9200\n",
      "confusion matrix:\n",
      "[[3724   18]\n",
      " [ 160  132]]\n",
      "accuracy = 0.955875039100647\n",
      "precision class 0 = 0.9588053822517395\n",
      "precision class 1 = 0.8799999952316284\n",
      "recall class 0 = 0.9951897263526917\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.919989127490244\n",
      "AUC of PRC = 0.6874594655197158\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.5972850436121233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:51:00,056 - INFO - Epoch 86 Batch 0: Train Loss = 0.1349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 0: Train Loss = 0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:51:12,382 - INFO - Epoch 86 Batch 20: Train Loss = 0.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 20: Train Loss = 0.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:51:24,637 - INFO - Epoch 86 Batch 40: Train Loss = 0.2271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 40: Train Loss = 0.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:51:36,799 - INFO - Epoch 86 Batch 60: Train Loss = 0.2028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 60: Train Loss = 0.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:51:49,638 - INFO - Epoch 86 Batch 80: Train Loss = 0.1190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 80: Train Loss = 0.1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:52:02,937 - INFO - Epoch 86 Batch 100: Train Loss = 0.1944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 100: Train Loss = 0.1944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:52:15,333 - INFO - Epoch 86 Batch 120: Train Loss = 0.1521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 120: Train Loss = 0.1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:52:24,793 - INFO - Epoch 86: Loss = 0.1608 Valid loss = 0.1375 roc = 0.9247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Loss = 0.1608 Valid loss = 0.1375 roc = 0.9247\n",
      "confusion matrix:\n",
      "[[3716   26]\n",
      " [ 146  146]]\n",
      "accuracy = 0.9573624134063721\n",
      "precision class 0 = 0.9621957540512085\n",
      "precision class 1 = 0.8488371968269348\n",
      "recall class 0 = 0.9930518269538879\n",
      "recall class 1 = 0.5\n",
      "AUC of ROC = 0.9247490536889655\n",
      "AUC of PRC = 0.7031829973245809\n",
      "min(+P, Se) = 0.6232876712328768\n",
      "f1_score = 0.6293103692080843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:52:25,245 - INFO - Epoch 87 Batch 0: Train Loss = 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 0: Train Loss = 0.1038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:52:37,762 - INFO - Epoch 87 Batch 20: Train Loss = 0.1495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 20: Train Loss = 0.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:52:51,203 - INFO - Epoch 87 Batch 40: Train Loss = 0.1356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 40: Train Loss = 0.1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:53:03,835 - INFO - Epoch 87 Batch 60: Train Loss = 0.1391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 60: Train Loss = 0.1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:53:15,629 - INFO - Epoch 87 Batch 80: Train Loss = 0.1729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 80: Train Loss = 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:53:28,780 - INFO - Epoch 87 Batch 100: Train Loss = 0.2032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 100: Train Loss = 0.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:53:41,802 - INFO - Epoch 87 Batch 120: Train Loss = 0.1590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 120: Train Loss = 0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:53:51,598 - INFO - Epoch 87: Loss = 0.1537 Valid loss = 0.1384 roc = 0.9239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Loss = 0.1537 Valid loss = 0.1384 roc = 0.9239\n",
      "confusion matrix:\n",
      "[[3720   22]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9556271433830261\n",
      "precision class 0 = 0.9595047831535339\n",
      "precision class 1 = 0.8598726391792297\n",
      "recall class 0 = 0.9941207766532898\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.9239089052078223\n",
      "AUC of PRC = 0.6989657176210138\n",
      "min(+P, Se) = 0.6372881355932203\n",
      "f1_score = 0.6013363187371891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:53:52,146 - INFO - Epoch 88 Batch 0: Train Loss = 0.1525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 0: Train Loss = 0.1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:54:04,470 - INFO - Epoch 88 Batch 20: Train Loss = 0.1684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 20: Train Loss = 0.1684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:54:17,765 - INFO - Epoch 88 Batch 40: Train Loss = 0.1371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 40: Train Loss = 0.1371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:54:31,137 - INFO - Epoch 88 Batch 60: Train Loss = 0.1531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 60: Train Loss = 0.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:54:45,555 - INFO - Epoch 88 Batch 80: Train Loss = 0.1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 80: Train Loss = 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:54:59,051 - INFO - Epoch 88 Batch 100: Train Loss = 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 100: Train Loss = 0.1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:55:11,164 - INFO - Epoch 88 Batch 120: Train Loss = 0.1540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 120: Train Loss = 0.1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:55:20,763 - INFO - Epoch 88: Loss = 0.1555 Valid loss = 0.1388 roc = 0.9226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Loss = 0.1555 Valid loss = 0.1388 roc = 0.9226\n",
      "confusion matrix:\n",
      "[[3717   25]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.9597211480140686\n",
      "precision class 1 = 0.8447204828262329\n",
      "recall class 0 = 0.9933190941810608\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.9225516718771734\n",
      "AUC of PRC = 0.6975617323065944\n",
      "min(+P, Se) = 0.6267123287671232\n",
      "f1_score = 0.6004415070488518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:55:21,501 - INFO - Epoch 89 Batch 0: Train Loss = 0.1364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 0: Train Loss = 0.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:55:34,340 - INFO - Epoch 89 Batch 20: Train Loss = 0.2402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 20: Train Loss = 0.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:55:46,970 - INFO - Epoch 89 Batch 40: Train Loss = 0.1447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 40: Train Loss = 0.1447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:55:59,582 - INFO - Epoch 89 Batch 60: Train Loss = 0.1193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 60: Train Loss = 0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:56:11,788 - INFO - Epoch 89 Batch 80: Train Loss = 0.1537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 80: Train Loss = 0.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:56:24,658 - INFO - Epoch 89 Batch 100: Train Loss = 0.1699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 100: Train Loss = 0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:56:38,016 - INFO - Epoch 89 Batch 120: Train Loss = 0.2287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 120: Train Loss = 0.2287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:56:47,620 - INFO - Epoch 89: Loss = 0.1553 Valid loss = 0.1414 roc = 0.9146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Loss = 0.1553 Valid loss = 0.1414 roc = 0.9146\n",
      "confusion matrix:\n",
      "[[3719   23]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9556271433830261\n",
      "precision class 0 = 0.9597419500350952\n",
      "precision class 1 = 0.8553459048271179\n",
      "recall class 0 = 0.9938535690307617\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.914550127028986\n",
      "AUC of PRC = 0.6889350470457176\n",
      "min(+P, Se) = 0.6232876712328768\n",
      "f1_score = 0.6031042478838757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:56:48,262 - INFO - Epoch 90 Batch 0: Train Loss = 0.1330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 0: Train Loss = 0.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:57:01,028 - INFO - Epoch 90 Batch 20: Train Loss = 0.1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 20: Train Loss = 0.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:57:13,981 - INFO - Epoch 90 Batch 40: Train Loss = 0.1945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 40: Train Loss = 0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:57:27,315 - INFO - Epoch 90 Batch 60: Train Loss = 0.1393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 60: Train Loss = 0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:57:39,572 - INFO - Epoch 90 Batch 80: Train Loss = 0.1510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 80: Train Loss = 0.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:57:51,916 - INFO - Epoch 90 Batch 100: Train Loss = 0.1345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 100: Train Loss = 0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:58:04,800 - INFO - Epoch 90 Batch 120: Train Loss = 0.1595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 120: Train Loss = 0.1595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:58:14,514 - INFO - Epoch 90: Loss = 0.1549 Valid loss = 0.1374 roc = 0.9218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Loss = 0.1549 Valid loss = 0.1374 roc = 0.9218\n",
      "confusion matrix:\n",
      "[[3718   24]\n",
      " [ 150  142]]\n",
      "accuracy = 0.9568666219711304\n",
      "precision class 0 = 0.9612202644348145\n",
      "precision class 1 = 0.8554216623306274\n",
      "recall class 0 = 0.9935863018035889\n",
      "recall class 1 = 0.48630136251449585\n",
      "AUC of ROC = 0.921806703616116\n",
      "AUC of PRC = 0.7021605355878595\n",
      "min(+P, Se) = 0.6404109589041096\n",
      "f1_score = 0.6200873514022923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:58:15,275 - INFO - Epoch 91 Batch 0: Train Loss = 0.1492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 0: Train Loss = 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:58:28,695 - INFO - Epoch 91 Batch 20: Train Loss = 0.1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 20: Train Loss = 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:58:41,521 - INFO - Epoch 91 Batch 40: Train Loss = 0.2039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 40: Train Loss = 0.2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:58:54,312 - INFO - Epoch 91 Batch 60: Train Loss = 0.1472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 60: Train Loss = 0.1472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:59:06,760 - INFO - Epoch 91 Batch 80: Train Loss = 0.1313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 80: Train Loss = 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:59:19,193 - INFO - Epoch 91 Batch 100: Train Loss = 0.2222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 100: Train Loss = 0.2222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:59:32,886 - INFO - Epoch 91 Batch 120: Train Loss = 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 120: Train Loss = 0.0990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:59:43,307 - INFO - Epoch 91: Loss = 0.1510 Valid loss = 0.1371 roc = 0.9239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Loss = 0.1510 Valid loss = 0.1371 roc = 0.9239\n",
      "confusion matrix:\n",
      "[[3716   26]\n",
      " [ 149  143]]\n",
      "accuracy = 0.9566187262535095\n",
      "precision class 0 = 0.9614489078521729\n",
      "precision class 1 = 0.8461538553237915\n",
      "recall class 0 = 0.9930518269538879\n",
      "recall class 1 = 0.4897260367870331\n",
      "AUC of ROC = 0.9239006684580073\n",
      "AUC of PRC = 0.6996203496019975\n",
      "min(+P, Se) = 0.6335616438356164\n",
      "f1_score = 0.6203904516902087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:59:43,997 - INFO - Epoch 92 Batch 0: Train Loss = 0.1573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 0: Train Loss = 0.1573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:59:56,766 - INFO - Epoch 92 Batch 20: Train Loss = 0.1440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 20: Train Loss = 0.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:00:10,872 - INFO - Epoch 92 Batch 40: Train Loss = 0.1276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 40: Train Loss = 0.1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:00:24,230 - INFO - Epoch 92 Batch 60: Train Loss = 0.1318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 60: Train Loss = 0.1318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:00:37,106 - INFO - Epoch 92 Batch 80: Train Loss = 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 80: Train Loss = 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:00:49,909 - INFO - Epoch 92 Batch 100: Train Loss = 0.1736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 100: Train Loss = 0.1736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:01:02,815 - INFO - Epoch 92 Batch 120: Train Loss = 0.1778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 120: Train Loss = 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:01:12,230 - INFO - Epoch 92: Loss = 0.1497 Valid loss = 0.1372 roc = 0.9226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Loss = 0.1497 Valid loss = 0.1372 roc = 0.9226\n",
      "confusion matrix:\n",
      "[[3720   22]\n",
      " [ 148  144]]\n",
      "accuracy = 0.9578582048416138\n",
      "precision class 0 = 0.961737334728241\n",
      "precision class 1 = 0.8674699068069458\n",
      "recall class 0 = 0.9941207766532898\n",
      "recall class 1 = 0.4931506812572479\n",
      "AUC of ROC = 0.9225553326548691\n",
      "AUC of PRC = 0.6980339185273404\n",
      "min(+P, Se) = 0.6169491525423729\n",
      "f1_score = 0.6288209511080265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:01:12,945 - INFO - Epoch 93 Batch 0: Train Loss = 0.1659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 0: Train Loss = 0.1659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:01:25,596 - INFO - Epoch 93 Batch 20: Train Loss = 0.1380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 20: Train Loss = 0.1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:01:39,302 - INFO - Epoch 93 Batch 40: Train Loss = 0.1761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 40: Train Loss = 0.1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:01:51,328 - INFO - Epoch 93 Batch 60: Train Loss = 0.0947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 60: Train Loss = 0.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:02:04,746 - INFO - Epoch 93 Batch 80: Train Loss = 0.1326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 80: Train Loss = 0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:02:17,162 - INFO - Epoch 93 Batch 100: Train Loss = 0.1563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 100: Train Loss = 0.1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:02:29,630 - INFO - Epoch 93 Batch 120: Train Loss = 0.2074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 120: Train Loss = 0.2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:02:39,791 - INFO - Epoch 93: Loss = 0.1560 Valid loss = 0.1385 roc = 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Loss = 0.1560 Valid loss = 0.1385 roc = 0.9237\n",
      "confusion matrix:\n",
      "[[3720   22]\n",
      " [ 153  139]]\n",
      "accuracy = 0.9566187262535095\n",
      "precision class 0 = 0.9604957103729248\n",
      "precision class 1 = 0.8633540272712708\n",
      "recall class 0 = 0.9941207766532898\n",
      "recall class 1 = 0.47602739930152893\n",
      "AUC of ROC = 0.9236654634910639\n",
      "AUC of PRC = 0.7029446085225417\n",
      "min(+P, Se) = 0.621160409556314\n",
      "f1_score = 0.6136865197323452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:02:40,389 - INFO - Epoch 94 Batch 0: Train Loss = 0.1407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 0: Train Loss = 0.1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:02:52,872 - INFO - Epoch 94 Batch 20: Train Loss = 0.1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 20: Train Loss = 0.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:03:04,493 - INFO - Epoch 94 Batch 40: Train Loss = 0.1287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 40: Train Loss = 0.1287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:03:16,320 - INFO - Epoch 94 Batch 60: Train Loss = 0.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 60: Train Loss = 0.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:03:28,534 - INFO - Epoch 94 Batch 80: Train Loss = 0.1584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 80: Train Loss = 0.1584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:03:41,789 - INFO - Epoch 94 Batch 100: Train Loss = 0.1261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 100: Train Loss = 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:03:54,869 - INFO - Epoch 94 Batch 120: Train Loss = 0.1139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 120: Train Loss = 0.1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:04:05,188 - INFO - Epoch 94: Loss = 0.1502 Valid loss = 0.1379 roc = 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Loss = 0.1502 Valid loss = 0.1379 roc = 0.9237\n",
      "confusion matrix:\n",
      "[[3718   24]\n",
      " [ 151  141]]\n",
      "accuracy = 0.9566187262535095\n",
      "precision class 0 = 0.9609718322753906\n",
      "precision class 1 = 0.8545454740524292\n",
      "recall class 0 = 0.9935863018035889\n",
      "recall class 1 = 0.482876718044281\n",
      "AUC of ROC = 0.9237304422951612\n",
      "AUC of PRC = 0.6959373043323215\n",
      "min(+P, Se) = 0.6301369863013698\n",
      "f1_score = 0.6170678709513272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:04:05,915 - INFO - Epoch 95 Batch 0: Train Loss = 0.1261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 0: Train Loss = 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:04:19,080 - INFO - Epoch 95 Batch 20: Train Loss = 0.1357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 20: Train Loss = 0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:04:31,728 - INFO - Epoch 95 Batch 40: Train Loss = 0.1528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 40: Train Loss = 0.1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:04:45,557 - INFO - Epoch 95 Batch 60: Train Loss = 0.1763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 60: Train Loss = 0.1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:04:59,780 - INFO - Epoch 95 Batch 80: Train Loss = 0.1664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 80: Train Loss = 0.1664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:05:12,946 - INFO - Epoch 95 Batch 100: Train Loss = 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 100: Train Loss = 0.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:05:25,990 - INFO - Epoch 95 Batch 120: Train Loss = 0.1372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 120: Train Loss = 0.1372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:05:36,223 - INFO - Epoch 95: Loss = 0.1513 Valid loss = 0.1386 roc = 0.9240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Loss = 0.1513 Valid loss = 0.1386 roc = 0.9240\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 151  141]]\n",
      "accuracy = 0.9551314115524292\n",
      "precision class 0 = 0.960911214351654\n",
      "precision class 1 = 0.8245614171028137\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.482876718044281\n",
      "AUC of ROC = 0.9239619864844087\n",
      "AUC of PRC = 0.6914699879383588\n",
      "min(+P, Se) = 0.6279863481228669\n",
      "f1_score = 0.6090712825532698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:05:36,756 - INFO - Epoch 96 Batch 0: Train Loss = 0.1653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 0: Train Loss = 0.1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:05:49,592 - INFO - Epoch 96 Batch 20: Train Loss = 0.1952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 20: Train Loss = 0.1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:06:02,217 - INFO - Epoch 96 Batch 40: Train Loss = 0.2323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 40: Train Loss = 0.2323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:06:14,330 - INFO - Epoch 96 Batch 60: Train Loss = 0.1498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 60: Train Loss = 0.1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:06:26,576 - INFO - Epoch 96 Batch 80: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 80: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:06:39,291 - INFO - Epoch 96 Batch 100: Train Loss = 0.1839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 100: Train Loss = 0.1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:06:51,570 - INFO - Epoch 96 Batch 120: Train Loss = 0.1910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 120: Train Loss = 0.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:07:01,605 - INFO - Epoch 96: Loss = 0.1528 Valid loss = 0.1378 roc = 0.9257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Loss = 0.1528 Valid loss = 0.1378 roc = 0.9257\n",
      "confusion matrix:\n",
      "[[3719   23]\n",
      " [ 152  140]]\n",
      "accuracy = 0.9566187262535095\n",
      "precision class 0 = 0.9607336521148682\n",
      "precision class 1 = 0.8588957190513611\n",
      "recall class 0 = 0.9938535690307617\n",
      "recall class 1 = 0.4794520437717438\n",
      "AUC of ROC = 0.9256724848626843\n",
      "AUC of PRC = 0.704631751943317\n",
      "min(+P, Se) = 0.6267123287671232\n",
      "f1_score = 0.6153845960744669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:07:02,325 - INFO - Epoch 97 Batch 0: Train Loss = 0.1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 0: Train Loss = 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:07:14,519 - INFO - Epoch 97 Batch 20: Train Loss = 0.1432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 20: Train Loss = 0.1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:07:27,525 - INFO - Epoch 97 Batch 40: Train Loss = 0.1141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 40: Train Loss = 0.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:07:40,163 - INFO - Epoch 97 Batch 60: Train Loss = 0.1665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 60: Train Loss = 0.1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:07:53,053 - INFO - Epoch 97 Batch 80: Train Loss = 0.1776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 80: Train Loss = 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:08:05,845 - INFO - Epoch 97 Batch 100: Train Loss = 0.1342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 100: Train Loss = 0.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:08:18,703 - INFO - Epoch 97 Batch 120: Train Loss = 0.0973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 120: Train Loss = 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:08:27,882 - INFO - Epoch 97: Loss = 0.1520 Valid loss = 0.1389 roc = 0.9230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Loss = 0.1520 Valid loss = 0.1389 roc = 0.9230\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 144  148]]\n",
      "accuracy = 0.9563708305358887\n",
      "precision class 0 = 0.9626362323760986\n",
      "precision class 1 = 0.8222222328186035\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.5068492889404297\n",
      "AUC of ROC = 0.9230394705051141\n",
      "AUC of PRC = 0.6890408319845162\n",
      "min(+P, Se) = 0.6164383561643836\n",
      "f1_score = 0.6271186271504191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:08:28,556 - INFO - Epoch 98 Batch 0: Train Loss = 0.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 0: Train Loss = 0.1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:08:40,956 - INFO - Epoch 98 Batch 20: Train Loss = 0.1490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 20: Train Loss = 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:08:53,293 - INFO - Epoch 98 Batch 40: Train Loss = 0.1268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 40: Train Loss = 0.1268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:09:05,375 - INFO - Epoch 98 Batch 60: Train Loss = 0.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 60: Train Loss = 0.1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:09:18,302 - INFO - Epoch 98 Batch 80: Train Loss = 0.1438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 80: Train Loss = 0.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:09:32,374 - INFO - Epoch 98 Batch 100: Train Loss = 0.1417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 100: Train Loss = 0.1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:09:44,994 - INFO - Epoch 98 Batch 120: Train Loss = 0.2011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 120: Train Loss = 0.2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:09:55,698 - INFO - Epoch 98: Loss = 0.1511 Valid loss = 0.1394 roc = 0.9220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Loss = 0.1511 Valid loss = 0.1394 roc = 0.9220\n",
      "confusion matrix:\n",
      "[[3716   26]\n",
      " [ 151  141]]\n",
      "accuracy = 0.9561229348182678\n",
      "precision class 0 = 0.9609516263008118\n",
      "precision class 1 = 0.8443113565444946\n",
      "recall class 0 = 0.9930518269538879\n",
      "recall class 1 = 0.482876718044281\n",
      "AUC of ROC = 0.9220043856116793\n",
      "AUC of PRC = 0.6929412019338587\n",
      "min(+P, Se) = 0.6232876712328768\n",
      "f1_score = 0.6143791117049759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:09:56,350 - INFO - Epoch 99 Batch 0: Train Loss = 0.1466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 0: Train Loss = 0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:10:09,957 - INFO - Epoch 99 Batch 20: Train Loss = 0.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 20: Train Loss = 0.1998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:10:23,436 - INFO - Epoch 99 Batch 40: Train Loss = 0.1168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 40: Train Loss = 0.1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:10:36,932 - INFO - Epoch 99 Batch 60: Train Loss = 0.1258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 60: Train Loss = 0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:10:48,898 - INFO - Epoch 99 Batch 80: Train Loss = 0.1461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 80: Train Loss = 0.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:01,652 - INFO - Epoch 99 Batch 100: Train Loss = 0.1402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 100: Train Loss = 0.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:14,177 - INFO - Epoch 99 Batch 120: Train Loss = 0.1552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 120: Train Loss = 0.1552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:23,992 - INFO - Epoch 99: Loss = 0.1527 Valid loss = 0.1367 roc = 0.9257\n",
      "2023-11-08 14:11:24,026 - INFO - auroc 0.9295\n",
      "2023-11-08 14:11:24,027 - INFO - auprc 0.7015\n",
      "2023-11-08 14:11:24,028 - INFO - minpse 0.6233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.1527 Valid loss = 0.1367 roc = 0.9257\n",
      "confusion matrix:\n",
      "[[3716   26]\n",
      " [ 149  143]]\n",
      "accuracy = 0.9566187262535095\n",
      "precision class 0 = 0.9614489078521729\n",
      "precision class 1 = 0.8461538553237915\n",
      "recall class 0 = 0.9930518269538879\n",
      "recall class 1 = 0.4897260367870331\n",
      "AUC of ROC = 0.9256715696682603\n",
      "AUC of PRC = 0.7049421077176191\n",
      "min(+P, Se) = 0.6301369863013698\n",
      "f1_score = 0.6203904516902087\n",
      "auroc 0.9295\n",
      "auprc 0.7015\n",
      "minpse 0.6233\n"
     ]
    }
   ],
   "source": [
    "# Training Teacher\n",
    "# If you don't want to train Teacher Model:\n",
    "# - The pretrained taecher model is in direcrtory './model/', and can be directly loaded, \n",
    "# - Simply skip this cell and load the model to validate on Dev Dataset.\n",
    "# logger.info('Training Teacher')\n",
    "\n",
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "global_best = 0\n",
    "auroc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "history = []\n",
    "\n",
    "pad_token = np.zeros(input_dim)\n",
    "# begin_time = time.time()\n",
    "best_auroc = 0\n",
    "best_auprc = 0\n",
    "best_minpse = 0\n",
    "    \n",
    "if target_dataset == 'PD':    \n",
    "    file_name = './model/pretrained-challenge-front-fill-teacher-2pd' + '-lstm'\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "    counter_batch = 0\n",
    "    model.train()  \n",
    "\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(train_x, train_y, train_mask_x, train_x_len, batch_size, shuffle=True)):  \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "#        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "        opt, decov_loss, emb = model(batch_x, batch_lens)\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1)) # b t 1\n",
    "#             REC_Loss = F.mse_loss(masks * recon, masks * batch_x, reduction='mean').to(device)\n",
    "\n",
    "        loss = BCE_Loss #+ 1000 * decov_loss\n",
    "\n",
    "        epoch_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, loss.cpu().detach().numpy()))\n",
    "            logger.info('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, loss.cpu().detach().numpy()))\n",
    "\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    total_train_loss.append(epoch_loss)\n",
    "\n",
    "    #Validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valid_loss = []\n",
    "        valid_true = []\n",
    "        valid_pred = []\n",
    "        for batch_x, batch_y, batch_mask_x, batch_lens in batch_iter(dev_x, dev_y, dev_mask_x, dev_x_len, batch_size):\n",
    "            batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "            batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "            batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "#            masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "\n",
    "            opt, decov_loss, emb = model(batch_x, batch_lens)\n",
    "\n",
    "            BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "#                 REC_Loss = F.mse_loss(recon, batch_x, reduction='mean').to(device)\n",
    "\n",
    "            valid_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "\n",
    "            y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "            y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "        valid_loss = np.mean(valid_loss)\n",
    "        total_valid_loss.append(valid_loss)\n",
    "        ret = metrics.print_metrics_binary(y_true, y_pred,verbose = 0)\n",
    "        history.append(ret)\n",
    "        #print()\n",
    "\n",
    "        print('Epoch %d: Loss = %.4f Valid loss = %.4f roc = %.4f'%(each_epoch, total_train_loss[-1], total_valid_loss[-1], ret['auroc']))\n",
    "        logger.info('Epoch %d: Loss = %.4f Valid loss = %.4f roc = %.4f'%(each_epoch, total_train_loss[-1], total_valid_loss[-1], ret['auroc']))\n",
    "        metrics.print_metrics_binary(y_true, y_pred)\n",
    "\n",
    "        cur_auroc = ret['auroc']\n",
    "        if cur_auroc > best_auroc:\n",
    "            best_auroc = cur_auroc\n",
    "            best_auprc = ret['auprc']\n",
    "            best_minpse = ret['minpse']\n",
    "            state = {\n",
    "                'net': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'epoch': each_epoch\n",
    "            }\n",
    "            torch.save(state, file_name)\n",
    "            print('------------ Save best model - AUROC: %.4f ------------'%cur_auroc)       \n",
    "\n",
    "print('auroc %.4f'%(best_auroc))\n",
    "print('auprc %.4f'%(best_auprc))\n",
    "print('minpse %.4f'%(best_minpse))  \n",
    "logger.info('auroc %.4f'%(best_auroc))\n",
    "logger.info('auprc %.4f'%(best_auprc))\n",
    "logger.info('minpse %.4f'%(best_minpse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T10:41:54.613732Z",
     "start_time": "2021-01-30T10:41:54.090698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:24,158 - INFO - last saved model is in epoch 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last saved model is in epoch 83\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "distcare_teacher(\n",
       "  (PositionalEncoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (LSTMs): ModuleList(\n",
       "    (0): LSTM(1, 32, batch_first=True)\n",
       "    (1): LSTM(1, 32, batch_first=True)\n",
       "    (2): LSTM(1, 32, batch_first=True)\n",
       "    (3): LSTM(1, 32, batch_first=True)\n",
       "    (4): LSTM(1, 32, batch_first=True)\n",
       "    (5): LSTM(1, 32, batch_first=True)\n",
       "    (6): LSTM(1, 32, batch_first=True)\n",
       "    (7): LSTM(1, 32, batch_first=True)\n",
       "    (8): LSTM(1, 32, batch_first=True)\n",
       "    (9): LSTM(1, 32, batch_first=True)\n",
       "    (10): LSTM(1, 32, batch_first=True)\n",
       "    (11): LSTM(1, 32, batch_first=True)\n",
       "    (12): LSTM(1, 32, batch_first=True)\n",
       "    (13): LSTM(1, 32, batch_first=True)\n",
       "    (14): LSTM(1, 32, batch_first=True)\n",
       "    (15): LSTM(1, 32, batch_first=True)\n",
       "    (16): LSTM(1, 32, batch_first=True)\n",
       "    (17): LSTM(1, 32, batch_first=True)\n",
       "    (18): LSTM(1, 32, batch_first=True)\n",
       "    (19): LSTM(1, 32, batch_first=True)\n",
       "    (20): LSTM(1, 32, batch_first=True)\n",
       "    (21): LSTM(1, 32, batch_first=True)\n",
       "    (22): LSTM(1, 32, batch_first=True)\n",
       "    (23): LSTM(1, 32, batch_first=True)\n",
       "    (24): LSTM(1, 32, batch_first=True)\n",
       "    (25): LSTM(1, 32, batch_first=True)\n",
       "    (26): LSTM(1, 32, batch_first=True)\n",
       "    (27): LSTM(1, 32, batch_first=True)\n",
       "    (28): LSTM(1, 32, batch_first=True)\n",
       "    (29): LSTM(1, 32, batch_first=True)\n",
       "    (30): LSTM(1, 32, batch_first=True)\n",
       "    (31): LSTM(1, 32, batch_first=True)\n",
       "    (32): LSTM(1, 32, batch_first=True)\n",
       "    (33): LSTM(1, 32, batch_first=True)\n",
       "  )\n",
       "  (LastStepAttentions): ModuleList(\n",
       "    (0): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (1): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (2): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (3): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (4): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (5): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (6): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (7): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (8): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (9): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (10): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (11): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (12): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (13): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (14): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (15): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (16): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (17): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (18): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (19): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (20): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (21): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (22): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (23): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (24): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (25): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (26): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (27): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (28): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (29): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (30): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (31): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (32): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (33): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "  )\n",
       "  (FinalAttentionQKV): FinalAttentionQKV(\n",
       "    (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_out): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (tanh): Tanh()\n",
       "    (softmax): Softmax(dim=None)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (MultiHeadedAttention): MultiHeadedAttention(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (final_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (SublayerConnection): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (PositionwiseFeedForward): PositionwiseFeedForward(\n",
       "    (w_1): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (w_2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (demo_proj_main): Linear(in_features=12, out_features=32, bias=True)\n",
       "  (demo_proj): Linear(in_features=12, out_features=32, bias=True)\n",
       "  (Linear): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (output): Linear(in_features=34, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (tanh): Tanh()\n",
       "  (softmax): Softmax(dim=None)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if target_dataset == 'PD':    \n",
    "    file_name = './model/pretrained-challenge-front-fill-teacher-2pd' + '-lstm'\n",
    "    \n",
    "checkpoint = torch.load(file_name, \\\n",
    "                        map_location=torch.device(\"cuda:2\" if torch.cuda.is_available() == True else 'cpu') )\n",
    "save_epoch = checkpoint['epoch']\n",
    "print(\"last saved model is in epoch {}\".format(save_epoch))\n",
    "logger.info(\"last saved model is in epoch {}\".format(save_epoch))\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T10:42:04.714142Z",
     "start_time": "2021-01-30T10:41:56.611967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:24,728 - INFO - Batch 0: Test Loss = 0.1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Test Loss = 0.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:31,202 - INFO - \n",
      "==>Predicting on test\n",
      "2023-11-08 14:11:31,204 - INFO - Test Loss = 0.1322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==>Predicting on test\n",
      "Test Loss = 0.1322\n",
      "confusion matrix:\n",
      "[[3715   21]\n",
      " [ 152  145]]\n",
      "accuracy = 0.9571039080619812\n",
      "precision class 0 = 0.9606930613517761\n",
      "precision class 1 = 0.8734939694404602\n",
      "recall class 0 = 0.9943790435791016\n",
      "recall class 1 = 0.48821547627449036\n",
      "AUC of ROC = 0.942715881152712\n",
      "AUC of PRC = 0.7341192604889052\n",
      "min(+P, Se) = 0.6835016835016835\n",
      "f1_score = 0.6263498668117478\n"
     ]
    }
   ],
   "source": [
    "batch_loss = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "pad_token = np.zeros(34)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(test_x, test_y, test_mask_x, test_x_len, batch_size, shuffle=True)):  \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "        opt, decov_loss, emb = model(batch_x, batch_lens)\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "#             REC_Loss = F.mse_loss(masks * recon, masks * batch_x, reduction='mean').to(device)\n",
    "\n",
    "        model_loss =  BCE_Loss \n",
    "\n",
    "        loss = model_loss\n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        if step % 20 == 0:\n",
    "            print('Batch %d: Test Loss = %.4f'%(step, loss.cpu().detach().numpy()))\n",
    "            logger.info('Batch %d: Test Loss = %.4f'%(step, loss.cpu().detach().numpy()))\n",
    "        y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "print(\"\\n==>Predicting on test\")\n",
    "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "logger.info(\"\\n==>Predicting on test\")\n",
    "logger.info('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "test_res = metrics.print_metrics_binary(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:02.685007Z",
     "start_time": "2021-02-10T15:06:02.655919Z"
    }
   },
   "outputs": [],
   "source": [
    "class distcare_student(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(distcare_student, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
    "\n",
    "        self.LSTMs = clones(nn.LSTM(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        self.generalLSTM =  nn.LSTM(1, self.hidden_dim, batch_first = True)\n",
    "        self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 8, attention_type='concat', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
    "        \n",
    "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
    "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.Linear = nn.Linear(self.hidden_dim, 1)\n",
    "        self.output = nn.Linear(34, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.FC_embed = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "        self.to_MMD = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "    def forward(self, input, input_diff, lens, tar, train):\n",
    "        lens = lens.to('cpu')\n",
    "        tar_x, tar_lens = tar\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "#         demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        feature_dim_diff = input_diff.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "        # Initialization\n",
    "        #cur_hs = Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0))\n",
    "\n",
    "        # forward\n",
    "        # LSTM_embeded_input = self.LSTMs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b t h\n",
    "        # Attention_embeded_input = self.LastStepAttentions[0](LSTM_embeded_input)[0].unsqueeze(1)# b 1 h\n",
    "        # for i in range(feature_dim-1):\n",
    "        #     embeded_input = self.LSTMs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b 1 h\n",
    "        #     embeded_input = self.LastStepAttentions[i+1](embeded_input)[0].unsqueeze(1)# b 1 h\n",
    "        #     Attention_embeded_input = torch.cat((Attention_embeded_input, embeded_input), 1)# b i h\n",
    "\n",
    "        # Attention_embeded_input = torch.cat((Attention_embeded_input, demo_main), 1)# b i+1 h\n",
    "        # posi_input = self.dropout(Attention_embeded_input) # batch_size * d_input+1 * hidden_dim\n",
    "\n",
    "#         input = pack_padded_sequence(input, lens, batch_first=True)\n",
    "        \n",
    "        LSTM_embeded_input = self.LSTMs[0](pack_padded_sequence(input[:,:,0].unsqueeze(-1), lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "#         print(LSTM_embeded_input.shape)\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.LSTMs[i+1](pack_padded_sequence(input[:,:,i+1].unsqueeze(-1), lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "            LSTM_embeded_input = torch.cat((LSTM_embeded_input, embeded_input), 1)\n",
    "\n",
    "#         LSTM_embeded_input = torch.cat((LSTM_embeded_input, demo_main), 1)# b i+1 h\n",
    "        General_LSTM_embeded_input = self.generalLSTM(pack_padded_sequence(input_diff[:,:,0].unsqueeze(-1), lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "        for i in range(1,feature_dim_diff):\n",
    "            general_embeded_input = self.generalLSTM(pack_padded_sequence(input_diff[:,:,i].unsqueeze(-1), lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "            General_LSTM_embeded_input = torch.cat((General_LSTM_embeded_input,general_embeded_input), 1)\n",
    "        \n",
    "#         posi_input = self.dropout(LSTM_embeded_input) # batch_size * d_input * hidden_dim\n",
    "        posi_input = self.dropout(torch.cat((LSTM_embeded_input, General_LSTM_embeded_input), 1)) # batch_size * d_input * hidden_dim\n",
    "    \n",
    "        # cul tar loss\n",
    "        if train:\n",
    "            tar_lens = tar_lens.to('cpu')\n",
    "            LSTM_tar_input = self.LSTMs[0](pack_padded_sequence(tar_x[:,:,0].unsqueeze(-1), tar_lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "            for i in range(feature_dim-1):\n",
    "                tar_input = self.LSTMs[i+1](pack_padded_sequence(tar_x[:,:,i+1].unsqueeze(-1), tar_lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "                LSTM_tar_input = torch.cat((LSTM_tar_input, tar_input), 1)\n",
    "            LSTM_embeded_output = self.to_MMD(LSTM_embeded_input)\n",
    "            LSTM_tar_output = self.to_MMD(LSTM_tar_input)\n",
    "        else:\n",
    "            LSTM_embeded_output = []\n",
    "            LSTM_tar_output = []\n",
    "        \n",
    "        #mask = subsequent_mask(time_step).to(device) # 1 t t 下三角 N to 1任务不用mask\n",
    "#         contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
    "    \n",
    "#         DeCov_loss = contexts[1]\n",
    "#         contexts = contexts[0]\n",
    "\n",
    "#         contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
    "#         #contexts = contexts.view(batch_size, feature_dim * self.hidden_dim)#\n",
    "#         # contexts = torch.matmul(self.Wproj, contexts) + self.bproj\n",
    "#         # contexts = contexts.squeeze()\n",
    "#         # demo_key = self.demo_proj(demo_input)# b hidden_dim\n",
    "#         # demo_key = self.relu(demo_key)\n",
    "#         # input_dim_scores = torch.matmul(contexts, demo_key.unsqueeze(-1)).squeeze() # b i\n",
    "#         # input_dim_scores = self.dropout(self.sigmoid(input_dim_scores)).unsqueeze(1)# b i\n",
    "        \n",
    "#         # weighted_contexts = torch.matmul(input_dim_scores, contexts).squeeze()\n",
    "# #         print(contexts.shape)\n",
    "\n",
    "#         weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
    "#         output_embed = self.FC_embed(weighted_contexts)\n",
    "#         output = self.output(self.dropout(weighted_contexts))# b 1\n",
    "#         output = self.sigmoid(output)\n",
    "        contexts = self.Linear(posi_input).squeeze()# b i\n",
    "        output = self.output(self.dropout(contexts))# b 1\n",
    "        output = self.sigmoid(output)\n",
    "#         print(weighted_contexts.shape)\n",
    "          \n",
    "        return output, None, contexts, [LSTM_embeded_output, LSTM_tar_output]\n",
    "    #, self.MultiHeadedAttention.attn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:31,276 - INFO - load target data\n",
      "2023-11-08 14:11:31,303 - INFO - [[-0.84276482  0.37440202  0.67961237 -1.39897541 -0.48314192 -0.21203008\n",
      "   1.58875966  0.79457896 -0.86126933 -0.48197292 -0.67452243  0.71372084\n",
      "  -1.44708995 -0.77101282 -1.42318156 -0.58514053]\n",
      " [-0.84276482  0.37440202  0.67961237 -1.39897541 -0.48314192 -0.21203008\n",
      "   1.58875966  0.79457896 -0.86126933 -0.48197292 -0.67452243  0.71372084\n",
      "  -1.44708995 -0.77101282 -1.42318156 -0.58514053]\n",
      " [-0.53383302  0.43115698  0.89646606 -1.34242175 -0.69460513 -0.21203008\n",
      "   0.89527972  0.03870413 -0.86126933  0.07263348 -0.50511021 -0.28657272\n",
      "   0.39888266 -1.37943777 -0.82370897 -0.92211195]\n",
      " [-0.71138003  0.09062723  0.55763217 -1.39897541 -0.8637757  -0.21203008\n",
      "   0.46852283  0.33565496 -0.86126933 -0.57440732 -0.50142734 -0.17115423\n",
      "  -0.25396131 -0.77101282 -0.67384083 -2.43848334]\n",
      " [-0.71138003  0.09062723  0.55763217 -1.39897541 -0.8637757  -0.21203008\n",
      "   0.46852283  0.33565496 -0.86126933 -0.57440732 -0.50142734 -0.17115423\n",
      "  -0.25396131  0.64864541  0.0754999  -0.58514053]\n",
      " [-0.51252738  0.60142185  0.50341875 -1.45552908 -0.52543456 -0.41638034\n",
      "   0.7885905   0.2816639  -0.58901728  0.59026612 -0.34306374 -0.74824667\n",
      "  -0.18642573  0.64864541  0.0754999  -0.58514053]\n",
      " [-0.46281422 -0.24990251 -0.37754938 -1.11620709 -1.17392174  0.19667043\n",
      "   0.68190128  0.4706326  -0.60716742 -0.14920908 -0.335698   -0.44046404\n",
      "  -1.2444832   0.39513501 -0.52397268 -0.83786909]\n",
      " [-0.46281422 -0.24990251 -0.37754938 -1.11620709 -1.17392174  0.19667043\n",
      "   0.68190128  0.4706326  -0.60716742 -0.14920908 -0.335698   -0.44046404\n",
      "  -1.2444832   0.69934749 -0.67384083 -0.92211195]\n",
      " [-0.64391217  0.03387228 -0.17424904 -1.37069858 -0.55362966  0.40102068\n",
      "   1.24201969  0.4706326  -0.60716742 -0.87019741 -0.4351356   0.02120991\n",
      "  -1.06438832  0.69934749 -0.67384083 -0.92211195]\n",
      " [-0.64391217  0.03387228 -0.17424904 -1.37069858 -0.55362966  0.40102068\n",
      "   1.24201969  0.4706326  -0.60716742 -0.87019741 -0.4351356   0.02120991\n",
      "  -1.06438832  1.05426204 -0.67384083 -0.0796834 ]\n",
      " [-1.03806653  0.26089211  0.16458485 -1.45552908 -1.6391408   0.19667043\n",
      "   1.24201969  0.4706326  -0.66161783 -0.5004598  -0.46091572  0.02120991\n",
      "  -1.17694762  0.09092253 -1.34824748 -1.25908337]\n",
      " [-0.89957987  0.48791194  0.15103149 -1.41311383 -0.65231249  0.19667043\n",
      "   0.14845517  0.4706326  -0.75236851 -0.94414493 -0.950738    0.17510123\n",
      "  -1.04187645  0.54724125 -0.67384083 -1.0063548 ]\n",
      " [-0.5764443   0.31764706 -0.12003562 -1.3000065  -0.63821494  0.19667043\n",
      "   0.86860741  0.4706326  -0.80681892 -0.24164348 -1.00229824 -4.7109481\n",
      "   6.99485797  0.54724125 -0.67384083 -1.0063548 ]\n",
      " [-0.5764443   0.31764706 -0.12003562 -1.3000065  -0.63821494  0.19667043\n",
      "   0.86860741  0.4706326  -0.80681892 -0.24164348 -1.00229824 -4.7109481\n",
      "   6.99485797  0.24302877  0.82484063 -1.42756908]\n",
      " [-0.2320031  -0.64718721 -0.41820945 -1.15862233 -1.32899476 -0.21203008\n",
      "   0.25514439  1.1995119  -0.75236851 -0.33407788 -0.93600651 -0.09420857\n",
      "  -0.09637829  0.24302877  0.82484063 -1.42756908]\n",
      " [-0.2320031  -0.64718721 -0.41820945 -1.15862233 -1.32899476 -0.21203008\n",
      "   0.25514439  1.1995119  -0.75236851 -0.33407788 -0.93600651 -0.09420857\n",
      "  -0.09637829 -1.07522529 -1.04851119  2.27911655]\n",
      " [-0.2142484  -0.02288268  0.01549794 -1.08793025 -0.92016589  0.19667043\n",
      "  -1.05179858  1.1995119  -0.75236851  0.96000372 -0.70398543 -0.5174097\n",
      "   0.62400127 -1.07522529 -1.04851119  2.27911655]\n",
      " [-0.2142484  -0.02288268  0.01549794 -1.08793025 -0.92016589  0.19667043\n",
      "  -1.05179858  1.1995119  -0.75236851  0.96000372 -0.70398543 -0.5174097\n",
      "   0.62400127 -0.26399202 -0.67384083  2.27911655]\n",
      " [-0.2142484  -0.02288268  0.01549794 -1.08793025 -0.92016589  0.19667043\n",
      "  -1.05179858  1.1995119  -0.75236851  0.96000372 -0.70398543 -0.5174097\n",
      "   0.62400127 -0.77101282 -0.67384083 -0.66938338]\n",
      " [-0.2142484  -0.02288268  0.01549794 -1.08793025 -0.92016589  0.19667043\n",
      "  -1.05179858  1.1995119  -0.75236851  0.96000372 -0.70398543 -0.5174097\n",
      "   0.62400127 -0.77101282 -0.67384083  0.08880231]]\n",
      "2023-11-08 14:11:31,312 - INFO - 16\n",
      "2023-11-08 14:11:31,313 - INFO - 325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.84276482  0.37440202  0.67961237 -1.39897541 -0.48314192 -0.21203008\n",
      "   1.58875966  0.79457896 -0.86126933 -0.48197292 -0.67452243  0.71372084\n",
      "  -1.44708995 -0.77101282 -1.42318156 -0.58514053]\n",
      " [-0.84276482  0.37440202  0.67961237 -1.39897541 -0.48314192 -0.21203008\n",
      "   1.58875966  0.79457896 -0.86126933 -0.48197292 -0.67452243  0.71372084\n",
      "  -1.44708995 -0.77101282 -1.42318156 -0.58514053]\n",
      " [-0.53383302  0.43115698  0.89646606 -1.34242175 -0.69460513 -0.21203008\n",
      "   0.89527972  0.03870413 -0.86126933  0.07263348 -0.50511021 -0.28657272\n",
      "   0.39888266 -1.37943777 -0.82370897 -0.92211195]\n",
      " [-0.71138003  0.09062723  0.55763217 -1.39897541 -0.8637757  -0.21203008\n",
      "   0.46852283  0.33565496 -0.86126933 -0.57440732 -0.50142734 -0.17115423\n",
      "  -0.25396131 -0.77101282 -0.67384083 -2.43848334]\n",
      " [-0.71138003  0.09062723  0.55763217 -1.39897541 -0.8637757  -0.21203008\n",
      "   0.46852283  0.33565496 -0.86126933 -0.57440732 -0.50142734 -0.17115423\n",
      "  -0.25396131  0.64864541  0.0754999  -0.58514053]\n",
      " [-0.51252738  0.60142185  0.50341875 -1.45552908 -0.52543456 -0.41638034\n",
      "   0.7885905   0.2816639  -0.58901728  0.59026612 -0.34306374 -0.74824667\n",
      "  -0.18642573  0.64864541  0.0754999  -0.58514053]\n",
      " [-0.46281422 -0.24990251 -0.37754938 -1.11620709 -1.17392174  0.19667043\n",
      "   0.68190128  0.4706326  -0.60716742 -0.14920908 -0.335698   -0.44046404\n",
      "  -1.2444832   0.39513501 -0.52397268 -0.83786909]\n",
      " [-0.46281422 -0.24990251 -0.37754938 -1.11620709 -1.17392174  0.19667043\n",
      "   0.68190128  0.4706326  -0.60716742 -0.14920908 -0.335698   -0.44046404\n",
      "  -1.2444832   0.69934749 -0.67384083 -0.92211195]\n",
      " [-0.64391217  0.03387228 -0.17424904 -1.37069858 -0.55362966  0.40102068\n",
      "   1.24201969  0.4706326  -0.60716742 -0.87019741 -0.4351356   0.02120991\n",
      "  -1.06438832  0.69934749 -0.67384083 -0.92211195]\n",
      " [-0.64391217  0.03387228 -0.17424904 -1.37069858 -0.55362966  0.40102068\n",
      "   1.24201969  0.4706326  -0.60716742 -0.87019741 -0.4351356   0.02120991\n",
      "  -1.06438832  1.05426204 -0.67384083 -0.0796834 ]\n",
      " [-1.03806653  0.26089211  0.16458485 -1.45552908 -1.6391408   0.19667043\n",
      "   1.24201969  0.4706326  -0.66161783 -0.5004598  -0.46091572  0.02120991\n",
      "  -1.17694762  0.09092253 -1.34824748 -1.25908337]\n",
      " [-0.89957987  0.48791194  0.15103149 -1.41311383 -0.65231249  0.19667043\n",
      "   0.14845517  0.4706326  -0.75236851 -0.94414493 -0.950738    0.17510123\n",
      "  -1.04187645  0.54724125 -0.67384083 -1.0063548 ]\n",
      " [-0.5764443   0.31764706 -0.12003562 -1.3000065  -0.63821494  0.19667043\n",
      "   0.86860741  0.4706326  -0.80681892 -0.24164348 -1.00229824 -4.7109481\n",
      "   6.99485797  0.54724125 -0.67384083 -1.0063548 ]\n",
      " [-0.5764443   0.31764706 -0.12003562 -1.3000065  -0.63821494  0.19667043\n",
      "   0.86860741  0.4706326  -0.80681892 -0.24164348 -1.00229824 -4.7109481\n",
      "   6.99485797  0.24302877  0.82484063 -1.42756908]\n",
      " [-0.2320031  -0.64718721 -0.41820945 -1.15862233 -1.32899476 -0.21203008\n",
      "   0.25514439  1.1995119  -0.75236851 -0.33407788 -0.93600651 -0.09420857\n",
      "  -0.09637829  0.24302877  0.82484063 -1.42756908]\n",
      " [-0.2320031  -0.64718721 -0.41820945 -1.15862233 -1.32899476 -0.21203008\n",
      "   0.25514439  1.1995119  -0.75236851 -0.33407788 -0.93600651 -0.09420857\n",
      "  -0.09637829 -1.07522529 -1.04851119  2.27911655]\n",
      " [-0.2142484  -0.02288268  0.01549794 -1.08793025 -0.92016589  0.19667043\n",
      "  -1.05179858  1.1995119  -0.75236851  0.96000372 -0.70398543 -0.5174097\n",
      "   0.62400127 -1.07522529 -1.04851119  2.27911655]\n",
      " [-0.2142484  -0.02288268  0.01549794 -1.08793025 -0.92016589  0.19667043\n",
      "  -1.05179858  1.1995119  -0.75236851  0.96000372 -0.70398543 -0.5174097\n",
      "   0.62400127 -0.26399202 -0.67384083  2.27911655]\n",
      " [-0.2142484  -0.02288268  0.01549794 -1.08793025 -0.92016589  0.19667043\n",
      "  -1.05179858  1.1995119  -0.75236851  0.96000372 -0.70398543 -0.5174097\n",
      "   0.62400127 -0.77101282 -0.67384083 -0.66938338]\n",
      " [-0.2142484  -0.02288268  0.01549794 -1.08793025 -0.92016589  0.19667043\n",
      "  -1.05179858  1.1995119  -0.75236851  0.96000372 -0.70398543 -0.5174097\n",
      "   0.62400127 -0.77101282 -0.67384083  0.08880231]]\n",
      "16\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"load target data\")\n",
    "if target_dataset == 'PD':\n",
    "    data_path = './data/PD/'\n",
    "    tar_all_x = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    tar_all_time = pickle.load(open(data_path + 'y_z.pkl', 'rb'))\n",
    "    tar_all_x_len = [len(i) for i in tar_all_x]\n",
    "\n",
    "    tar_subset_idx = [0, 2, 3, 4, 5, 7, 8, 9, 12, 16, 17, 19, 20, 56, 57, 58]\n",
    "    tar_other_idx = list(range(69))\n",
    "    for i in tar_subset_idx:\n",
    "        tar_other_idx.remove(i)\n",
    "    for i in range(len(tar_all_x)):\n",
    "        cur = np.array(tar_all_x[i], dtype=float)\n",
    "        cur_subset = cur[:, tar_subset_idx]\n",
    "        cur_other = cur[:, tar_other_idx]\n",
    "        tar_all_x[i] = cur_subset\n",
    "    \n",
    "print(tar_all_x[0])\n",
    "print(len(tar_all_x[0][0]))\n",
    "print(len(tar_all_x))\n",
    "logger.info(tar_all_x[0])\n",
    "logger.info(len(tar_all_x[0][0]))\n",
    "logger.info(len(tar_all_x))\n",
    "\n",
    "assert(subset_cnt == len(tar_subset_idx))\n",
    "\n",
    "examples = []\n",
    "for idx in range(len(tar_all_x)):\n",
    "    examples.append((tar_all_x[idx], tar_all_time[idx], tar_all_x_len[idx]))\n",
    "examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "tar_all_x = [e[0] for e in examples]\n",
    "tar_all_time = [e[1] for e in examples]\n",
    "tar_all_x_len = [e[2] for e in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:06.077135Z",
     "start_time": "2021-02-10T15:06:05.101451Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# epochs = 150\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "input_dim = subset_cnt\n",
    "hidden_dim = 32\n",
    "d_model = 32\n",
    "MHD_num_head = 4\n",
    "d_ff = 64\n",
    "output_dim = 1\n",
    "\n",
    "model_student = distcare_student(input_dim = input_dim, hidden_dim = hidden_dim, d_model=d_model, MHD_num_head=MHD_num_head, d_ff=d_ff, output_dim = output_dim).to(device)\n",
    "# input_dim, d_model, d_k, d_v, MHD_num_head, d_ff, output_dim\n",
    "optimizer_student = torch.optim.Adam(model_student.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T10:43:10.804571Z",
     "start_time": "2021-01-30T10:42:10.264393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:31,815 - INFO - Batch 0: Test Loss = 0.1479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Test Loss = 0.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:39,647 - INFO - Batch 20: Test Loss = 0.1729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20: Test Loss = 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:47,763 - INFO - Batch 40: Test Loss = 0.1553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 40: Test Loss = 0.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:11:55,230 - INFO - Batch 60: Test Loss = 0.1434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60: Test Loss = 0.1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:12:02,893 - INFO - Batch 80: Test Loss = 0.0945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 80: Test Loss = 0.0945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:12:10,760 - INFO - Batch 100: Test Loss = 0.0808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100: Test Loss = 0.0808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:12:18,265 - INFO - Batch 120: Test Loss = 0.1037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 120: Test Loss = 0.1037\n"
     ]
    }
   ],
   "source": [
    "#Generate Teacher model embedding\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "model.eval()\n",
    "\n",
    "train_teacher_emb = []\n",
    "batch_loss = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "pad_token = np.zeros(34)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(train_x, train_y, train_mask_x, train_x_len, batch_size, shuffle=False)):  \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "        opt, decov_loss, emb = model(batch_x, batch_lens)\n",
    "        train_teacher_emb.append(emb.cpu().detach().numpy())\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "#             REC_Loss = F.mse_loss(masks * recon, masks * batch_x, reduction='mean').to(device)\n",
    "\n",
    "        model_loss =  BCE_Loss \n",
    "        if step % 20 == 0:\n",
    "            print('Batch %d: Test Loss = %.4f'%(step, model_loss.cpu().detach().numpy()))\n",
    "            logger.info('Batch %d: Test Loss = %.4f'%(step, model_loss.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_all_x = torch.tensor(pad_sents(tar_all_x, np.zeros(len(tar_subset_idx))), dtype=torch.float32).to(device)\n",
    "tar_all_x_len = torch.tensor(tar_all_x_len, dtype=torch.float32).to(device).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMDLoss(nn.Module):\n",
    "    def __init__(self, kernel_type='rbf', kernel_mul=2.0, kernel_num=5, fix_sigma=None, **kwargs):\n",
    "        super(MMDLoss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = None\n",
    "        self.kernel_type = kernel_type\n",
    "\n",
    "    def guassian_kernel(self, source, target, kernel_mul, kernel_num, fix_sigma):\n",
    "        n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        total0 = total.unsqueeze(0).expand(\n",
    "            int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(\n",
    "            int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0-total1)**2).sum(2)\n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul**i)\n",
    "                          for i in range(kernel_num)]\n",
    "        kernel_val = [torch.exp(-L2_distance / bandwidth_temp)\n",
    "                      for bandwidth_temp in bandwidth_list]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def linear_mmd2(self, f_of_X, f_of_Y):\n",
    "        loss = 0.0\n",
    "        delta = f_of_X.float().mean(0) - f_of_Y.float().mean(0)\n",
    "        loss = delta.dot(delta.T)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        if self.kernel_type == 'linear':\n",
    "            return self.linear_mmd2(source, target)\n",
    "        elif self.kernel_type == 'rbf':\n",
    "            batch_size = int(source.size()[0])\n",
    "            kernels = self.guassian_kernel(\n",
    "                source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
    "            XX = torch.mean(kernels[:batch_size, :batch_size])\n",
    "            YY = torch.mean(kernels[batch_size:, batch_size:])\n",
    "            XY = torch.mean(kernels[:batch_size, batch_size:])\n",
    "            YX = torch.mean(kernels[batch_size:, :batch_size])\n",
    "            loss = torch.mean(XX + YY - XY - YX)\n",
    "            return loss\n",
    "\n",
    "class MultitaskLoss(nn.Module):\n",
    "    def __init__(self, task_num=3):\n",
    "        super(MultitaskLoss, self).__init__()\n",
    "        self.task_num = task_num\n",
    "        self.alpha = nn.Parameter(torch.ones((task_num)), requires_grad=True)\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.kl = nn.KLDivLoss(reduce=True, size_average=True)\n",
    "        self.tar = MMDLoss()\n",
    "\n",
    "    def forward(self, opt_student, batch_y, emb_student, emb_teacher, tar_source, tar_tar):\n",
    "        BCE_Loss = self.bce(opt_student, batch_y)\n",
    "        emb_Loss = self.kl(emb_student, emb_teacher)\n",
    "        tar_Loss = self.tar(source=tar_source, target=tar_tar)\n",
    "        return BCE_Loss * self.alpha[0] + emb_Loss * self.alpha[1] + tar_Loss * self.alpha[2]\n",
    "\n",
    "def get_multitask_loss(opt_student, batch_y, emb_student, emb_teacher, tar_source, tar_tar):\n",
    "    mtl = MultitaskLoss(task_num=3)\n",
    "    return mtl(opt_student, batch_y, emb_student, emb_teacher, tar_source, tar_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T15:39:24.489286Z",
     "start_time": "2021-01-30T10:43:58.619303Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:12:20,516 - INFO - Training Student\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:12:21,286 - INFO - Epoch 0 Batch 0: Train Loss = 0.8190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 0: Train Loss = 0.8190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:12:36,342 - INFO - Epoch 0 Batch 20: Train Loss = 0.6159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 20: Train Loss = 0.6159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:12:50,557 - INFO - Epoch 0 Batch 40: Train Loss = 0.4856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 40: Train Loss = 0.4856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:13:04,773 - INFO - Epoch 0 Batch 60: Train Loss = 0.4410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 60: Train Loss = 0.4410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:13:19,860 - INFO - Epoch 0 Batch 80: Train Loss = 0.3073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 80: Train Loss = 0.3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:13:34,343 - INFO - Epoch 0 Batch 100: Train Loss = 0.2774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 100: Train Loss = 0.2774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:13:49,199 - INFO - Epoch 0 Batch 120: Train Loss = 0.3056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 120: Train Loss = 0.3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "2023-11-08 14:13:59,387 - INFO - ------------ Save best model - AUROC: 0.6974 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.0292 Valid loss = 0.2476 roc = 0.6974\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 292    0]]\n",
      "accuracy = 0.9276152849197388\n",
      "precision class 0 = 0.9276152849197388\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.6974252835272325\n",
      "AUC of PRC = 0.28186492078032727\n",
      "min(+P, Se) = 0.2842465753424658\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.6974 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:14:00,082 - INFO - Epoch 1 Batch 0: Train Loss = 0.3385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0: Train Loss = 0.3385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:14:14,746 - INFO - Epoch 1 Batch 20: Train Loss = 0.3160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 20: Train Loss = 0.3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:14:29,301 - INFO - Epoch 1 Batch 40: Train Loss = 0.3291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 40: Train Loss = 0.3291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:14:43,732 - INFO - Epoch 1 Batch 60: Train Loss = 0.3535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 60: Train Loss = 0.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:14:58,679 - INFO - Epoch 1 Batch 80: Train Loss = 0.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 80: Train Loss = 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:15:15,080 - INFO - Epoch 1 Batch 100: Train Loss = 0.2486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 100: Train Loss = 0.2486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:15:30,213 - INFO - Epoch 1 Batch 120: Train Loss = 0.2931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 120: Train Loss = 0.2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "2023-11-08 14:15:40,744 - INFO - ------------ Save best model - AUROC: 0.7162 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.2604 Valid loss = 0.2418 roc = 0.7162\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 292    0]]\n",
      "accuracy = 0.9276152849197388\n",
      "precision class 0 = 0.9276152849197388\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.7162073610917904\n",
      "AUC of PRC = 0.2920914912698616\n",
      "min(+P, Se) = 0.29931972789115646\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7162 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:15:41,643 - INFO - Epoch 2 Batch 0: Train Loss = 0.3378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 0: Train Loss = 0.3378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:15:57,001 - INFO - Epoch 2 Batch 20: Train Loss = 0.3159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 20: Train Loss = 0.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:16:10,769 - INFO - Epoch 2 Batch 40: Train Loss = 0.3231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 40: Train Loss = 0.3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:16:25,020 - INFO - Epoch 2 Batch 60: Train Loss = 0.3503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 60: Train Loss = 0.3503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:16:40,161 - INFO - Epoch 2 Batch 80: Train Loss = 0.2509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 80: Train Loss = 0.2509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:16:54,892 - INFO - Epoch 2 Batch 100: Train Loss = 0.2357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 100: Train Loss = 0.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:17:10,297 - INFO - Epoch 2 Batch 120: Train Loss = 0.2852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Batch 120: Train Loss = 0.2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "/home/zzj/DistCare-plus/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "2023-11-08 14:17:21,059 - INFO - ------------ Save best model - AUROC: 0.7667 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.2572 Valid loss = 0.2301 roc = 0.7667\n",
      "confusion matrix:\n",
      "[[3742    0]\n",
      " [ 292    0]]\n",
      "accuracy = 0.9276152849197388\n",
      "precision class 0 = 0.9276152849197388\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.7666981798613298\n",
      "AUC of PRC = 0.31954898218264915\n",
      "min(+P, Se) = 0.2983606557377049\n",
      "f1_score = nan\n",
      "------------ Save best model - AUROC: 0.7667 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:17:21,672 - INFO - Epoch 3 Batch 0: Train Loss = 0.3118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 0: Train Loss = 0.3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:17:37,274 - INFO - Epoch 3 Batch 20: Train Loss = 0.2840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 20: Train Loss = 0.2840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:17:51,684 - INFO - Epoch 3 Batch 40: Train Loss = 0.2819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 40: Train Loss = 0.2819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:18:05,746 - INFO - Epoch 3 Batch 60: Train Loss = 0.3175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 60: Train Loss = 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:18:20,677 - INFO - Epoch 3 Batch 80: Train Loss = 0.2569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 80: Train Loss = 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:18:35,791 - INFO - Epoch 3 Batch 100: Train Loss = 0.2193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 100: Train Loss = 0.2193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:18:50,737 - INFO - Epoch 3 Batch 120: Train Loss = 0.2580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 120: Train Loss = 0.2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:19:00,917 - INFO - ------------ Save best model - AUROC: 0.7952 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.2487 Valid loss = 0.2235 roc = 0.7952\n",
      "confusion matrix:\n",
      "[[3740    2]\n",
      " [ 282   10]]\n",
      "accuracy = 0.9295983910560608\n",
      "precision class 0 = 0.9298856258392334\n",
      "precision class 1 = 0.8333333134651184\n",
      "recall class 0 = 0.9994655251502991\n",
      "recall class 1 = 0.034246575087308884\n",
      "AUC of ROC = 0.795205570971497\n",
      "AUC of PRC = 0.34631139512266784\n",
      "min(+P, Se) = 0.34935897435897434\n",
      "f1_score = 0.06578947399895115\n",
      "------------ Save best model - AUROC: 0.7952 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:19:01,647 - INFO - Epoch 4 Batch 0: Train Loss = 0.2732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 0: Train Loss = 0.2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:19:15,946 - INFO - Epoch 4 Batch 20: Train Loss = 0.2820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 20: Train Loss = 0.2820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:19:30,244 - INFO - Epoch 4 Batch 40: Train Loss = 0.3043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 40: Train Loss = 0.3043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:19:44,605 - INFO - Epoch 4 Batch 60: Train Loss = 0.3062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 60: Train Loss = 0.3062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:20:00,194 - INFO - Epoch 4 Batch 80: Train Loss = 0.2524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 80: Train Loss = 0.2524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:20:16,073 - INFO - Epoch 4 Batch 100: Train Loss = 0.2225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 100: Train Loss = 0.2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:20:31,409 - INFO - Epoch 4 Batch 120: Train Loss = 0.2576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Batch 120: Train Loss = 0.2576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:20:43,447 - INFO - ------------ Save best model - AUROC: 0.8069 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.2398 Valid loss = 0.2204 roc = 0.8069\n",
      "confusion matrix:\n",
      "[[3740    2]\n",
      " [ 282   10]]\n",
      "accuracy = 0.9295983910560608\n",
      "precision class 0 = 0.9298856258392334\n",
      "precision class 1 = 0.8333333134651184\n",
      "recall class 0 = 0.9994655251502991\n",
      "recall class 1 = 0.034246575087308884\n",
      "AUC of ROC = 0.8069260083612163\n",
      "AUC of PRC = 0.3611964071569757\n",
      "min(+P, Se) = 0.3835616438356164\n",
      "f1_score = 0.06578947399895115\n",
      "------------ Save best model - AUROC: 0.8069 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:20:44,169 - INFO - Epoch 5 Batch 0: Train Loss = 0.2703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 0: Train Loss = 0.2703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:20:59,629 - INFO - Epoch 5 Batch 20: Train Loss = 0.2872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 20: Train Loss = 0.2872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:21:14,025 - INFO - Epoch 5 Batch 40: Train Loss = 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 40: Train Loss = 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:21:29,073 - INFO - Epoch 5 Batch 60: Train Loss = 0.2920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 60: Train Loss = 0.2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:21:43,507 - INFO - Epoch 5 Batch 80: Train Loss = 0.2291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 80: Train Loss = 0.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:21:58,351 - INFO - Epoch 5 Batch 100: Train Loss = 0.2162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 100: Train Loss = 0.2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:22:12,814 - INFO - Epoch 5 Batch 120: Train Loss = 0.2799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 120: Train Loss = 0.2799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:22:23,334 - INFO - ------------ Save best model - AUROC: 0.8134 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.2338 Valid loss = 0.2172 roc = 0.8134\n",
      "confusion matrix:\n",
      "[[3740    2]\n",
      " [ 274   18]]\n",
      "accuracy = 0.9315815567970276\n",
      "precision class 0 = 0.9317389130592346\n",
      "precision class 1 = 0.8999999761581421\n",
      "recall class 0 = 0.9994655251502991\n",
      "recall class 1 = 0.06164383515715599\n",
      "AUC of ROC = 0.8134037544936047\n",
      "AUC of PRC = 0.36573110241786055\n",
      "min(+P, Se) = 0.36333333333333334\n",
      "f1_score = 0.11538461393711599\n",
      "------------ Save best model - AUROC: 0.8134 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:22:23,976 - INFO - Epoch 6 Batch 0: Train Loss = 0.2749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 0: Train Loss = 0.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:22:40,106 - INFO - Epoch 6 Batch 20: Train Loss = 0.2999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 20: Train Loss = 0.2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:22:54,409 - INFO - Epoch 6 Batch 40: Train Loss = 0.2968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 40: Train Loss = 0.2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:23:08,947 - INFO - Epoch 6 Batch 60: Train Loss = 0.3004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 60: Train Loss = 0.3004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:23:23,672 - INFO - Epoch 6 Batch 80: Train Loss = 0.2043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 80: Train Loss = 0.2043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:23:38,680 - INFO - Epoch 6 Batch 100: Train Loss = 0.2010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 100: Train Loss = 0.2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:23:53,750 - INFO - Epoch 6 Batch 120: Train Loss = 0.2113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Batch 120: Train Loss = 0.2113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:24:04,472 - INFO - ------------ Save best model - AUROC: 0.8528 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 0.2314 Valid loss = 0.1886 roc = 0.8528\n",
      "confusion matrix:\n",
      "[[3736    6]\n",
      " [ 253   39]]\n",
      "accuracy = 0.9357957243919373\n",
      "precision class 0 = 0.9365755915641785\n",
      "precision class 1 = 0.8666666746139526\n",
      "recall class 0 = 0.9983965754508972\n",
      "recall class 1 = 0.1335616409778595\n",
      "AUC of ROC = 0.8527534539437557\n",
      "AUC of PRC = 0.5111357513645083\n",
      "min(+P, Se) = 0.5201342281879194\n",
      "f1_score = 0.23145400882339343\n",
      "------------ Save best model - AUROC: 0.8528 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:24:05,134 - INFO - Epoch 7 Batch 0: Train Loss = 0.2521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 0: Train Loss = 0.2521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:24:20,628 - INFO - Epoch 7 Batch 20: Train Loss = 0.2381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 20: Train Loss = 0.2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:24:34,976 - INFO - Epoch 7 Batch 40: Train Loss = 0.2716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 40: Train Loss = 0.2716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:24:50,399 - INFO - Epoch 7 Batch 60: Train Loss = 0.2288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 60: Train Loss = 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:25:05,681 - INFO - Epoch 7 Batch 80: Train Loss = 0.1840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 80: Train Loss = 0.1840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:25:21,693 - INFO - Epoch 7 Batch 100: Train Loss = 0.1388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 100: Train Loss = 0.1388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:25:37,265 - INFO - Epoch 7 Batch 120: Train Loss = 0.1703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 120: Train Loss = 0.1703\n",
      "Epoch 7: Loss = 0.2045 Valid loss = 0.1751 roc = 0.8513\n",
      "confusion matrix:\n",
      "[[3702   40]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9514129757881165\n",
      "precision class 0 = 0.9595645666122437\n",
      "precision class 1 = 0.7727272510528564\n",
      "recall class 0 = 0.9893105030059814\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8512726693658801\n",
      "AUC of PRC = 0.5382125053928862\n",
      "min(+P, Se) = 0.5205479452054794\n",
      "f1_score = 0.581196583965852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:25:48,969 - INFO - Epoch 8 Batch 0: Train Loss = 0.2370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 0: Train Loss = 0.2370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:26:04,315 - INFO - Epoch 8 Batch 20: Train Loss = 0.2625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 20: Train Loss = 0.2625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:26:18,984 - INFO - Epoch 8 Batch 40: Train Loss = 0.2536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 40: Train Loss = 0.2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:26:32,926 - INFO - Epoch 8 Batch 60: Train Loss = 0.2303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 60: Train Loss = 0.2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:26:47,697 - INFO - Epoch 8 Batch 80: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 80: Train Loss = 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:27:02,674 - INFO - Epoch 8 Batch 100: Train Loss = 0.1607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 100: Train Loss = 0.1607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:27:17,013 - INFO - Epoch 8 Batch 120: Train Loss = 0.1672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Batch 120: Train Loss = 0.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:27:27,490 - INFO - ------------ Save best model - AUROC: 0.8616 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 0.2002 Valid loss = 0.1720 roc = 0.8616\n",
      "confusion matrix:\n",
      "[[3708   34]\n",
      " [ 159  133]]\n",
      "accuracy = 0.952156662940979\n",
      "precision class 0 = 0.9588828682899475\n",
      "precision class 1 = 0.796407163143158\n",
      "recall class 0 = 0.9909139275550842\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8615622002738262\n",
      "AUC of PRC = 0.5579003119702619\n",
      "min(+P, Se) = 0.5376712328767124\n",
      "f1_score = 0.5795206839449125\n",
      "------------ Save best model - AUROC: 0.8616 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:27:28,198 - INFO - Epoch 9 Batch 0: Train Loss = 0.2591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 0: Train Loss = 0.2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:27:43,431 - INFO - Epoch 9 Batch 20: Train Loss = 0.2424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 20: Train Loss = 0.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:27:58,648 - INFO - Epoch 9 Batch 40: Train Loss = 0.2499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 40: Train Loss = 0.2499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:28:14,385 - INFO - Epoch 9 Batch 60: Train Loss = 0.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 60: Train Loss = 0.2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:28:29,788 - INFO - Epoch 9 Batch 80: Train Loss = 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 80: Train Loss = 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:28:44,956 - INFO - Epoch 9 Batch 100: Train Loss = 0.1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 100: Train Loss = 0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:28:59,624 - INFO - Epoch 9 Batch 120: Train Loss = 0.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Batch 120: Train Loss = 0.1655\n",
      "Epoch 9: Loss = 0.1985 Valid loss = 0.1751 roc = 0.8537\n",
      "confusion matrix:\n",
      "[[3708   34]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9591308832168579\n",
      "precision class 1 = 0.7976190447807312\n",
      "recall class 0 = 0.9909139275550842\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8537162384777021\n",
      "AUC of PRC = 0.5457878026972875\n",
      "min(+P, Se) = 0.5187713310580204\n",
      "f1_score = 0.5826087149645298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:29:10,401 - INFO - Epoch 10 Batch 0: Train Loss = 0.2141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 0: Train Loss = 0.2141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:29:25,317 - INFO - Epoch 10 Batch 20: Train Loss = 0.2453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 20: Train Loss = 0.2453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:29:39,820 - INFO - Epoch 10 Batch 40: Train Loss = 0.2406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 40: Train Loss = 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:29:54,658 - INFO - Epoch 10 Batch 60: Train Loss = 0.2277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 60: Train Loss = 0.2277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:30:11,141 - INFO - Epoch 10 Batch 80: Train Loss = 0.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 80: Train Loss = 0.1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:30:27,427 - INFO - Epoch 10 Batch 100: Train Loss = 0.1443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 100: Train Loss = 0.1443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:30:43,182 - INFO - Epoch 10 Batch 120: Train Loss = 0.1817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Batch 120: Train Loss = 0.1817\n",
      "Epoch 10: Loss = 0.2049 Valid loss = 0.1710 roc = 0.8593\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9586563110351562\n",
      "precision class 1 = 0.8048780560493469\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.85934742976798\n",
      "AUC of PRC = 0.5687518402432999\n",
      "min(+P, Se) = 0.5392491467576792\n",
      "f1_score = 0.5789473736495302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:30:55,397 - INFO - Epoch 11 Batch 0: Train Loss = 0.2349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 0: Train Loss = 0.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:31:11,446 - INFO - Epoch 11 Batch 20: Train Loss = 0.2641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 20: Train Loss = 0.2641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:31:26,244 - INFO - Epoch 11 Batch 40: Train Loss = 0.2402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 40: Train Loss = 0.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:31:40,639 - INFO - Epoch 11 Batch 60: Train Loss = 0.2328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 60: Train Loss = 0.2328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:31:56,724 - INFO - Epoch 11 Batch 80: Train Loss = 0.1550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 80: Train Loss = 0.1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:32:11,114 - INFO - Epoch 11 Batch 100: Train Loss = 0.1456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 100: Train Loss = 0.1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:32:26,425 - INFO - Epoch 11 Batch 120: Train Loss = 0.1642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 120: Train Loss = 0.1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:32:37,028 - INFO - ------------ Save best model - AUROC: 0.8648 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss = 0.1964 Valid loss = 0.1745 roc = 0.8648\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 185  107]]\n",
      "accuracy = 0.9464551210403442\n",
      "precision class 0 = 0.9525154232978821\n",
      "precision class 1 = 0.7753623127937317\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.3664383590221405\n",
      "AUC of ROC = 0.8648010733400202\n",
      "AUC of PRC = 0.5255898787356915\n",
      "min(+P, Se) = 0.5445205479452054\n",
      "f1_score = 0.49767443298455416\n",
      "------------ Save best model - AUROC: 0.8648 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:32:37,708 - INFO - Epoch 12 Batch 0: Train Loss = 0.2518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 0: Train Loss = 0.2518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:32:53,024 - INFO - Epoch 12 Batch 20: Train Loss = 0.2613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 20: Train Loss = 0.2613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:33:07,827 - INFO - Epoch 12 Batch 40: Train Loss = 0.2861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 40: Train Loss = 0.2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:33:22,816 - INFO - Epoch 12 Batch 60: Train Loss = 0.2838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 60: Train Loss = 0.2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:33:37,720 - INFO - Epoch 12 Batch 80: Train Loss = 0.2118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 80: Train Loss = 0.2118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:33:52,988 - INFO - Epoch 12 Batch 100: Train Loss = 0.1874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 100: Train Loss = 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:34:07,961 - INFO - Epoch 12 Batch 120: Train Loss = 0.2417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Batch 120: Train Loss = 0.2417\n",
      "Epoch 12: Loss = 0.1989 Valid loss = 0.1874 roc = 0.8588\n",
      "confusion matrix:\n",
      "[[3725   17]\n",
      " [ 214   78]]\n",
      "accuracy = 0.9427367448806763\n",
      "precision class 0 = 0.9456714987754822\n",
      "precision class 1 = 0.821052610874176\n",
      "recall class 0 = 0.9954569935798645\n",
      "recall class 1 = 0.267123281955719\n",
      "AUC of ROC = 0.8588431576404092\n",
      "AUC of PRC = 0.4796472250539043\n",
      "min(+P, Se) = 0.5084745762711864\n",
      "f1_score = 0.40310076619075863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:34:19,245 - INFO - Epoch 13 Batch 0: Train Loss = 0.2420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 0: Train Loss = 0.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:34:34,824 - INFO - Epoch 13 Batch 20: Train Loss = 0.2514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 20: Train Loss = 0.2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:34:49,714 - INFO - Epoch 13 Batch 40: Train Loss = 0.2386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 40: Train Loss = 0.2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:35:04,839 - INFO - Epoch 13 Batch 60: Train Loss = 0.2368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 60: Train Loss = 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:35:19,846 - INFO - Epoch 13 Batch 80: Train Loss = 0.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 80: Train Loss = 0.1554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:35:35,586 - INFO - Epoch 13 Batch 100: Train Loss = 0.1488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 100: Train Loss = 0.1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:35:51,487 - INFO - Epoch 13 Batch 120: Train Loss = 0.1759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Batch 120: Train Loss = 0.1759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:36:02,719 - INFO - ------------ Save best model - AUROC: 0.8700 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss = 0.2050 Valid loss = 0.1681 roc = 0.8700\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 162  130]]\n",
      "accuracy = 0.952156662940979\n",
      "precision class 0 = 0.9581719636917114\n",
      "precision class 1 = 0.8074533939361572\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4452054798603058\n",
      "AUC of ROC = 0.8699517875577487\n",
      "AUC of PRC = 0.5748335872429798\n",
      "min(+P, Se) = 0.541095890410959\n",
      "f1_score = 0.5739514432612123\n",
      "------------ Save best model - AUROC: 0.8700 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:36:03,362 - INFO - Epoch 14 Batch 0: Train Loss = 0.2305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 0: Train Loss = 0.2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:36:19,195 - INFO - Epoch 14 Batch 20: Train Loss = 0.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 20: Train Loss = 0.2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:36:34,118 - INFO - Epoch 14 Batch 40: Train Loss = 0.2320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 40: Train Loss = 0.2320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:36:49,154 - INFO - Epoch 14 Batch 60: Train Loss = 0.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 60: Train Loss = 0.2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:37:04,162 - INFO - Epoch 14 Batch 80: Train Loss = 0.1658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 80: Train Loss = 0.1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:37:18,963 - INFO - Epoch 14 Batch 100: Train Loss = 0.1407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 100: Train Loss = 0.1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:37:33,768 - INFO - Epoch 14 Batch 120: Train Loss = 0.1531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 120: Train Loss = 0.1531\n",
      "Epoch 14: Loss = 0.1932 Valid loss = 0.1705 roc = 0.8649\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 162  130]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9581827521324158\n",
      "precision class 1 = 0.8125\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4452054798603058\n",
      "AUC of ROC = 0.8649127270597365\n",
      "AUC of PRC = 0.5604929891320157\n",
      "min(+P, Se) = 0.5205479452054794\n",
      "f1_score = 0.575221252909132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:37:44,531 - INFO - Epoch 15 Batch 0: Train Loss = 0.2324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 0: Train Loss = 0.2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:37:59,488 - INFO - Epoch 15 Batch 20: Train Loss = 0.2393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 20: Train Loss = 0.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:38:13,842 - INFO - Epoch 15 Batch 40: Train Loss = 0.2390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 40: Train Loss = 0.2390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:38:28,603 - INFO - Epoch 15 Batch 60: Train Loss = 0.2294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 60: Train Loss = 0.2294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:38:43,487 - INFO - Epoch 15 Batch 80: Train Loss = 0.1705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 80: Train Loss = 0.1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:38:58,474 - INFO - Epoch 15 Batch 100: Train Loss = 0.1377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 100: Train Loss = 0.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:39:13,740 - INFO - Epoch 15 Batch 120: Train Loss = 0.1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Batch 120: Train Loss = 0.1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:39:23,563 - INFO - ------------ Save best model - AUROC: 0.8728 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss = 0.1982 Valid loss = 0.1663 roc = 0.8728\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9589147567749023\n",
      "precision class 1 = 0.8109756112098694\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8728401411595879\n",
      "AUC of PRC = 0.5834927001158666\n",
      "min(+P, Se) = 0.5513698630136986\n",
      "f1_score = 0.5833333263436843\n",
      "------------ Save best model - AUROC: 0.8728 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:39:24,259 - INFO - Epoch 16 Batch 0: Train Loss = 0.2249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 0: Train Loss = 0.2249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:39:39,653 - INFO - Epoch 16 Batch 20: Train Loss = 0.2343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 20: Train Loss = 0.2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:39:54,000 - INFO - Epoch 16 Batch 40: Train Loss = 0.2218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 40: Train Loss = 0.2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:40:08,329 - INFO - Epoch 16 Batch 60: Train Loss = 0.2104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 60: Train Loss = 0.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:40:23,445 - INFO - Epoch 16 Batch 80: Train Loss = 0.1579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 80: Train Loss = 0.1579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:40:38,576 - INFO - Epoch 16 Batch 100: Train Loss = 0.1206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 100: Train Loss = 0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:40:54,012 - INFO - Epoch 16 Batch 120: Train Loss = 0.1641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Batch 120: Train Loss = 0.1641\n",
      "Epoch 16: Loss = 0.1926 Valid loss = 0.1666 roc = 0.8727\n",
      "confusion matrix:\n",
      "[[3709   33]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9588934779167175\n",
      "precision class 1 = 0.8012048006057739\n",
      "recall class 0 = 0.9911811947822571\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.872736724189687\n",
      "AUC of PRC = 0.5911725191319214\n",
      "min(+P, Se) = 0.5684931506849316\n",
      "f1_score = 0.5807859864470168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:41:05,990 - INFO - Epoch 17 Batch 0: Train Loss = 0.2313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 0: Train Loss = 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:41:21,540 - INFO - Epoch 17 Batch 20: Train Loss = 0.2152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 20: Train Loss = 0.2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:41:35,806 - INFO - Epoch 17 Batch 40: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 40: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:41:51,056 - INFO - Epoch 17 Batch 60: Train Loss = 0.2124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 60: Train Loss = 0.2124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:42:06,728 - INFO - Epoch 17 Batch 80: Train Loss = 0.1663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 80: Train Loss = 0.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:42:21,851 - INFO - Epoch 17 Batch 100: Train Loss = 0.1263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 100: Train Loss = 0.1263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:42:37,075 - INFO - Epoch 17 Batch 120: Train Loss = 0.1474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Batch 120: Train Loss = 0.1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:42:47,628 - INFO - ------------ Save best model - AUROC: 0.8741 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss = 0.1940 Valid loss = 0.1660 roc = 0.8741\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9591520428657532\n",
      "precision class 1 = 0.8072289228439331\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8741058550478463\n",
      "AUC of PRC = 0.5901515940145524\n",
      "min(+P, Se) = 0.5616438356164384\n",
      "f1_score = 0.5851528328472227\n",
      "------------ Save best model - AUROC: 0.8741 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:42:48,416 - INFO - Epoch 18 Batch 0: Train Loss = 0.2207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 0: Train Loss = 0.2207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:43:04,920 - INFO - Epoch 18 Batch 20: Train Loss = 0.2499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 20: Train Loss = 0.2499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:43:19,089 - INFO - Epoch 18 Batch 40: Train Loss = 0.2441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 40: Train Loss = 0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:43:33,532 - INFO - Epoch 18 Batch 60: Train Loss = 0.2337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 60: Train Loss = 0.2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:43:48,879 - INFO - Epoch 18 Batch 80: Train Loss = 0.1686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 80: Train Loss = 0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:44:04,511 - INFO - Epoch 18 Batch 100: Train Loss = 0.1435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 100: Train Loss = 0.1435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:44:19,071 - INFO - Epoch 18 Batch 120: Train Loss = 0.1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Batch 120: Train Loss = 0.1704\n",
      "Epoch 18: Loss = 0.1932 Valid loss = 0.1661 roc = 0.8740\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9591625928878784\n",
      "precision class 1 = 0.8121212124824524\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8739923709392823\n",
      "AUC of PRC = 0.5858248866543356\n",
      "min(+P, Se) = 0.5513698630136986\n",
      "f1_score = 0.5864332805719331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:44:30,660 - INFO - Epoch 19 Batch 0: Train Loss = 0.2013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 0: Train Loss = 0.2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:44:46,241 - INFO - Epoch 19 Batch 20: Train Loss = 0.2533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 20: Train Loss = 0.2533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:45:01,292 - INFO - Epoch 19 Batch 40: Train Loss = 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 40: Train Loss = 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:45:15,875 - INFO - Epoch 19 Batch 60: Train Loss = 0.2163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 60: Train Loss = 0.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:45:31,349 - INFO - Epoch 19 Batch 80: Train Loss = 0.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 80: Train Loss = 0.1631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:45:47,054 - INFO - Epoch 19 Batch 100: Train Loss = 0.1395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 100: Train Loss = 0.1395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:46:03,173 - INFO - Epoch 19 Batch 120: Train Loss = 0.1626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Batch 120: Train Loss = 0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:46:14,247 - INFO - ------------ Save best model - AUROC: 0.8759 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss = 0.1937 Valid loss = 0.1657 roc = 0.8759\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9584194421768188\n",
      "precision class 1 = 0.8086419701576233\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.8758566219807735\n",
      "AUC of PRC = 0.5856353503756544\n",
      "min(+P, Se) = 0.5513698630136986\n",
      "f1_score = 0.5770924855514871\n",
      "------------ Save best model - AUROC: 0.8759 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:46:15,099 - INFO - Epoch 20 Batch 0: Train Loss = 0.2415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 0: Train Loss = 0.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:46:30,422 - INFO - Epoch 20 Batch 20: Train Loss = 0.2310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 20: Train Loss = 0.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:46:45,256 - INFO - Epoch 20 Batch 40: Train Loss = 0.2254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 40: Train Loss = 0.2254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:47:00,078 - INFO - Epoch 20 Batch 60: Train Loss = 0.2241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 60: Train Loss = 0.2241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:47:14,856 - INFO - Epoch 20 Batch 80: Train Loss = 0.1757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 80: Train Loss = 0.1757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:47:29,794 - INFO - Epoch 20 Batch 100: Train Loss = 0.1292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 100: Train Loss = 0.1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:47:45,100 - INFO - Epoch 20 Batch 120: Train Loss = 0.1796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 120: Train Loss = 0.1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:47:55,260 - INFO - ------------ Save best model - AUROC: 0.8783 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss = 0.1933 Valid loss = 0.1659 roc = 0.8783\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9589253664016724\n",
      "precision class 1 = 0.8159509301185608\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8782727352598787\n",
      "AUC of PRC = 0.5882185901067118\n",
      "min(+P, Se) = 0.5494880546075085\n",
      "f1_score = 0.5846153797514266\n",
      "------------ Save best model - AUROC: 0.8783 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:47:56,029 - INFO - Epoch 21 Batch 0: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 0: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:48:10,907 - INFO - Epoch 21 Batch 20: Train Loss = 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 20: Train Loss = 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:48:25,611 - INFO - Epoch 21 Batch 40: Train Loss = 0.2253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 40: Train Loss = 0.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:48:40,102 - INFO - Epoch 21 Batch 60: Train Loss = 0.2162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 60: Train Loss = 0.2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:48:54,795 - INFO - Epoch 21 Batch 80: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 80: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:49:09,923 - INFO - Epoch 21 Batch 100: Train Loss = 0.1251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 100: Train Loss = 0.1251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:49:24,328 - INFO - Epoch 21 Batch 120: Train Loss = 0.1760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 120: Train Loss = 0.1760\n",
      "Epoch 21: Loss = 0.1935 Valid loss = 0.1652 roc = 0.8774\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9589040875434875\n",
      "precision class 1 = 0.8060606122016907\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8773666927802142\n",
      "AUC of PRC = 0.5869829895399503\n",
      "min(+P, Se) = 0.5547945205479452\n",
      "f1_score = 0.5820568870465316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:49:35,149 - INFO - Epoch 22 Batch 0: Train Loss = 0.2199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 0: Train Loss = 0.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:49:50,746 - INFO - Epoch 22 Batch 20: Train Loss = 0.2208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 20: Train Loss = 0.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:50:05,331 - INFO - Epoch 22 Batch 40: Train Loss = 0.2034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 40: Train Loss = 0.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:50:20,723 - INFO - Epoch 22 Batch 60: Train Loss = 0.2287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 60: Train Loss = 0.2287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:50:35,326 - INFO - Epoch 22 Batch 80: Train Loss = 0.1558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 80: Train Loss = 0.1558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:50:53,042 - INFO - Epoch 22 Batch 100: Train Loss = 0.1245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 100: Train Loss = 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:51:07,917 - INFO - Epoch 22 Batch 120: Train Loss = 0.1575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 120: Train Loss = 0.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:51:18,665 - INFO - ------------ Save best model - AUROC: 0.8795 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Loss = 0.1940 Valid loss = 0.1635 roc = 0.8795\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9589147567749023\n",
      "precision class 1 = 0.8109756112098694\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8794670639830726\n",
      "AUC of PRC = 0.5991532012780374\n",
      "min(+P, Se) = 0.5616438356164384\n",
      "f1_score = 0.5833333263436843\n",
      "------------ Save best model - AUROC: 0.8795 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:51:19,358 - INFO - Epoch 23 Batch 0: Train Loss = 0.2401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 0: Train Loss = 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:51:35,520 - INFO - Epoch 23 Batch 20: Train Loss = 0.2449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 20: Train Loss = 0.2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:51:49,971 - INFO - Epoch 23 Batch 40: Train Loss = 0.2236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 40: Train Loss = 0.2236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:52:04,735 - INFO - Epoch 23 Batch 60: Train Loss = 0.2216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 60: Train Loss = 0.2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:52:20,500 - INFO - Epoch 23 Batch 80: Train Loss = 0.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 80: Train Loss = 0.1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:52:35,710 - INFO - Epoch 23 Batch 100: Train Loss = 0.1269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 100: Train Loss = 0.1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:52:49,716 - INFO - Epoch 23 Batch 120: Train Loss = 0.1648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Batch 120: Train Loss = 0.1648\n",
      "Epoch 23: Loss = 0.1908 Valid loss = 0.1656 roc = 0.8755\n",
      "confusion matrix:\n",
      "[[3707   35]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9596168994903564\n",
      "precision class 1 = 0.7953216433525085\n",
      "recall class 0 = 0.9906467199325562\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8755207456272012\n",
      "AUC of PRC = 0.5857333486148018\n",
      "min(+P, Se) = 0.5371621621621622\n",
      "f1_score = 0.5874730406365205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:53:00,484 - INFO - Epoch 24 Batch 0: Train Loss = 0.2085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 0: Train Loss = 0.2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:53:14,965 - INFO - Epoch 24 Batch 20: Train Loss = 0.2278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 20: Train Loss = 0.2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:53:29,251 - INFO - Epoch 24 Batch 40: Train Loss = 0.2183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 40: Train Loss = 0.2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:53:43,826 - INFO - Epoch 24 Batch 60: Train Loss = 0.2152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 60: Train Loss = 0.2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:53:59,125 - INFO - Epoch 24 Batch 80: Train Loss = 0.1706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 80: Train Loss = 0.1706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:54:14,385 - INFO - Epoch 24 Batch 100: Train Loss = 0.1313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 100: Train Loss = 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:54:29,289 - INFO - Epoch 24 Batch 120: Train Loss = 0.1501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Batch 120: Train Loss = 0.1501\n",
      "Epoch 24: Loss = 0.1969 Valid loss = 0.1639 roc = 0.8792\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9589040875434875\n",
      "precision class 1 = 0.8060606122016907\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8791659650176082\n",
      "AUC of PRC = 0.5951051847588817\n",
      "min(+P, Se) = 0.5547945205479452\n",
      "f1_score = 0.5820568870465316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:54:39,891 - INFO - Epoch 25 Batch 0: Train Loss = 0.2185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 0: Train Loss = 0.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:54:54,570 - INFO - Epoch 25 Batch 20: Train Loss = 0.2290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 20: Train Loss = 0.2290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:55:08,999 - INFO - Epoch 25 Batch 40: Train Loss = 0.2125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 40: Train Loss = 0.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:55:23,869 - INFO - Epoch 25 Batch 60: Train Loss = 0.2087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 60: Train Loss = 0.2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:55:38,750 - INFO - Epoch 25 Batch 80: Train Loss = 0.1570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 80: Train Loss = 0.1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:55:54,011 - INFO - Epoch 25 Batch 100: Train Loss = 0.1383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 100: Train Loss = 0.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:56:09,589 - INFO - Epoch 25 Batch 120: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Batch 120: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:56:20,587 - INFO - ------------ Save best model - AUROC: 0.8811 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Loss = 0.1914 Valid loss = 0.1631 roc = 0.8811\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9589253664016724\n",
      "precision class 1 = 0.8159509301185608\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8810805517524142\n",
      "AUC of PRC = 0.6010711286583451\n",
      "min(+P, Se) = 0.571917808219178\n",
      "f1_score = 0.5846153797514266\n",
      "------------ Save best model - AUROC: 0.8811 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:56:21,348 - INFO - Epoch 26 Batch 0: Train Loss = 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 0: Train Loss = 0.2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:56:36,924 - INFO - Epoch 26 Batch 20: Train Loss = 0.2520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 20: Train Loss = 0.2520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:56:53,619 - INFO - Epoch 26 Batch 40: Train Loss = 0.2259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 40: Train Loss = 0.2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:57:07,244 - INFO - Epoch 26 Batch 60: Train Loss = 0.2259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 60: Train Loss = 0.2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:57:21,741 - INFO - Epoch 26 Batch 80: Train Loss = 0.1664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 80: Train Loss = 0.1664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:57:38,855 - INFO - Epoch 26 Batch 100: Train Loss = 0.1305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 100: Train Loss = 0.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:57:53,196 - INFO - Epoch 26 Batch 120: Train Loss = 0.1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Batch 120: Train Loss = 0.1704\n",
      "Epoch 26: Loss = 0.1917 Valid loss = 0.1652 roc = 0.8780\n",
      "confusion matrix:\n",
      "[[3709   33]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9591414332389832\n",
      "precision class 1 = 0.802395224571228\n",
      "recall class 0 = 0.9911811947822571\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8779666027250829\n",
      "AUC of PRC = 0.587180960593008\n",
      "min(+P, Se) = 0.5376712328767124\n",
      "f1_score = 0.5838779920938263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:58:04,027 - INFO - Epoch 27 Batch 0: Train Loss = 0.2190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 0: Train Loss = 0.2190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:58:18,071 - INFO - Epoch 27 Batch 20: Train Loss = 0.2393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 20: Train Loss = 0.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:58:31,893 - INFO - Epoch 27 Batch 40: Train Loss = 0.2417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 40: Train Loss = 0.2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:58:46,369 - INFO - Epoch 27 Batch 60: Train Loss = 0.2397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 60: Train Loss = 0.2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:59:00,351 - INFO - Epoch 27 Batch 80: Train Loss = 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 80: Train Loss = 0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:59:15,295 - INFO - Epoch 27 Batch 100: Train Loss = 0.1293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 100: Train Loss = 0.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:59:30,111 - INFO - Epoch 27 Batch 120: Train Loss = 0.1744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 120: Train Loss = 0.1744\n",
      "Epoch 27: Loss = 0.1954 Valid loss = 0.1645 roc = 0.8791\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9591520428657532\n",
      "precision class 1 = 0.8072289228439331\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8791247812685327\n",
      "AUC of PRC = 0.5941955147745559\n",
      "min(+P, Se) = 0.5426621160409556\n",
      "f1_score = 0.5851528328472227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 14:59:40,686 - INFO - Epoch 28 Batch 0: Train Loss = 0.2133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 0: Train Loss = 0.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 14:59:54,896 - INFO - Epoch 28 Batch 20: Train Loss = 0.2494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 20: Train Loss = 0.2494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:00:09,584 - INFO - Epoch 28 Batch 40: Train Loss = 0.2318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 40: Train Loss = 0.2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:00:23,839 - INFO - Epoch 28 Batch 60: Train Loss = 0.2428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 60: Train Loss = 0.2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:00:38,409 - INFO - Epoch 28 Batch 80: Train Loss = 0.1733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 80: Train Loss = 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:00:53,034 - INFO - Epoch 28 Batch 100: Train Loss = 0.1153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 100: Train Loss = 0.1153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:01:08,086 - INFO - Epoch 28 Batch 120: Train Loss = 0.1491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Batch 120: Train Loss = 0.1491\n",
      "Epoch 28: Loss = 0.1951 Valid loss = 0.1632 roc = 0.8807\n",
      "confusion matrix:\n",
      "[[3708   34]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9591308832168579\n",
      "precision class 1 = 0.7976190447807312\n",
      "recall class 0 = 0.9909139275550842\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.880676035817049\n",
      "AUC of PRC = 0.5973886475961339\n",
      "min(+P, Se) = 0.5445205479452054\n",
      "f1_score = 0.5826087149645298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:01:19,468 - INFO - Epoch 29 Batch 0: Train Loss = 0.2187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 0: Train Loss = 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:01:35,665 - INFO - Epoch 29 Batch 20: Train Loss = 0.2452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 20: Train Loss = 0.2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:01:50,670 - INFO - Epoch 29 Batch 40: Train Loss = 0.2111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 40: Train Loss = 0.2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:02:04,697 - INFO - Epoch 29 Batch 60: Train Loss = 0.1922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 60: Train Loss = 0.1922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:02:19,774 - INFO - Epoch 29 Batch 80: Train Loss = 0.1606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 80: Train Loss = 0.1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:02:34,308 - INFO - Epoch 29 Batch 100: Train Loss = 0.1341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 100: Train Loss = 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:02:48,548 - INFO - Epoch 29 Batch 120: Train Loss = 0.1468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Batch 120: Train Loss = 0.1468\n",
      "Epoch 29: Loss = 0.1938 Valid loss = 0.1635 roc = 0.8810\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9591520428657532\n",
      "precision class 1 = 0.8072289228439331\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8810201489204367\n",
      "AUC of PRC = 0.5959864251397771\n",
      "min(+P, Se) = 0.5420875420875421\n",
      "f1_score = 0.5851528328472227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:02:58,939 - INFO - Epoch 30 Batch 0: Train Loss = 0.2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 0: Train Loss = 0.2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:03:13,702 - INFO - Epoch 30 Batch 20: Train Loss = 0.2524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 20: Train Loss = 0.2524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:03:28,293 - INFO - Epoch 30 Batch 40: Train Loss = 0.2097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 40: Train Loss = 0.2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:03:42,138 - INFO - Epoch 30 Batch 60: Train Loss = 0.2170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 60: Train Loss = 0.2170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:03:56,890 - INFO - Epoch 30 Batch 80: Train Loss = 0.1650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 80: Train Loss = 0.1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:04:11,457 - INFO - Epoch 30 Batch 100: Train Loss = 0.1348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 100: Train Loss = 0.1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:04:25,736 - INFO - Epoch 30 Batch 120: Train Loss = 0.1753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Batch 120: Train Loss = 0.1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:04:35,604 - INFO - ------------ Save best model - AUROC: 0.8859 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss = 0.1925 Valid loss = 0.1617 roc = 0.8859\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9591520428657532\n",
      "precision class 1 = 0.8072289228439331\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8858825768946356\n",
      "AUC of PRC = 0.6090904941265177\n",
      "min(+P, Se) = 0.5699658703071673\n",
      "f1_score = 0.5851528328472227\n",
      "------------ Save best model - AUROC: 0.8859 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:04:36,197 - INFO - Epoch 31 Batch 0: Train Loss = 0.2105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 0: Train Loss = 0.2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:04:51,193 - INFO - Epoch 31 Batch 20: Train Loss = 0.2387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 20: Train Loss = 0.2387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:05:05,832 - INFO - Epoch 31 Batch 40: Train Loss = 0.2172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 40: Train Loss = 0.2172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:05:19,670 - INFO - Epoch 31 Batch 60: Train Loss = 0.2388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 60: Train Loss = 0.2388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:05:34,043 - INFO - Epoch 31 Batch 80: Train Loss = 0.1647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 80: Train Loss = 0.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:05:48,319 - INFO - Epoch 31 Batch 100: Train Loss = 0.1437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 100: Train Loss = 0.1437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:06:02,095 - INFO - Epoch 31 Batch 120: Train Loss = 0.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Batch 120: Train Loss = 0.1504\n",
      "Epoch 31: Loss = 0.1892 Valid loss = 0.1624 roc = 0.8842\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9591625928878784\n",
      "precision class 1 = 0.8121212124824524\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8841867216271425\n",
      "AUC of PRC = 0.6032282996070719\n",
      "min(+P, Se) = 0.5544217687074829\n",
      "f1_score = 0.5864332805719331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:06:12,966 - INFO - Epoch 32 Batch 0: Train Loss = 0.2087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 0: Train Loss = 0.2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:06:28,860 - INFO - Epoch 32 Batch 20: Train Loss = 0.2157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 20: Train Loss = 0.2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:06:43,975 - INFO - Epoch 32 Batch 40: Train Loss = 0.2147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 40: Train Loss = 0.2147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:06:59,668 - INFO - Epoch 32 Batch 60: Train Loss = 0.2353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 60: Train Loss = 0.2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:07:15,270 - INFO - Epoch 32 Batch 80: Train Loss = 0.1773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 80: Train Loss = 0.1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:07:30,001 - INFO - Epoch 32 Batch 100: Train Loss = 0.1394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 100: Train Loss = 0.1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:07:45,210 - INFO - Epoch 32 Batch 120: Train Loss = 0.1622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 120: Train Loss = 0.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:07:55,673 - INFO - ------------ Save best model - AUROC: 0.8862 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Loss = 0.1929 Valid loss = 0.1614 roc = 0.8862\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9589253664016724\n",
      "precision class 1 = 0.8159509301185608\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8861530168468991\n",
      "AUC of PRC = 0.6082075202180158\n",
      "min(+P, Se) = 0.5582191780821918\n",
      "f1_score = 0.5846153797514266\n",
      "------------ Save best model - AUROC: 0.8862 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:07:56,278 - INFO - Epoch 33 Batch 0: Train Loss = 0.2238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 0: Train Loss = 0.2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:08:10,910 - INFO - Epoch 33 Batch 20: Train Loss = 0.2605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 20: Train Loss = 0.2605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:08:25,062 - INFO - Epoch 33 Batch 40: Train Loss = 0.2058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 40: Train Loss = 0.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:08:39,179 - INFO - Epoch 33 Batch 60: Train Loss = 0.2139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 60: Train Loss = 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:08:53,935 - INFO - Epoch 33 Batch 80: Train Loss = 0.1686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 80: Train Loss = 0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:09:08,476 - INFO - Epoch 33 Batch 100: Train Loss = 0.1349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 100: Train Loss = 0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:09:22,665 - INFO - Epoch 33 Batch 120: Train Loss = 0.1483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 120: Train Loss = 0.1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:09:32,976 - INFO - ------------ Save best model - AUROC: 0.8875 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Loss = 0.1904 Valid loss = 0.1619 roc = 0.8875\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 164  128]]\n",
      "accuracy = 0.9516608715057373\n",
      "precision class 0 = 0.95767742395401\n",
      "precision class 1 = 0.805031418800354\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4383561611175537\n",
      "AUC of ROC = 0.8875143685524554\n",
      "AUC of PRC = 0.6069087949369927\n",
      "min(+P, Se) = 0.5631399317406144\n",
      "f1_score = 0.567627484822777\n",
      "------------ Save best model - AUROC: 0.8875 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:09:33,550 - INFO - Epoch 34 Batch 0: Train Loss = 0.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 0: Train Loss = 0.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:09:48,217 - INFO - Epoch 34 Batch 20: Train Loss = 0.2327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 20: Train Loss = 0.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:10:02,411 - INFO - Epoch 34 Batch 40: Train Loss = 0.2228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 40: Train Loss = 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:10:17,075 - INFO - Epoch 34 Batch 60: Train Loss = 0.2360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 60: Train Loss = 0.2360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:10:31,849 - INFO - Epoch 34 Batch 80: Train Loss = 0.1593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 80: Train Loss = 0.1593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:10:46,904 - INFO - Epoch 34 Batch 100: Train Loss = 0.1346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 100: Train Loss = 0.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:11:01,881 - INFO - Epoch 34 Batch 120: Train Loss = 0.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Batch 120: Train Loss = 0.1569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:11:12,123 - INFO - ------------ Save best model - AUROC: 0.8882 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Loss = 0.1914 Valid loss = 0.1618 roc = 0.8882\n",
      "confusion matrix:\n",
      "[[3709   33]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9591414332389832\n",
      "precision class 1 = 0.802395224571228\n",
      "recall class 0 = 0.9911811947822571\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.888217237870013\n",
      "AUC of PRC = 0.6090132884051402\n",
      "min(+P, Se) = 0.5547945205479452\n",
      "f1_score = 0.5838779920938263\n",
      "------------ Save best model - AUROC: 0.8882 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:11:12,956 - INFO - Epoch 35 Batch 0: Train Loss = 0.2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 0: Train Loss = 0.2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:11:28,941 - INFO - Epoch 35 Batch 20: Train Loss = 0.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 20: Train Loss = 0.2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:11:43,776 - INFO - Epoch 35 Batch 40: Train Loss = 0.2162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 40: Train Loss = 0.2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:12:00,084 - INFO - Epoch 35 Batch 60: Train Loss = 0.2039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 60: Train Loss = 0.2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:12:16,586 - INFO - Epoch 35 Batch 80: Train Loss = 0.1586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 80: Train Loss = 0.1586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:12:30,977 - INFO - Epoch 35 Batch 100: Train Loss = 0.1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 100: Train Loss = 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:12:45,482 - INFO - Epoch 35 Batch 120: Train Loss = 0.1527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Batch 120: Train Loss = 0.1527\n",
      "Epoch 35: Loss = 0.1900 Valid loss = 0.1613 roc = 0.8854\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9589040875434875\n",
      "precision class 1 = 0.8060606122016907\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8854304708492272\n",
      "AUC of PRC = 0.6090123979373434\n",
      "min(+P, Se) = 0.547945205479452\n",
      "f1_score = 0.5820568870465316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:12:55,919 - INFO - Epoch 36 Batch 0: Train Loss = 0.2416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 0: Train Loss = 0.2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:13:10,897 - INFO - Epoch 36 Batch 20: Train Loss = 0.2325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 20: Train Loss = 0.2325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:13:24,657 - INFO - Epoch 36 Batch 40: Train Loss = 0.2403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 40: Train Loss = 0.2403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:13:38,750 - INFO - Epoch 36 Batch 60: Train Loss = 0.2137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 60: Train Loss = 0.2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:13:54,306 - INFO - Epoch 36 Batch 80: Train Loss = 0.1687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 80: Train Loss = 0.1687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:14:09,685 - INFO - Epoch 36 Batch 100: Train Loss = 0.1154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 100: Train Loss = 0.1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:14:24,755 - INFO - Epoch 36 Batch 120: Train Loss = 0.1580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Batch 120: Train Loss = 0.1580\n",
      "Epoch 36: Loss = 0.1888 Valid loss = 0.1600 roc = 0.8851\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9591625928878784\n",
      "precision class 1 = 0.8121212124824524\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8850561563298508\n",
      "AUC of PRC = 0.6154799258251817\n",
      "min(+P, Se) = 0.5684931506849316\n",
      "f1_score = 0.5864332805719331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:14:35,900 - INFO - Epoch 37 Batch 0: Train Loss = 0.2093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 0: Train Loss = 0.2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:14:50,358 - INFO - Epoch 37 Batch 20: Train Loss = 0.2387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 20: Train Loss = 0.2387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:15:05,889 - INFO - Epoch 37 Batch 40: Train Loss = 0.2060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 40: Train Loss = 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:15:24,126 - INFO - Epoch 37 Batch 60: Train Loss = 0.2313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 60: Train Loss = 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:15:40,205 - INFO - Epoch 37 Batch 80: Train Loss = 0.1535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 80: Train Loss = 0.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:15:55,059 - INFO - Epoch 37 Batch 100: Train Loss = 0.1106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 100: Train Loss = 0.1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:16:10,460 - INFO - Epoch 37 Batch 120: Train Loss = 0.1477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Batch 120: Train Loss = 0.1477\n",
      "Epoch 37: Loss = 0.1908 Valid loss = 0.1611 roc = 0.8824\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9586563110351562\n",
      "precision class 1 = 0.8048780560493469\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.8824222267778566\n",
      "AUC of PRC = 0.6073144628692023\n",
      "min(+P, Se) = 0.5547945205479452\n",
      "f1_score = 0.5789473736495302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:16:21,566 - INFO - Epoch 38 Batch 0: Train Loss = 0.2203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 0: Train Loss = 0.2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:16:37,854 - INFO - Epoch 38 Batch 20: Train Loss = 0.2341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 20: Train Loss = 0.2341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:16:52,724 - INFO - Epoch 38 Batch 40: Train Loss = 0.2406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 40: Train Loss = 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:17:08,186 - INFO - Epoch 38 Batch 60: Train Loss = 0.1871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 60: Train Loss = 0.1871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:17:22,455 - INFO - Epoch 38 Batch 80: Train Loss = 0.1464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 80: Train Loss = 0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:17:37,078 - INFO - Epoch 38 Batch 100: Train Loss = 0.1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 100: Train Loss = 0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:17:52,163 - INFO - Epoch 38 Batch 120: Train Loss = 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Batch 120: Train Loss = 0.1587\n",
      "Epoch 38: Loss = 0.1914 Valid loss = 0.1607 roc = 0.8845\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9591520428657532\n",
      "precision class 1 = 0.8072289228439331\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8844951421479978\n",
      "AUC of PRC = 0.6130483501801058\n",
      "min(+P, Se) = 0.5616438356164384\n",
      "f1_score = 0.5851528328472227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:18:03,678 - INFO - Epoch 39 Batch 0: Train Loss = 0.2251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 0: Train Loss = 0.2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:18:18,769 - INFO - Epoch 39 Batch 20: Train Loss = 0.2297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 20: Train Loss = 0.2297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:18:33,113 - INFO - Epoch 39 Batch 40: Train Loss = 0.2232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 40: Train Loss = 0.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:18:46,951 - INFO - Epoch 39 Batch 60: Train Loss = 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 60: Train Loss = 0.2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:19:04,150 - INFO - Epoch 39 Batch 80: Train Loss = 0.1384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 80: Train Loss = 0.1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:19:22,121 - INFO - Epoch 39 Batch 100: Train Loss = 0.1239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 100: Train Loss = 0.1239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:19:36,884 - INFO - Epoch 39 Batch 120: Train Loss = 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Batch 120: Train Loss = 0.1636\n",
      "Epoch 39: Loss = 0.1916 Valid loss = 0.1627 roc = 0.8866\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9589147567749023\n",
      "precision class 1 = 0.8109756112098694\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8866348667110842\n",
      "AUC of PRC = 0.6056427814541934\n",
      "min(+P, Se) = 0.547945205479452\n",
      "f1_score = 0.5833333263436843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:19:47,752 - INFO - Epoch 40 Batch 0: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 0: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:20:02,363 - INFO - Epoch 40 Batch 20: Train Loss = 0.2446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 20: Train Loss = 0.2446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:20:16,584 - INFO - Epoch 40 Batch 40: Train Loss = 0.2228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 40: Train Loss = 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:20:31,018 - INFO - Epoch 40 Batch 60: Train Loss = 0.2033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 60: Train Loss = 0.2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:20:45,812 - INFO - Epoch 40 Batch 80: Train Loss = 0.1590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 80: Train Loss = 0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:20:59,952 - INFO - Epoch 40 Batch 100: Train Loss = 0.1209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 100: Train Loss = 0.1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:21:14,688 - INFO - Epoch 40 Batch 120: Train Loss = 0.1519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 120: Train Loss = 0.1519\n",
      "Epoch 40: Loss = 0.1932 Valid loss = 0.1620 roc = 0.8834\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9584301710128784\n",
      "precision class 1 = 0.8136646151542664\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.8834353470051179\n",
      "AUC of PRC = 0.6089427960848239\n",
      "min(+P, Se) = 0.5547945205479452\n",
      "f1_score = 0.5783664265140855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:21:25,517 - INFO - Epoch 41 Batch 0: Train Loss = 0.2195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 0: Train Loss = 0.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:21:41,521 - INFO - Epoch 41 Batch 20: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 20: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:21:57,275 - INFO - Epoch 41 Batch 40: Train Loss = 0.2074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 40: Train Loss = 0.2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:22:13,967 - INFO - Epoch 41 Batch 60: Train Loss = 0.2227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 60: Train Loss = 0.2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:22:28,285 - INFO - Epoch 41 Batch 80: Train Loss = 0.1668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 80: Train Loss = 0.1668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:22:42,596 - INFO - Epoch 41 Batch 100: Train Loss = 0.1349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 100: Train Loss = 0.1349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:22:56,314 - INFO - Epoch 41 Batch 120: Train Loss = 0.1725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Batch 120: Train Loss = 0.1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:23:05,924 - INFO - ------------ Save best model - AUROC: 0.8916 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Loss = 0.1910 Valid loss = 0.1584 roc = 0.8916\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9589253664016724\n",
      "precision class 1 = 0.8159509301185608\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8916034572384558\n",
      "AUC of PRC = 0.619108980311576\n",
      "min(+P, Se) = 0.5733788395904437\n",
      "f1_score = 0.5846153797514266\n",
      "------------ Save best model - AUROC: 0.8916 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:23:06,526 - INFO - Epoch 42 Batch 0: Train Loss = 0.2173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 0: Train Loss = 0.2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:23:20,709 - INFO - Epoch 42 Batch 20: Train Loss = 0.2389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 20: Train Loss = 0.2389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:23:34,685 - INFO - Epoch 42 Batch 40: Train Loss = 0.2503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 40: Train Loss = 0.2503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:23:48,659 - INFO - Epoch 42 Batch 60: Train Loss = 0.2186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 60: Train Loss = 0.2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:24:03,449 - INFO - Epoch 42 Batch 80: Train Loss = 0.1760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 80: Train Loss = 0.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:24:17,346 - INFO - Epoch 42 Batch 100: Train Loss = 0.1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 100: Train Loss = 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:24:31,105 - INFO - Epoch 42 Batch 120: Train Loss = 0.1579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 120: Train Loss = 0.1579\n",
      "Epoch 42: Loss = 0.1856 Valid loss = 0.1613 roc = 0.8851\n",
      "confusion matrix:\n",
      "[[3708   34]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9591308832168579\n",
      "precision class 1 = 0.7976190447807312\n",
      "recall class 0 = 0.9909139275550842\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8851449301889693\n",
      "AUC of PRC = 0.6060770904603267\n",
      "min(+P, Se) = 0.5445205479452054\n",
      "f1_score = 0.5826087149645298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:24:41,340 - INFO - Epoch 43 Batch 0: Train Loss = 0.2307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 0: Train Loss = 0.2307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:24:55,422 - INFO - Epoch 43 Batch 20: Train Loss = 0.2334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 20: Train Loss = 0.2334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:25:09,121 - INFO - Epoch 43 Batch 40: Train Loss = 0.2203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 40: Train Loss = 0.2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:25:22,764 - INFO - Epoch 43 Batch 60: Train Loss = 0.2337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 60: Train Loss = 0.2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:25:36,856 - INFO - Epoch 43 Batch 80: Train Loss = 0.1643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 80: Train Loss = 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:25:51,451 - INFO - Epoch 43 Batch 100: Train Loss = 0.1281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 100: Train Loss = 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:26:06,458 - INFO - Epoch 43 Batch 120: Train Loss = 0.1521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 120: Train Loss = 0.1521\n",
      "Epoch 43: Loss = 0.1933 Valid loss = 0.1608 roc = 0.8893\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9589253664016724\n",
      "precision class 1 = 0.8159509301185608\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8892619323048988\n",
      "AUC of PRC = 0.6216221933967528\n",
      "min(+P, Se) = 0.5666666666666667\n",
      "f1_score = 0.5846153797514266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:26:18,318 - INFO - Epoch 44 Batch 0: Train Loss = 0.2129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 0: Train Loss = 0.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:26:34,521 - INFO - Epoch 44 Batch 20: Train Loss = 0.2074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 20: Train Loss = 0.2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:26:48,938 - INFO - Epoch 44 Batch 40: Train Loss = 0.2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 40: Train Loss = 0.2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:27:04,035 - INFO - Epoch 44 Batch 60: Train Loss = 0.2134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 60: Train Loss = 0.2134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:27:19,288 - INFO - Epoch 44 Batch 80: Train Loss = 0.1457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 80: Train Loss = 0.1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:27:34,325 - INFO - Epoch 44 Batch 100: Train Loss = 0.1289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 100: Train Loss = 0.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:27:47,908 - INFO - Epoch 44 Batch 120: Train Loss = 0.1668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Batch 120: Train Loss = 0.1668\n",
      "Epoch 44: Loss = 0.1899 Valid loss = 0.1585 roc = 0.8893\n",
      "confusion matrix:\n",
      "[[3709   33]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9596377611160278\n",
      "precision class 1 = 0.8047337532043457\n",
      "recall class 0 = 0.9911811947822571\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8893246231229361\n",
      "AUC of PRC = 0.6228527303903266\n",
      "min(+P, Se) = 0.5733788395904437\n",
      "f1_score = 0.5900217079716777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:27:58,188 - INFO - Epoch 45 Batch 0: Train Loss = 0.2132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 0: Train Loss = 0.2132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:28:11,940 - INFO - Epoch 45 Batch 20: Train Loss = 0.2389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 20: Train Loss = 0.2389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:28:26,206 - INFO - Epoch 45 Batch 40: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 40: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:28:40,529 - INFO - Epoch 45 Batch 60: Train Loss = 0.2397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 60: Train Loss = 0.2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:28:55,535 - INFO - Epoch 45 Batch 80: Train Loss = 0.1503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 80: Train Loss = 0.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:29:09,563 - INFO - Epoch 45 Batch 100: Train Loss = 0.1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 100: Train Loss = 0.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:29:23,133 - INFO - Epoch 45 Batch 120: Train Loss = 0.1438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Batch 120: Train Loss = 0.1438\n",
      "Epoch 45: Loss = 0.1885 Valid loss = 0.1584 roc = 0.8890\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9591520428657532\n",
      "precision class 1 = 0.8072289228439331\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8889869163805159\n",
      "AUC of PRC = 0.6244005356529377\n",
      "min(+P, Se) = 0.5787671232876712\n",
      "f1_score = 0.5851528328472227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:29:33,237 - INFO - Epoch 46 Batch 0: Train Loss = 0.2212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 0: Train Loss = 0.2212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:29:47,014 - INFO - Epoch 46 Batch 20: Train Loss = 0.2309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 20: Train Loss = 0.2309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:30:00,794 - INFO - Epoch 46 Batch 40: Train Loss = 0.2107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 40: Train Loss = 0.2107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:30:14,310 - INFO - Epoch 46 Batch 60: Train Loss = 0.2220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 60: Train Loss = 0.2220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:30:28,859 - INFO - Epoch 46 Batch 80: Train Loss = 0.1630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 80: Train Loss = 0.1630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:30:43,798 - INFO - Epoch 46 Batch 100: Train Loss = 0.1277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 100: Train Loss = 0.1277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:30:58,432 - INFO - Epoch 46 Batch 120: Train Loss = 0.1533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 120: Train Loss = 0.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:31:08,815 - INFO - ------------ Save best model - AUROC: 0.8917 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Loss = 0.1897 Valid loss = 0.1580 roc = 0.8917\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9589147567749023\n",
      "precision class 1 = 0.8109756112098694\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8917196869302916\n",
      "AUC of PRC = 0.6301701813264245\n",
      "min(+P, Se) = 0.57\n",
      "f1_score = 0.5833333263436843\n",
      "------------ Save best model - AUROC: 0.8917 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:31:09,516 - INFO - Epoch 47 Batch 0: Train Loss = 0.2005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 0: Train Loss = 0.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:31:25,126 - INFO - Epoch 47 Batch 20: Train Loss = 0.2431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 20: Train Loss = 0.2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:31:39,709 - INFO - Epoch 47 Batch 40: Train Loss = 0.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 40: Train Loss = 0.2284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:31:54,107 - INFO - Epoch 47 Batch 60: Train Loss = 0.2110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 60: Train Loss = 0.2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:32:07,899 - INFO - Epoch 47 Batch 80: Train Loss = 0.1619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 80: Train Loss = 0.1619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:32:21,629 - INFO - Epoch 47 Batch 100: Train Loss = 0.1403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 100: Train Loss = 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:32:35,068 - INFO - Epoch 47 Batch 120: Train Loss = 0.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Batch 120: Train Loss = 0.1504\n",
      "Epoch 47: Loss = 0.1846 Valid loss = 0.1574 roc = 0.8904\n",
      "confusion matrix:\n",
      "[[3708   34]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9596273303031921\n",
      "precision class 1 = 0.800000011920929\n",
      "recall class 0 = 0.9909139275550842\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8903542168498276\n",
      "AUC of PRC = 0.6240179782426895\n",
      "min(+P, Se) = 0.5787671232876712\n",
      "f1_score = 0.5887445733812668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:32:45,436 - INFO - Epoch 48 Batch 0: Train Loss = 0.2180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 0: Train Loss = 0.2180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:32:59,930 - INFO - Epoch 48 Batch 20: Train Loss = 0.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 20: Train Loss = 0.2158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:33:13,646 - INFO - Epoch 48 Batch 40: Train Loss = 0.2261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 40: Train Loss = 0.2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:33:27,590 - INFO - Epoch 48 Batch 60: Train Loss = 0.2316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 60: Train Loss = 0.2316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:33:41,459 - INFO - Epoch 48 Batch 80: Train Loss = 0.1634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 80: Train Loss = 0.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:33:55,468 - INFO - Epoch 48 Batch 100: Train Loss = 0.1322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 100: Train Loss = 0.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:34:09,814 - INFO - Epoch 48 Batch 120: Train Loss = 0.1526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 120: Train Loss = 0.1526\n",
      "Epoch 48: Loss = 0.1849 Valid loss = 0.1605 roc = 0.8884\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9589147567749023\n",
      "precision class 1 = 0.8109756112098694\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.888418580643272\n",
      "AUC of PRC = 0.6165217739085573\n",
      "min(+P, Se) = 0.5618729096989966\n",
      "f1_score = 0.5833333263436843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:34:20,077 - INFO - Epoch 49 Batch 0: Train Loss = 0.2401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 0: Train Loss = 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:34:34,469 - INFO - Epoch 49 Batch 20: Train Loss = 0.2418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 20: Train Loss = 0.2418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:34:47,544 - INFO - Epoch 49 Batch 40: Train Loss = 0.2292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 40: Train Loss = 0.2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:35:01,712 - INFO - Epoch 49 Batch 60: Train Loss = 0.2312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 60: Train Loss = 0.2312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:35:16,650 - INFO - Epoch 49 Batch 80: Train Loss = 0.1576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 80: Train Loss = 0.1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:35:32,280 - INFO - Epoch 49 Batch 100: Train Loss = 0.1259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 100: Train Loss = 0.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:35:47,752 - INFO - Epoch 49 Batch 120: Train Loss = 0.1477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Batch 120: Train Loss = 0.1477\n",
      "Epoch 49: Loss = 0.1920 Valid loss = 0.1591 roc = 0.8854\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.959410548210144\n",
      "precision class 1 = 0.8132529854774475\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8853636616562821\n",
      "AUC of PRC = 0.6224124525049638\n",
      "min(+P, Se) = 0.5787671232876712\n",
      "f1_score = 0.5895196531328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:35:59,046 - INFO - Epoch 50 Batch 0: Train Loss = 0.1929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 0: Train Loss = 0.1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:36:13,936 - INFO - Epoch 50 Batch 20: Train Loss = 0.2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 20: Train Loss = 0.2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:36:28,890 - INFO - Epoch 50 Batch 40: Train Loss = 0.2295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 40: Train Loss = 0.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:36:43,256 - INFO - Epoch 50 Batch 60: Train Loss = 0.2161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 60: Train Loss = 0.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:36:57,725 - INFO - Epoch 50 Batch 80: Train Loss = 0.1567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 80: Train Loss = 0.1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:37:12,098 - INFO - Epoch 50 Batch 100: Train Loss = 0.1298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 100: Train Loss = 0.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:37:25,769 - INFO - Epoch 50 Batch 120: Train Loss = 0.1678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Batch 120: Train Loss = 0.1678\n",
      "Epoch 50: Loss = 0.1888 Valid loss = 0.1602 roc = 0.8882\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9589040875434875\n",
      "precision class 1 = 0.8060606122016907\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8881632413990028\n",
      "AUC of PRC = 0.618076498501841\n",
      "min(+P, Se) = 0.5753424657534246\n",
      "f1_score = 0.5820568870465316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:37:36,185 - INFO - Epoch 51 Batch 0: Train Loss = 0.2446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 0: Train Loss = 0.2446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:37:51,436 - INFO - Epoch 51 Batch 20: Train Loss = 0.2437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 20: Train Loss = 0.2437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:38:04,695 - INFO - Epoch 51 Batch 40: Train Loss = 0.2347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 40: Train Loss = 0.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:38:19,110 - INFO - Epoch 51 Batch 60: Train Loss = 0.2310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 60: Train Loss = 0.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:38:33,261 - INFO - Epoch 51 Batch 80: Train Loss = 0.1526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 80: Train Loss = 0.1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:38:47,495 - INFO - Epoch 51 Batch 100: Train Loss = 0.1344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 100: Train Loss = 0.1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:39:01,048 - INFO - Epoch 51 Batch 120: Train Loss = 0.1701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Batch 120: Train Loss = 0.1701\n",
      "Epoch 51: Loss = 0.1912 Valid loss = 0.1583 roc = 0.8868\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9596481919288635\n",
      "precision class 1 = 0.8095238208770752\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8868316335122232\n",
      "AUC of PRC = 0.6206920681466124\n",
      "min(+P, Se) = 0.5864406779661017\n",
      "f1_score = 0.5913043600670106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:39:11,484 - INFO - Epoch 52 Batch 0: Train Loss = 0.2366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 0: Train Loss = 0.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:39:26,050 - INFO - Epoch 52 Batch 20: Train Loss = 0.2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 20: Train Loss = 0.2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:39:40,343 - INFO - Epoch 52 Batch 40: Train Loss = 0.2056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 40: Train Loss = 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:39:55,263 - INFO - Epoch 52 Batch 60: Train Loss = 0.2389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 60: Train Loss = 0.2389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:40:09,950 - INFO - Epoch 52 Batch 80: Train Loss = 0.1682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 80: Train Loss = 0.1682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:40:25,037 - INFO - Epoch 52 Batch 100: Train Loss = 0.1325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 100: Train Loss = 0.1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:40:39,504 - INFO - Epoch 52 Batch 120: Train Loss = 0.1615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 120: Train Loss = 0.1615\n",
      "Epoch 52: Loss = 0.1908 Valid loss = 0.1620 roc = 0.8838\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.959410548210144\n",
      "precision class 1 = 0.8132529854774475\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8838453541070265\n",
      "AUC of PRC = 0.6088232526911942\n",
      "min(+P, Se) = 0.5460750853242321\n",
      "f1_score = 0.5895196531328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:40:50,091 - INFO - Epoch 53 Batch 0: Train Loss = 0.2335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 0: Train Loss = 0.2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:41:05,192 - INFO - Epoch 53 Batch 20: Train Loss = 0.2390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 20: Train Loss = 0.2390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:41:19,206 - INFO - Epoch 53 Batch 40: Train Loss = 0.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 40: Train Loss = 0.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:41:34,641 - INFO - Epoch 53 Batch 60: Train Loss = 0.2493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 60: Train Loss = 0.2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:41:49,272 - INFO - Epoch 53 Batch 80: Train Loss = 0.1609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 80: Train Loss = 0.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:42:03,056 - INFO - Epoch 53 Batch 100: Train Loss = 0.1068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 100: Train Loss = 0.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:42:16,705 - INFO - Epoch 53 Batch 120: Train Loss = 0.1575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Batch 120: Train Loss = 0.1575\n",
      "Epoch 53: Loss = 0.1948 Valid loss = 0.1577 roc = 0.8916\n",
      "confusion matrix:\n",
      "[[3713   29]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.958440899848938\n",
      "precision class 1 = 0.8187500238418579\n",
      "recall class 0 = 0.9922501444816589\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.8915531215451411\n",
      "AUC of PRC = 0.6315669199165821\n",
      "min(+P, Se) = 0.5924657534246576\n",
      "f1_score = 0.5796460267408718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:42:27,431 - INFO - Epoch 54 Batch 0: Train Loss = 0.2335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 0: Train Loss = 0.2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:42:41,294 - INFO - Epoch 54 Batch 20: Train Loss = 0.2409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 20: Train Loss = 0.2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:42:54,520 - INFO - Epoch 54 Batch 40: Train Loss = 0.2112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 40: Train Loss = 0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:43:07,895 - INFO - Epoch 54 Batch 60: Train Loss = 0.2360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 60: Train Loss = 0.2360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:43:22,137 - INFO - Epoch 54 Batch 80: Train Loss = 0.1403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 80: Train Loss = 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:43:36,409 - INFO - Epoch 54 Batch 100: Train Loss = 0.1321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 100: Train Loss = 0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:43:49,801 - INFO - Epoch 54 Batch 120: Train Loss = 0.1648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Batch 120: Train Loss = 0.1648\n",
      "Epoch 54: Loss = 0.1865 Valid loss = 0.1565 roc = 0.8917\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9596481919288635\n",
      "precision class 1 = 0.8095238208770752\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8917123653749003\n",
      "AUC of PRC = 0.6342866397661917\n",
      "min(+P, Se) = 0.5993150684931506\n",
      "f1_score = 0.5913043600670106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:43:59,931 - INFO - Epoch 55 Batch 0: Train Loss = 0.2227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 0: Train Loss = 0.2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:44:14,403 - INFO - Epoch 55 Batch 20: Train Loss = 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 20: Train Loss = 0.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:44:28,095 - INFO - Epoch 55 Batch 40: Train Loss = 0.2324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 40: Train Loss = 0.2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:44:43,137 - INFO - Epoch 55 Batch 60: Train Loss = 0.2305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 60: Train Loss = 0.2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:44:57,919 - INFO - Epoch 55 Batch 80: Train Loss = 0.1524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 80: Train Loss = 0.1524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:45:12,387 - INFO - Epoch 55 Batch 100: Train Loss = 0.1301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 100: Train Loss = 0.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:45:25,681 - INFO - Epoch 55 Batch 120: Train Loss = 0.1650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 120: Train Loss = 0.1650\n",
      "Epoch 55: Loss = 0.1868 Valid loss = 0.1584 roc = 0.8870\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9594210386276245\n",
      "precision class 1 = 0.8181818127632141\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.887024739535667\n",
      "AUC of PRC = 0.6234464235671521\n",
      "min(+P, Se) = 0.5802047781569966\n",
      "f1_score = 0.590809636012966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:45:35,912 - INFO - Epoch 56 Batch 0: Train Loss = 0.2223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 0: Train Loss = 0.2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:45:51,372 - INFO - Epoch 56 Batch 20: Train Loss = 0.2253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 20: Train Loss = 0.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:46:06,499 - INFO - Epoch 56 Batch 40: Train Loss = 0.2102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 40: Train Loss = 0.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:46:20,480 - INFO - Epoch 56 Batch 60: Train Loss = 0.2095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 60: Train Loss = 0.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:46:35,313 - INFO - Epoch 56 Batch 80: Train Loss = 0.1650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 80: Train Loss = 0.1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:46:48,931 - INFO - Epoch 56 Batch 100: Train Loss = 0.1320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 100: Train Loss = 0.1320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:47:02,830 - INFO - Epoch 56 Batch 120: Train Loss = 0.1654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Batch 120: Train Loss = 0.1654\n",
      "Epoch 56: Loss = 0.1886 Valid loss = 0.1567 roc = 0.8895\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9591731429100037\n",
      "precision class 1 = 0.8170731663703918\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8895277962850427\n",
      "AUC of PRC = 0.6307095947348257\n",
      "min(+P, Se) = 0.5870307167235495\n",
      "f1_score = 0.5877193172057253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:47:13,543 - INFO - Epoch 57 Batch 0: Train Loss = 0.2556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 0: Train Loss = 0.2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:47:27,060 - INFO - Epoch 57 Batch 20: Train Loss = 0.2249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 20: Train Loss = 0.2249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:47:40,719 - INFO - Epoch 57 Batch 40: Train Loss = 0.2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 40: Train Loss = 0.2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:47:54,555 - INFO - Epoch 57 Batch 60: Train Loss = 0.2189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 60: Train Loss = 0.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:48:08,531 - INFO - Epoch 57 Batch 80: Train Loss = 0.1723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 80: Train Loss = 0.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:48:22,693 - INFO - Epoch 57 Batch 100: Train Loss = 0.1336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 100: Train Loss = 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:48:36,246 - INFO - Epoch 57 Batch 120: Train Loss = 0.1885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Batch 120: Train Loss = 0.1885\n",
      "Epoch 57: Loss = 0.1875 Valid loss = 0.1576 roc = 0.8883\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.959410548210144\n",
      "precision class 1 = 0.8132529854774475\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8883270612008816\n",
      "AUC of PRC = 0.6309233994525562\n",
      "min(+P, Se) = 0.5993150684931506\n",
      "f1_score = 0.5895196531328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:48:46,525 - INFO - Epoch 58 Batch 0: Train Loss = 0.2093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 0: Train Loss = 0.2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:49:01,611 - INFO - Epoch 58 Batch 20: Train Loss = 0.2345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 20: Train Loss = 0.2345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:49:16,139 - INFO - Epoch 58 Batch 40: Train Loss = 0.2443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 40: Train Loss = 0.2443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:49:31,046 - INFO - Epoch 58 Batch 60: Train Loss = 0.2171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 60: Train Loss = 0.2171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:49:45,581 - INFO - Epoch 58 Batch 80: Train Loss = 0.1628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 80: Train Loss = 0.1628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:49:59,515 - INFO - Epoch 58 Batch 100: Train Loss = 0.1385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 100: Train Loss = 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:50:13,448 - INFO - Epoch 58 Batch 120: Train Loss = 0.1545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Batch 120: Train Loss = 0.1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:50:23,571 - INFO - ------------ Save best model - AUROC: 0.8922 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Loss = 0.1877 Valid loss = 0.1586 roc = 0.8922\n",
      "confusion matrix:\n",
      "[[3713   29]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9586883783340454\n",
      "precision class 1 = 0.8198757767677307\n",
      "recall class 0 = 0.9922501444816589\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.8922468389184597\n",
      "AUC of PRC = 0.6316130453266409\n",
      "min(+P, Se) = 0.5892255892255892\n",
      "f1_score = 0.5827814604397221\n",
      "------------ Save best model - AUROC: 0.8922 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:50:24,216 - INFO - Epoch 59 Batch 0: Train Loss = 0.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 0: Train Loss = 0.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:50:39,281 - INFO - Epoch 59 Batch 20: Train Loss = 0.2204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 20: Train Loss = 0.2204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:50:53,477 - INFO - Epoch 59 Batch 40: Train Loss = 0.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 40: Train Loss = 0.2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:51:09,057 - INFO - Epoch 59 Batch 60: Train Loss = 0.2234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 60: Train Loss = 0.2234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:51:24,484 - INFO - Epoch 59 Batch 80: Train Loss = 0.1653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 80: Train Loss = 0.1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:51:38,999 - INFO - Epoch 59 Batch 100: Train Loss = 0.1379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 100: Train Loss = 0.1379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:51:52,674 - INFO - Epoch 59 Batch 120: Train Loss = 0.1770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Batch 120: Train Loss = 0.1770\n",
      "Epoch 59: Loss = 0.1894 Valid loss = 0.1580 roc = 0.8868\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9586777091026306\n",
      "precision class 1 = 0.8148148059844971\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.8868270575401037\n",
      "AUC of PRC = 0.6220744531256692\n",
      "min(+P, Se) = 0.5821917808219178\n",
      "f1_score = 0.5814978258445392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:52:03,583 - INFO - Epoch 60 Batch 0: Train Loss = 0.2078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 0: Train Loss = 0.2078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:52:17,984 - INFO - Epoch 60 Batch 20: Train Loss = 0.2230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 20: Train Loss = 0.2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:52:31,761 - INFO - Epoch 60 Batch 40: Train Loss = 0.2189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 40: Train Loss = 0.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:52:45,649 - INFO - Epoch 60 Batch 60: Train Loss = 0.2730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 60: Train Loss = 0.2730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:52:59,158 - INFO - Epoch 60 Batch 80: Train Loss = 0.1581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 80: Train Loss = 0.1581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:53:13,379 - INFO - Epoch 60 Batch 100: Train Loss = 0.1574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 100: Train Loss = 0.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:53:27,205 - INFO - Epoch 60 Batch 120: Train Loss = 0.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 120: Train Loss = 0.1518\n",
      "Epoch 60: Loss = 0.1893 Valid loss = 0.1580 roc = 0.8862\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9591731429100037\n",
      "precision class 1 = 0.8170731663703918\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8862230292203276\n",
      "AUC of PRC = 0.6268818347489743\n",
      "min(+P, Se) = 0.5787671232876712\n",
      "f1_score = 0.5877193172057253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:53:38,321 - INFO - Epoch 61 Batch 0: Train Loss = 0.2210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 0: Train Loss = 0.2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:53:54,236 - INFO - Epoch 61 Batch 20: Train Loss = 0.2319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 20: Train Loss = 0.2319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:54:09,249 - INFO - Epoch 61 Batch 40: Train Loss = 0.2345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 40: Train Loss = 0.2345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:54:23,661 - INFO - Epoch 61 Batch 60: Train Loss = 0.2456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 60: Train Loss = 0.2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:54:38,220 - INFO - Epoch 61 Batch 80: Train Loss = 0.1643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 80: Train Loss = 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:54:52,426 - INFO - Epoch 61 Batch 100: Train Loss = 0.1223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 100: Train Loss = 0.1223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:55:06,056 - INFO - Epoch 61 Batch 120: Train Loss = 0.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Batch 120: Train Loss = 0.1683\n",
      "Epoch 61: Loss = 0.1874 Valid loss = 0.1589 roc = 0.8858\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9594210386276245\n",
      "precision class 1 = 0.8181818127632141\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.885822174062658\n",
      "AUC of PRC = 0.6182980682228011\n",
      "min(+P, Se) = 0.5680272108843537\n",
      "f1_score = 0.590809636012966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:55:16,277 - INFO - Epoch 62 Batch 0: Train Loss = 0.2002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 0: Train Loss = 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:55:30,951 - INFO - Epoch 62 Batch 20: Train Loss = 0.2196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 20: Train Loss = 0.2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:55:45,898 - INFO - Epoch 62 Batch 40: Train Loss = 0.2228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 40: Train Loss = 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:56:00,937 - INFO - Epoch 62 Batch 60: Train Loss = 0.2429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 60: Train Loss = 0.2429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:56:15,452 - INFO - Epoch 62 Batch 80: Train Loss = 0.1538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 80: Train Loss = 0.1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:56:29,783 - INFO - Epoch 62 Batch 100: Train Loss = 0.1242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 100: Train Loss = 0.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:56:43,829 - INFO - Epoch 62 Batch 120: Train Loss = 0.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Batch 120: Train Loss = 0.1591\n",
      "Epoch 62: Loss = 0.1906 Valid loss = 0.1587 roc = 0.8894\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9591625928878784\n",
      "precision class 1 = 0.8121212124824524\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8894362768426525\n",
      "AUC of PRC = 0.6276933227947374\n",
      "min(+P, Se) = 0.5821917808219178\n",
      "f1_score = 0.5864332805719331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:56:53,846 - INFO - Epoch 63 Batch 0: Train Loss = 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 0: Train Loss = 0.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:57:09,517 - INFO - Epoch 63 Batch 20: Train Loss = 0.2513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 20: Train Loss = 0.2513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:57:23,175 - INFO - Epoch 63 Batch 40: Train Loss = 0.2372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 40: Train Loss = 0.2372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:57:37,266 - INFO - Epoch 63 Batch 60: Train Loss = 0.2443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 60: Train Loss = 0.2443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:57:50,368 - INFO - Epoch 63 Batch 80: Train Loss = 0.1490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 80: Train Loss = 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:58:04,757 - INFO - Epoch 63 Batch 100: Train Loss = 0.1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 100: Train Loss = 0.1445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:58:18,689 - INFO - Epoch 63 Batch 120: Train Loss = 0.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 120: Train Loss = 0.1728\n",
      "Epoch 63: Loss = 0.1875 Valid loss = 0.1576 roc = 0.8879\n",
      "confusion matrix:\n",
      "[[3713   29]\n",
      " [ 157  135]]\n",
      "accuracy = 0.953891932964325\n",
      "precision class 0 = 0.959431529045105\n",
      "precision class 1 = 0.8231707215309143\n",
      "recall class 0 = 0.9922501444816589\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8879225452655163\n",
      "AUC of PRC = 0.6293237973271997\n",
      "min(+P, Se) = 0.5856164383561644\n",
      "f1_score = 0.5921052698998793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 15:58:29,158 - INFO - Epoch 64 Batch 0: Train Loss = 0.2164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 0: Train Loss = 0.2164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:58:44,091 - INFO - Epoch 64 Batch 20: Train Loss = 0.2305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 20: Train Loss = 0.2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:58:58,749 - INFO - Epoch 64 Batch 40: Train Loss = 0.2332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 40: Train Loss = 0.2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:59:13,630 - INFO - Epoch 64 Batch 60: Train Loss = 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 60: Train Loss = 0.2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:59:27,687 - INFO - Epoch 64 Batch 80: Train Loss = 0.1609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 80: Train Loss = 0.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:59:41,652 - INFO - Epoch 64 Batch 100: Train Loss = 0.1190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 100: Train Loss = 0.1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 15:59:55,901 - INFO - Epoch 64 Batch 120: Train Loss = 0.1870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 120: Train Loss = 0.1870\n",
      "Epoch 64: Loss = 0.1867 Valid loss = 0.1561 roc = 0.8893\n",
      "confusion matrix:\n",
      "[[3713   29]\n",
      " [ 162  130]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9581935405731201\n",
      "precision class 1 = 0.8176100850105286\n",
      "recall class 0 = 0.9922501444816589\n",
      "recall class 1 = 0.4452054798603058\n",
      "AUC of ROC = 0.8893154711786972\n",
      "AUC of PRC = 0.6378528036576434\n",
      "min(+P, Se) = 0.6061643835616438\n",
      "f1_score = 0.576496666292674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:00:06,508 - INFO - Epoch 65 Batch 0: Train Loss = 0.2182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 0: Train Loss = 0.2182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:00:21,137 - INFO - Epoch 65 Batch 20: Train Loss = 0.2409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 20: Train Loss = 0.2409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:00:35,235 - INFO - Epoch 65 Batch 40: Train Loss = 0.2157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 40: Train Loss = 0.2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:00:49,605 - INFO - Epoch 65 Batch 60: Train Loss = 0.2238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 60: Train Loss = 0.2238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:01:04,741 - INFO - Epoch 65 Batch 80: Train Loss = 0.1533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 80: Train Loss = 0.1533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:01:19,230 - INFO - Epoch 65 Batch 100: Train Loss = 0.1323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 100: Train Loss = 0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:01:32,452 - INFO - Epoch 65 Batch 120: Train Loss = 0.1694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Batch 120: Train Loss = 0.1694\n",
      "Epoch 65: Loss = 0.1832 Valid loss = 0.1590 roc = 0.8856\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9591625928878784\n",
      "precision class 1 = 0.8121212124824524\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8855549372908781\n",
      "AUC of PRC = 0.621537849765735\n",
      "min(+P, Se) = 0.5684931506849316\n",
      "f1_score = 0.5864332805719331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:01:43,448 - INFO - Epoch 66 Batch 0: Train Loss = 0.2221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 0: Train Loss = 0.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:01:57,585 - INFO - Epoch 66 Batch 20: Train Loss = 0.2282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 20: Train Loss = 0.2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:02:11,354 - INFO - Epoch 66 Batch 40: Train Loss = 0.2471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 40: Train Loss = 0.2471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:02:25,608 - INFO - Epoch 66 Batch 60: Train Loss = 0.2183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 60: Train Loss = 0.2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:02:39,537 - INFO - Epoch 66 Batch 80: Train Loss = 0.1547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 80: Train Loss = 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:02:52,521 - INFO - Epoch 66 Batch 100: Train Loss = 0.1352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 100: Train Loss = 0.1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:03:06,554 - INFO - Epoch 66 Batch 120: Train Loss = 0.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Batch 120: Train Loss = 0.1646\n",
      "Epoch 66: Loss = 0.1885 Valid loss = 0.1569 roc = 0.8913\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9591731429100037\n",
      "precision class 1 = 0.8170731663703918\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8913407964387955\n",
      "AUC of PRC = 0.6325054136911957\n",
      "min(+P, Se) = 0.590443686006826\n",
      "f1_score = 0.5877193172057253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:03:17,599 - INFO - Epoch 67 Batch 0: Train Loss = 0.2248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 0: Train Loss = 0.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:03:32,341 - INFO - Epoch 67 Batch 20: Train Loss = 0.2244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 20: Train Loss = 0.2244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:03:46,405 - INFO - Epoch 67 Batch 40: Train Loss = 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 40: Train Loss = 0.2346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:04:00,526 - INFO - Epoch 67 Batch 60: Train Loss = 0.2255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 60: Train Loss = 0.2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:04:14,224 - INFO - Epoch 67 Batch 80: Train Loss = 0.1463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 80: Train Loss = 0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:04:27,786 - INFO - Epoch 67 Batch 100: Train Loss = 0.1282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 100: Train Loss = 0.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:04:40,929 - INFO - Epoch 67 Batch 120: Train Loss = 0.1648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Batch 120: Train Loss = 0.1648\n",
      "Epoch 67: Loss = 0.1854 Valid loss = 0.1591 roc = 0.8852\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9596481919288635\n",
      "precision class 1 = 0.8095238208770752\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8851540821332085\n",
      "AUC of PRC = 0.6156970632305308\n",
      "min(+P, Se) = 0.565068493150685\n",
      "f1_score = 0.5913043600670106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:04:52,043 - INFO - Epoch 68 Batch 0: Train Loss = 0.2174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 0: Train Loss = 0.2174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:05:06,504 - INFO - Epoch 68 Batch 20: Train Loss = 0.2399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 20: Train Loss = 0.2399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:05:20,608 - INFO - Epoch 68 Batch 40: Train Loss = 0.2071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 40: Train Loss = 0.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:05:34,949 - INFO - Epoch 68 Batch 60: Train Loss = 0.2281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 60: Train Loss = 0.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:05:49,999 - INFO - Epoch 68 Batch 80: Train Loss = 0.1671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 80: Train Loss = 0.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:06:04,281 - INFO - Epoch 68 Batch 100: Train Loss = 0.1195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 100: Train Loss = 0.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:06:18,590 - INFO - Epoch 68 Batch 120: Train Loss = 0.1775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Batch 120: Train Loss = 0.1775\n",
      "Epoch 68: Loss = 0.1917 Valid loss = 0.1582 roc = 0.8864\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.959410548210144\n",
      "precision class 1 = 0.8132529854774475\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.886369460328152\n",
      "AUC of PRC = 0.6252421183955744\n",
      "min(+P, Se) = 0.5684931506849316\n",
      "f1_score = 0.5895196531328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:06:29,447 - INFO - Epoch 69 Batch 0: Train Loss = 0.2061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 0: Train Loss = 0.2061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:06:43,888 - INFO - Epoch 69 Batch 20: Train Loss = 0.2145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 20: Train Loss = 0.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:06:57,908 - INFO - Epoch 69 Batch 40: Train Loss = 0.2152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 40: Train Loss = 0.2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:07:12,072 - INFO - Epoch 69 Batch 60: Train Loss = 0.2523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 60: Train Loss = 0.2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:07:25,564 - INFO - Epoch 69 Batch 80: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 80: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:07:40,172 - INFO - Epoch 69 Batch 100: Train Loss = 0.1357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 100: Train Loss = 0.1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:07:54,401 - INFO - Epoch 69 Batch 120: Train Loss = 0.1806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Batch 120: Train Loss = 0.1806\n",
      "Epoch 69: Loss = 0.1877 Valid loss = 0.1577 roc = 0.8848\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.959410548210144\n",
      "precision class 1 = 0.8132529854774475\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.884815460196364\n",
      "AUC of PRC = 0.6272346047744617\n",
      "min(+P, Se) = 0.5787671232876712\n",
      "f1_score = 0.5895196531328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:08:05,399 - INFO - Epoch 70 Batch 0: Train Loss = 0.2054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 0: Train Loss = 0.2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:08:20,728 - INFO - Epoch 70 Batch 20: Train Loss = 0.2350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 20: Train Loss = 0.2350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:08:34,786 - INFO - Epoch 70 Batch 40: Train Loss = 0.2359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 40: Train Loss = 0.2359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:08:48,331 - INFO - Epoch 70 Batch 60: Train Loss = 0.2359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 60: Train Loss = 0.2359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:09:02,300 - INFO - Epoch 70 Batch 80: Train Loss = 0.1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 80: Train Loss = 0.1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:09:16,333 - INFO - Epoch 70 Batch 100: Train Loss = 0.1242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 100: Train Loss = 0.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:09:29,931 - INFO - Epoch 70 Batch 120: Train Loss = 0.1572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Batch 120: Train Loss = 0.1572\n",
      "Epoch 70: Loss = 0.1878 Valid loss = 0.1582 roc = 0.8864\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9594210386276245\n",
      "precision class 1 = 0.8181818127632141\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8864348967294612\n",
      "AUC of PRC = 0.6284148192410229\n",
      "min(+P, Se) = 0.5821917808219178\n",
      "f1_score = 0.590809636012966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:09:40,273 - INFO - Epoch 71 Batch 0: Train Loss = 0.2253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 0: Train Loss = 0.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:09:54,721 - INFO - Epoch 71 Batch 20: Train Loss = 0.2102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 20: Train Loss = 0.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:10:08,450 - INFO - Epoch 71 Batch 40: Train Loss = 0.1968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 40: Train Loss = 0.1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:10:22,565 - INFO - Epoch 71 Batch 60: Train Loss = 0.2165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 60: Train Loss = 0.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:10:36,842 - INFO - Epoch 71 Batch 80: Train Loss = 0.1812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 80: Train Loss = 0.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:10:51,244 - INFO - Epoch 71 Batch 100: Train Loss = 0.1144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 100: Train Loss = 0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:11:04,892 - INFO - Epoch 71 Batch 120: Train Loss = 0.1660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Batch 120: Train Loss = 0.1660\n",
      "Epoch 71: Loss = 0.1856 Valid loss = 0.1584 roc = 0.8858\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9594210386276245\n",
      "precision class 1 = 0.8181818127632141\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8858121069239948\n",
      "AUC of PRC = 0.6240877726696588\n",
      "min(+P, Se) = 0.571917808219178\n",
      "f1_score = 0.590809636012966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:11:15,942 - INFO - Epoch 72 Batch 0: Train Loss = 0.1974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 0: Train Loss = 0.1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:11:30,710 - INFO - Epoch 72 Batch 20: Train Loss = 0.2139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 20: Train Loss = 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:11:43,879 - INFO - Epoch 72 Batch 40: Train Loss = 0.2234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 40: Train Loss = 0.2234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:11:57,527 - INFO - Epoch 72 Batch 60: Train Loss = 0.2355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 60: Train Loss = 0.2355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:12:11,581 - INFO - Epoch 72 Batch 80: Train Loss = 0.1740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 80: Train Loss = 0.1740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:12:26,354 - INFO - Epoch 72 Batch 100: Train Loss = 0.1362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 100: Train Loss = 0.1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:12:41,083 - INFO - Epoch 72 Batch 120: Train Loss = 0.1825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Batch 120: Train Loss = 0.1825\n",
      "Epoch 72: Loss = 0.1875 Valid loss = 0.1583 roc = 0.8893\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9586670398712158\n",
      "precision class 1 = 0.8098159432411194\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.8892541531522957\n",
      "AUC of PRC = 0.63343595746978\n",
      "min(+P, Se) = 0.5856164383561644\n",
      "f1_score = 0.5802197816115389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:12:51,810 - INFO - Epoch 73 Batch 0: Train Loss = 0.2093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 0: Train Loss = 0.2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:13:06,812 - INFO - Epoch 73 Batch 20: Train Loss = 0.2190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 20: Train Loss = 0.2190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:13:21,029 - INFO - Epoch 73 Batch 40: Train Loss = 0.2370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 40: Train Loss = 0.2370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:13:34,516 - INFO - Epoch 73 Batch 60: Train Loss = 0.2401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 60: Train Loss = 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:13:48,875 - INFO - Epoch 73 Batch 80: Train Loss = 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 80: Train Loss = 0.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:14:02,877 - INFO - Epoch 73 Batch 100: Train Loss = 0.1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 100: Train Loss = 0.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:14:16,672 - INFO - Epoch 73 Batch 120: Train Loss = 0.1779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 120: Train Loss = 0.1779\n",
      "Epoch 73: Loss = 0.1845 Valid loss = 0.1573 roc = 0.8889\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9584301710128784\n",
      "precision class 1 = 0.8136646151542664\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.8889182767987232\n",
      "AUC of PRC = 0.6341019115227017\n",
      "min(+P, Se) = 0.5924657534246576\n",
      "f1_score = 0.5783664265140855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:14:26,761 - INFO - Epoch 74 Batch 0: Train Loss = 0.2046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 0: Train Loss = 0.2046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:14:41,014 - INFO - Epoch 74 Batch 20: Train Loss = 0.2245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 20: Train Loss = 0.2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:14:54,255 - INFO - Epoch 74 Batch 40: Train Loss = 0.2681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 40: Train Loss = 0.2681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:15:07,702 - INFO - Epoch 74 Batch 60: Train Loss = 0.2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 60: Train Loss = 0.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:15:22,128 - INFO - Epoch 74 Batch 80: Train Loss = 0.1905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 80: Train Loss = 0.1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:15:36,356 - INFO - Epoch 74 Batch 100: Train Loss = 0.1109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 100: Train Loss = 0.1109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:15:51,316 - INFO - Epoch 74 Batch 120: Train Loss = 0.1544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Batch 120: Train Loss = 0.1544\n",
      "Epoch 74: Loss = 0.1855 Valid loss = 0.1601 roc = 0.8885\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9584301710128784\n",
      "precision class 1 = 0.8136646151542664\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.8885073545023904\n",
      "AUC of PRC = 0.6226462217686354\n",
      "min(+P, Se) = 0.5684931506849316\n",
      "f1_score = 0.5783664265140855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:16:01,809 - INFO - Epoch 75 Batch 0: Train Loss = 0.2212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 0: Train Loss = 0.2212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:16:15,466 - INFO - Epoch 75 Batch 20: Train Loss = 0.2310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 20: Train Loss = 0.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:16:28,422 - INFO - Epoch 75 Batch 40: Train Loss = 0.2275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 40: Train Loss = 0.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:16:41,442 - INFO - Epoch 75 Batch 60: Train Loss = 0.1906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 60: Train Loss = 0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:16:54,985 - INFO - Epoch 75 Batch 80: Train Loss = 0.1794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 80: Train Loss = 0.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:17:09,837 - INFO - Epoch 75 Batch 100: Train Loss = 0.1347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 100: Train Loss = 0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:17:23,575 - INFO - Epoch 75 Batch 120: Train Loss = 0.1546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Batch 120: Train Loss = 0.1546\n",
      "Epoch 75: Loss = 0.1893 Valid loss = 0.1556 roc = 0.8900\n",
      "confusion matrix:\n",
      "[[3713   29]\n",
      " [ 157  135]]\n",
      "accuracy = 0.953891932964325\n",
      "precision class 0 = 0.959431529045105\n",
      "precision class 1 = 0.8231707215309143\n",
      "recall class 0 = 0.9922501444816589\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8900036973854724\n",
      "AUC of PRC = 0.6383744025133973\n",
      "min(+P, Se) = 0.5958904109589042\n",
      "f1_score = 0.5921052698998793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:17:33,729 - INFO - Epoch 76 Batch 0: Train Loss = 0.2153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 0: Train Loss = 0.2153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:17:47,683 - INFO - Epoch 76 Batch 20: Train Loss = 0.2344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 20: Train Loss = 0.2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:18:01,660 - INFO - Epoch 76 Batch 40: Train Loss = 0.2335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 40: Train Loss = 0.2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:18:15,353 - INFO - Epoch 76 Batch 60: Train Loss = 0.2789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 60: Train Loss = 0.2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:18:29,957 - INFO - Epoch 76 Batch 80: Train Loss = 0.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 80: Train Loss = 0.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:18:43,655 - INFO - Epoch 76 Batch 100: Train Loss = 0.1039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 100: Train Loss = 0.1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:18:56,434 - INFO - Epoch 76 Batch 120: Train Loss = 0.1846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Batch 120: Train Loss = 0.1846\n",
      "Epoch 76: Loss = 0.1854 Valid loss = 0.1566 roc = 0.8877\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.959410548210144\n",
      "precision class 1 = 0.8132529854774475\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.887658054077008\n",
      "AUC of PRC = 0.6328610572769094\n",
      "min(+P, Se) = 0.5864406779661017\n",
      "f1_score = 0.5895196531328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:19:06,473 - INFO - Epoch 77 Batch 0: Train Loss = 0.2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 0: Train Loss = 0.2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:19:19,892 - INFO - Epoch 77 Batch 20: Train Loss = 0.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 20: Train Loss = 0.2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:19:32,991 - INFO - Epoch 77 Batch 40: Train Loss = 0.2534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 40: Train Loss = 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:19:46,020 - INFO - Epoch 77 Batch 60: Train Loss = 0.2040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 60: Train Loss = 0.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:19:59,375 - INFO - Epoch 77 Batch 80: Train Loss = 0.1634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 80: Train Loss = 0.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:20:12,778 - INFO - Epoch 77 Batch 100: Train Loss = 0.1291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 100: Train Loss = 0.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:20:25,764 - INFO - Epoch 77 Batch 120: Train Loss = 0.1891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Batch 120: Train Loss = 0.1891\n",
      "Epoch 77: Loss = 0.1860 Valid loss = 0.1568 roc = 0.8850\n",
      "confusion matrix:\n",
      "[[3708   34]\n",
      " [ 155  137]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.959875762462616\n",
      "precision class 1 = 0.8011695742607117\n",
      "recall class 0 = 0.9909139275550842\n",
      "recall class 1 = 0.46917808055877686\n",
      "AUC of ROC = 0.8849948383034492\n",
      "AUC of PRC = 0.634780152672388\n",
      "min(+P, Se) = 0.5787671232876712\n",
      "f1_score = 0.5917926785859923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:20:36,086 - INFO - Epoch 78 Batch 0: Train Loss = 0.2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 0: Train Loss = 0.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:20:49,973 - INFO - Epoch 78 Batch 20: Train Loss = 0.2391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 20: Train Loss = 0.2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:21:03,131 - INFO - Epoch 78 Batch 40: Train Loss = 0.2441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 40: Train Loss = 0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:21:17,303 - INFO - Epoch 78 Batch 60: Train Loss = 0.2077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 60: Train Loss = 0.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:21:32,215 - INFO - Epoch 78 Batch 80: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 80: Train Loss = 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:21:46,630 - INFO - Epoch 78 Batch 100: Train Loss = 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 100: Train Loss = 0.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:22:00,440 - INFO - Epoch 78 Batch 120: Train Loss = 0.1736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Batch 120: Train Loss = 0.1736\n",
      "Epoch 78: Loss = 0.1867 Valid loss = 0.1573 roc = 0.8883\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9596586227416992\n",
      "precision class 1 = 0.8143712282180786\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8882648279800561\n",
      "AUC of PRC = 0.633332604670615\n",
      "min(+P, Se) = 0.5856164383561644\n",
      "f1_score = 0.592592594096564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:22:10,467 - INFO - Epoch 79 Batch 0: Train Loss = 0.2321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 0: Train Loss = 0.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:22:23,846 - INFO - Epoch 79 Batch 20: Train Loss = 0.2391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 20: Train Loss = 0.2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:22:36,726 - INFO - Epoch 79 Batch 40: Train Loss = 0.2205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 40: Train Loss = 0.2205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:22:49,953 - INFO - Epoch 79 Batch 60: Train Loss = 0.1999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 60: Train Loss = 0.1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:23:03,547 - INFO - Epoch 79 Batch 80: Train Loss = 0.1754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 80: Train Loss = 0.1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:23:16,752 - INFO - Epoch 79 Batch 100: Train Loss = 0.1322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 100: Train Loss = 0.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:23:30,032 - INFO - Epoch 79 Batch 120: Train Loss = 0.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 120: Train Loss = 0.1646\n",
      "Epoch 79: Loss = 0.1866 Valid loss = 0.1589 roc = 0.8897\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9591625928878784\n",
      "precision class 1 = 0.8121212124824524\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8897392061969646\n",
      "AUC of PRC = 0.6324343156227662\n",
      "min(+P, Se) = 0.5821917808219178\n",
      "f1_score = 0.5864332805719331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:23:39,906 - INFO - Epoch 80 Batch 0: Train Loss = 0.2096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 0: Train Loss = 0.2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:23:51,912 - INFO - Epoch 80 Batch 20: Train Loss = 0.2364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 20: Train Loss = 0.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:24:03,683 - INFO - Epoch 80 Batch 40: Train Loss = 0.2326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 40: Train Loss = 0.2326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:24:17,259 - INFO - Epoch 80 Batch 60: Train Loss = 0.2002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 60: Train Loss = 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:24:30,459 - INFO - Epoch 80 Batch 80: Train Loss = 0.1540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 80: Train Loss = 0.1540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:24:42,375 - INFO - Epoch 80 Batch 100: Train Loss = 0.1317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 100: Train Loss = 0.1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:24:55,974 - INFO - Epoch 80 Batch 120: Train Loss = 0.1627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Batch 120: Train Loss = 0.1627\n",
      "Epoch 80: Loss = 0.1873 Valid loss = 0.1565 roc = 0.8866\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9596481919288635\n",
      "precision class 1 = 0.8095238208770752\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8866412730720513\n",
      "AUC of PRC = 0.6335492128017639\n",
      "min(+P, Se) = 0.5821917808219178\n",
      "f1_score = 0.5913043600670106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:25:06,011 - INFO - Epoch 81 Batch 0: Train Loss = 0.2221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 0: Train Loss = 0.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:25:20,116 - INFO - Epoch 81 Batch 20: Train Loss = 0.2203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 20: Train Loss = 0.2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:25:33,201 - INFO - Epoch 81 Batch 40: Train Loss = 0.2340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 40: Train Loss = 0.2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:25:47,074 - INFO - Epoch 81 Batch 60: Train Loss = 0.2525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 60: Train Loss = 0.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:26:01,014 - INFO - Epoch 81 Batch 80: Train Loss = 0.1561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 80: Train Loss = 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:26:14,633 - INFO - Epoch 81 Batch 100: Train Loss = 0.1404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 100: Train Loss = 0.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:26:27,341 - INFO - Epoch 81 Batch 120: Train Loss = 0.1588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Batch 120: Train Loss = 0.1588\n",
      "Epoch 81: Loss = 0.1872 Valid loss = 0.1594 roc = 0.8868\n",
      "confusion matrix:\n",
      "[[3714   28]\n",
      " [ 162  130]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9582043290138245\n",
      "precision class 1 = 0.8227847814559937\n",
      "recall class 0 = 0.992517352104187\n",
      "recall class 1 = 0.4452054798603058\n",
      "AUC of ROC = 0.8868426158453102\n",
      "AUC of PRC = 0.6306731964026322\n",
      "min(+P, Se) = 0.5813953488372093\n",
      "f1_score = 0.5777777846324594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:26:37,386 - INFO - Epoch 82 Batch 0: Train Loss = 0.2296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 0: Train Loss = 0.2296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:26:49,892 - INFO - Epoch 82 Batch 20: Train Loss = 0.2537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 20: Train Loss = 0.2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:27:02,804 - INFO - Epoch 82 Batch 40: Train Loss = 0.2199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 40: Train Loss = 0.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:27:16,044 - INFO - Epoch 82 Batch 60: Train Loss = 0.2173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 60: Train Loss = 0.2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:27:29,412 - INFO - Epoch 82 Batch 80: Train Loss = 0.1949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 80: Train Loss = 0.1949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:27:42,434 - INFO - Epoch 82 Batch 100: Train Loss = 0.1281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 100: Train Loss = 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:27:54,780 - INFO - Epoch 82 Batch 120: Train Loss = 0.1725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Batch 120: Train Loss = 0.1725\n",
      "Epoch 82: Loss = 0.1917 Valid loss = 0.1566 roc = 0.8856\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9591625928878784\n",
      "precision class 1 = 0.8121212124824524\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8855778171514758\n",
      "AUC of PRC = 0.6307878405493136\n",
      "min(+P, Se) = 0.5787671232876712\n",
      "f1_score = 0.5864332805719331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:28:04,561 - INFO - Epoch 83 Batch 0: Train Loss = 0.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 0: Train Loss = 0.2289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:28:17,540 - INFO - Epoch 83 Batch 20: Train Loss = 0.2538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 20: Train Loss = 0.2538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:28:30,098 - INFO - Epoch 83 Batch 40: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 40: Train Loss = 0.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:28:43,228 - INFO - Epoch 83 Batch 60: Train Loss = 0.2281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 60: Train Loss = 0.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:28:56,557 - INFO - Epoch 83 Batch 80: Train Loss = 0.1708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 80: Train Loss = 0.1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:29:09,479 - INFO - Epoch 83 Batch 100: Train Loss = 0.1291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 100: Train Loss = 0.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:29:22,423 - INFO - Epoch 83 Batch 120: Train Loss = 0.1677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 120: Train Loss = 0.1677\n",
      "Epoch 83: Loss = 0.1844 Valid loss = 0.1590 roc = 0.8841\n",
      "confusion matrix:\n",
      "[[3708   34]\n",
      " [ 155  137]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.959875762462616\n",
      "precision class 1 = 0.8011695742607117\n",
      "recall class 0 = 0.9909139275550842\n",
      "recall class 1 = 0.46917808055877686\n",
      "AUC of ROC = 0.8841176244481378\n",
      "AUC of PRC = 0.6256251580508955\n",
      "min(+P, Se) = 0.565068493150685\n",
      "f1_score = 0.5917926785859923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:29:32,198 - INFO - Epoch 84 Batch 0: Train Loss = 0.2221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 0: Train Loss = 0.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:29:46,055 - INFO - Epoch 84 Batch 20: Train Loss = 0.2241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 20: Train Loss = 0.2241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:29:59,618 - INFO - Epoch 84 Batch 40: Train Loss = 0.2252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 40: Train Loss = 0.2252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:30:13,252 - INFO - Epoch 84 Batch 60: Train Loss = 0.2573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 60: Train Loss = 0.2573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:30:26,924 - INFO - Epoch 84 Batch 80: Train Loss = 0.1479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 80: Train Loss = 0.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:30:40,157 - INFO - Epoch 84 Batch 100: Train Loss = 0.1377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 100: Train Loss = 0.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:30:52,891 - INFO - Epoch 84 Batch 120: Train Loss = 0.1725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Batch 120: Train Loss = 0.1725\n",
      "Epoch 84: Loss = 0.1932 Valid loss = 0.1573 roc = 0.8865\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9594210386276245\n",
      "precision class 1 = 0.8181818127632141\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8865049091028899\n",
      "AUC of PRC = 0.6274455727634399\n",
      "min(+P, Se) = 0.571917808219178\n",
      "f1_score = 0.590809636012966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:31:02,751 - INFO - Epoch 85 Batch 0: Train Loss = 0.2297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 0: Train Loss = 0.2297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:31:16,912 - INFO - Epoch 85 Batch 20: Train Loss = 0.2526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 20: Train Loss = 0.2526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:31:30,408 - INFO - Epoch 85 Batch 40: Train Loss = 0.2329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 40: Train Loss = 0.2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:31:44,987 - INFO - Epoch 85 Batch 60: Train Loss = 0.2254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 60: Train Loss = 0.2254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:31:58,205 - INFO - Epoch 85 Batch 80: Train Loss = 0.1539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 80: Train Loss = 0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:32:11,253 - INFO - Epoch 85 Batch 100: Train Loss = 0.1404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 100: Train Loss = 0.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:32:23,818 - INFO - Epoch 85 Batch 120: Train Loss = 0.1829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Batch 120: Train Loss = 0.1829\n",
      "Epoch 85: Loss = 0.1877 Valid loss = 0.1587 roc = 0.8896\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9591520428657532\n",
      "precision class 1 = 0.8072289228439331\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8895534217289122\n",
      "AUC of PRC = 0.6330535313027049\n",
      "min(+P, Se) = 0.5856164383561644\n",
      "f1_score = 0.5851528328472227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:32:33,694 - INFO - Epoch 86 Batch 0: Train Loss = 0.1968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 0: Train Loss = 0.1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:32:47,250 - INFO - Epoch 86 Batch 20: Train Loss = 0.2535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 20: Train Loss = 0.2535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:33:00,302 - INFO - Epoch 86 Batch 40: Train Loss = 0.2276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 40: Train Loss = 0.2276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:33:13,705 - INFO - Epoch 86 Batch 60: Train Loss = 0.2498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 60: Train Loss = 0.2498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:33:26,994 - INFO - Epoch 86 Batch 80: Train Loss = 0.1625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 80: Train Loss = 0.1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:33:40,914 - INFO - Epoch 86 Batch 100: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 100: Train Loss = 0.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:33:54,576 - INFO - Epoch 86 Batch 120: Train Loss = 0.1661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 120: Train Loss = 0.1661\n",
      "Epoch 86: Loss = 0.1907 Valid loss = 0.1581 roc = 0.8830\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9584301710128784\n",
      "precision class 1 = 0.8136646151542664\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.8830317462641765\n",
      "AUC of PRC = 0.6261904581814078\n",
      "min(+P, Se) = 0.589041095890411\n",
      "f1_score = 0.5783664265140855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:34:04,883 - INFO - Epoch 87 Batch 0: Train Loss = 0.2136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 0: Train Loss = 0.2136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:34:19,348 - INFO - Epoch 87 Batch 20: Train Loss = 0.2389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 20: Train Loss = 0.2389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:34:32,684 - INFO - Epoch 87 Batch 40: Train Loss = 0.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 40: Train Loss = 0.2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:34:46,336 - INFO - Epoch 87 Batch 60: Train Loss = 0.2292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 60: Train Loss = 0.2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:35:00,132 - INFO - Epoch 87 Batch 80: Train Loss = 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 80: Train Loss = 0.1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:35:13,658 - INFO - Epoch 87 Batch 100: Train Loss = 0.1418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 100: Train Loss = 0.1418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:35:25,679 - INFO - Epoch 87 Batch 120: Train Loss = 0.1756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Batch 120: Train Loss = 0.1756\n",
      "Epoch 87: Loss = 0.1845 Valid loss = 0.1564 roc = 0.8830\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.9596481919288635\n",
      "precision class 1 = 0.8095238208770752\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.882988732126253\n",
      "AUC of PRC = 0.6360810759455529\n",
      "min(+P, Se) = 0.581081081081081\n",
      "f1_score = 0.5913043600670106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:35:35,639 - INFO - Epoch 88 Batch 0: Train Loss = 0.2047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 0: Train Loss = 0.2047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:35:49,588 - INFO - Epoch 88 Batch 20: Train Loss = 0.2765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 20: Train Loss = 0.2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:36:02,555 - INFO - Epoch 88 Batch 40: Train Loss = 0.2206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 40: Train Loss = 0.2206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:36:16,176 - INFO - Epoch 88 Batch 60: Train Loss = 0.2422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 60: Train Loss = 0.2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:36:30,079 - INFO - Epoch 88 Batch 80: Train Loss = 0.1674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 80: Train Loss = 0.1674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:36:43,912 - INFO - Epoch 88 Batch 100: Train Loss = 0.1412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 100: Train Loss = 0.1412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:36:57,874 - INFO - Epoch 88 Batch 120: Train Loss = 0.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Batch 120: Train Loss = 0.1655\n",
      "Epoch 88: Loss = 0.1842 Valid loss = 0.1572 roc = 0.8840\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 157  135]]\n",
      "accuracy = 0.9533961415290833\n",
      "precision class 0 = 0.959410548210144\n",
      "precision class 1 = 0.8132529854774475\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4623287618160248\n",
      "AUC of ROC = 0.8839844636594598\n",
      "AUC of PRC = 0.6265699903299342\n",
      "min(+P, Se) = 0.5753424657534246\n",
      "f1_score = 0.5895196531328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:37:07,980 - INFO - Epoch 89 Batch 0: Train Loss = 0.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 0: Train Loss = 0.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:37:21,172 - INFO - Epoch 89 Batch 20: Train Loss = 0.2379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 20: Train Loss = 0.2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:37:34,903 - INFO - Epoch 89 Batch 40: Train Loss = 0.2295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 40: Train Loss = 0.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:37:48,516 - INFO - Epoch 89 Batch 60: Train Loss = 0.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 60: Train Loss = 0.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:38:02,136 - INFO - Epoch 89 Batch 80: Train Loss = 0.1642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 80: Train Loss = 0.1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:38:16,286 - INFO - Epoch 89 Batch 100: Train Loss = 0.1380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 100: Train Loss = 0.1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:38:30,625 - INFO - Epoch 89 Batch 120: Train Loss = 0.1840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Batch 120: Train Loss = 0.1840\n",
      "Epoch 89: Loss = 0.1887 Valid loss = 0.1557 roc = 0.8896\n",
      "confusion matrix:\n",
      "[[3709   33]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9591414332389832\n",
      "precision class 1 = 0.802395224571228\n",
      "recall class 0 = 0.9911811947822571\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8896010118389551\n",
      "AUC of PRC = 0.6375273744131401\n",
      "min(+P, Se) = 0.5856164383561644\n",
      "f1_score = 0.5838779920938263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:38:41,026 - INFO - Epoch 90 Batch 0: Train Loss = 0.2033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 0: Train Loss = 0.2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:38:54,826 - INFO - Epoch 90 Batch 20: Train Loss = 0.2266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 20: Train Loss = 0.2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:39:08,114 - INFO - Epoch 90 Batch 40: Train Loss = 0.2173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 40: Train Loss = 0.2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:39:21,919 - INFO - Epoch 90 Batch 60: Train Loss = 0.2287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 60: Train Loss = 0.2287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:39:34,865 - INFO - Epoch 90 Batch 80: Train Loss = 0.1570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 80: Train Loss = 0.1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:39:48,741 - INFO - Epoch 90 Batch 100: Train Loss = 0.1326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 100: Train Loss = 0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:40:02,116 - INFO - Epoch 90 Batch 120: Train Loss = 0.1552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Batch 120: Train Loss = 0.1552\n",
      "Epoch 90: Loss = 0.1849 Valid loss = 0.1606 roc = 0.8841\n",
      "confusion matrix:\n",
      "[[3709   33]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9588934779167175\n",
      "precision class 1 = 0.8012048006057739\n",
      "recall class 0 = 0.9911811947822571\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8840613399910677\n",
      "AUC of PRC = 0.6146267815948728\n",
      "min(+P, Se) = 0.5563139931740614\n",
      "f1_score = 0.5807859864470168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:40:12,220 - INFO - Epoch 91 Batch 0: Train Loss = 0.2351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 0: Train Loss = 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:40:27,122 - INFO - Epoch 91 Batch 20: Train Loss = 0.2232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 20: Train Loss = 0.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:40:40,439 - INFO - Epoch 91 Batch 40: Train Loss = 0.2398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 40: Train Loss = 0.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:40:54,177 - INFO - Epoch 91 Batch 60: Train Loss = 0.2077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 60: Train Loss = 0.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:41:08,594 - INFO - Epoch 91 Batch 80: Train Loss = 0.1595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 80: Train Loss = 0.1595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:41:23,182 - INFO - Epoch 91 Batch 100: Train Loss = 0.1194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 100: Train Loss = 0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:41:36,339 - INFO - Epoch 91 Batch 120: Train Loss = 0.1678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Batch 120: Train Loss = 0.1678\n",
      "Epoch 91: Loss = 0.1939 Valid loss = 0.1575 roc = 0.8888\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9584194421768188\n",
      "precision class 1 = 0.8086419701576233\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.8888368244949958\n",
      "AUC of PRC = 0.6303305670747396\n",
      "min(+P, Se) = 0.5856164383561644\n",
      "f1_score = 0.5770924855514871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:41:46,387 - INFO - Epoch 92 Batch 0: Train Loss = 0.2140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 0: Train Loss = 0.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:42:00,365 - INFO - Epoch 92 Batch 20: Train Loss = 0.2081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 20: Train Loss = 0.2081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:42:13,693 - INFO - Epoch 92 Batch 40: Train Loss = 0.2174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 40: Train Loss = 0.2174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:42:27,163 - INFO - Epoch 92 Batch 60: Train Loss = 0.2070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 60: Train Loss = 0.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:42:41,169 - INFO - Epoch 92 Batch 80: Train Loss = 0.1696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 80: Train Loss = 0.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:42:56,459 - INFO - Epoch 92 Batch 100: Train Loss = 0.1252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 100: Train Loss = 0.1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:43:09,588 - INFO - Epoch 92 Batch 120: Train Loss = 0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Batch 120: Train Loss = 0.1542\n",
      "Epoch 92: Loss = 0.1864 Valid loss = 0.1609 roc = 0.8825\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 161  131]]\n",
      "accuracy = 0.9524045586585999\n",
      "precision class 0 = 0.9584194421768188\n",
      "precision class 1 = 0.8086419701576233\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.44863012433052063\n",
      "AUC of ROC = 0.882457004165965\n",
      "AUC of PRC = 0.6187786784118132\n",
      "min(+P, Se) = 0.565068493150685\n",
      "f1_score = 0.5770924855514871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:43:20,164 - INFO - Epoch 93 Batch 0: Train Loss = 0.2185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 0: Train Loss = 0.2185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:43:33,918 - INFO - Epoch 93 Batch 20: Train Loss = 0.2652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 20: Train Loss = 0.2652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:43:46,557 - INFO - Epoch 93 Batch 40: Train Loss = 0.2288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 40: Train Loss = 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:43:58,477 - INFO - Epoch 93 Batch 60: Train Loss = 0.2374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 60: Train Loss = 0.2374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:44:11,882 - INFO - Epoch 93 Batch 80: Train Loss = 0.1662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 80: Train Loss = 0.1662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:44:25,615 - INFO - Epoch 93 Batch 100: Train Loss = 0.1367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 100: Train Loss = 0.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:44:39,448 - INFO - Epoch 93 Batch 120: Train Loss = 0.1779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Batch 120: Train Loss = 0.1779\n",
      "Epoch 93: Loss = 0.1894 Valid loss = 0.1572 roc = 0.8902\n",
      "confusion matrix:\n",
      "[[3712   30]\n",
      " [ 160  132]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9586777091026306\n",
      "precision class 1 = 0.8148148059844971\n",
      "recall class 0 = 0.9919828772544861\n",
      "recall class 1 = 0.45205479860305786\n",
      "AUC of ROC = 0.8902032097698835\n",
      "AUC of PRC = 0.6370584474813489\n",
      "min(+P, Se) = 0.590443686006826\n",
      "f1_score = 0.5814978258445392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:44:49,482 - INFO - Epoch 94 Batch 0: Train Loss = 0.2129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 0: Train Loss = 0.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:45:02,373 - INFO - Epoch 94 Batch 20: Train Loss = 0.2658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 20: Train Loss = 0.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:45:15,796 - INFO - Epoch 94 Batch 40: Train Loss = 0.2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 40: Train Loss = 0.2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:45:28,761 - INFO - Epoch 94 Batch 60: Train Loss = 0.2056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 60: Train Loss = 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:45:42,972 - INFO - Epoch 94 Batch 80: Train Loss = 0.1593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 80: Train Loss = 0.1593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:45:56,788 - INFO - Epoch 94 Batch 100: Train Loss = 0.1311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 100: Train Loss = 0.1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:46:10,446 - INFO - Epoch 94 Batch 120: Train Loss = 0.1603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 120: Train Loss = 0.1603\n",
      "Epoch 94: Loss = 0.1838 Valid loss = 0.1618 roc = 0.8796\n",
      "confusion matrix:\n",
      "[[3707   35]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9526524543762207\n",
      "precision class 0 = 0.9596168994903564\n",
      "precision class 1 = 0.7953216433525085\n",
      "recall class 0 = 0.9906467199325562\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8795613290087346\n",
      "AUC of PRC = 0.6102841709704665\n",
      "min(+P, Se) = 0.5547945205479452\n",
      "f1_score = 0.5874730406365205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:46:20,715 - INFO - Epoch 95 Batch 0: Train Loss = 0.2566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 0: Train Loss = 0.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:46:34,855 - INFO - Epoch 95 Batch 20: Train Loss = 0.2226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 20: Train Loss = 0.2226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:46:49,052 - INFO - Epoch 95 Batch 40: Train Loss = 0.2115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 40: Train Loss = 0.2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:47:03,347 - INFO - Epoch 95 Batch 60: Train Loss = 0.1996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 60: Train Loss = 0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:47:17,685 - INFO - Epoch 95 Batch 80: Train Loss = 0.1473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 80: Train Loss = 0.1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:47:31,385 - INFO - Epoch 95 Batch 100: Train Loss = 0.1344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 100: Train Loss = 0.1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:47:44,560 - INFO - Epoch 95 Batch 120: Train Loss = 0.1957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 120: Train Loss = 0.1957\n",
      "Epoch 95: Loss = 0.1951 Valid loss = 0.1655 roc = 0.8779\n",
      "confusion matrix:\n",
      "[[3699   43]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9499256610870361\n",
      "precision class 0 = 0.9587869644165039\n",
      "precision class 1 = 0.7556818127632141\n",
      "recall class 0 = 0.9885088205337524\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.8779057422958934\n",
      "AUC of PRC = 0.5994398675114532\n",
      "min(+P, Se) = 0.547945205479452\n",
      "f1_score = 0.5683760598505446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:47:54,682 - INFO - Epoch 96 Batch 0: Train Loss = 0.2295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 0: Train Loss = 0.2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:48:08,376 - INFO - Epoch 96 Batch 20: Train Loss = 0.2377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 20: Train Loss = 0.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:48:21,138 - INFO - Epoch 96 Batch 40: Train Loss = 0.2121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 40: Train Loss = 0.2121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:48:33,899 - INFO - Epoch 96 Batch 60: Train Loss = 0.1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 60: Train Loss = 0.1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:48:48,128 - INFO - Epoch 96 Batch 80: Train Loss = 0.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 80: Train Loss = 0.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:49:01,536 - INFO - Epoch 96 Batch 100: Train Loss = 0.1454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 100: Train Loss = 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:49:15,041 - INFO - Epoch 96 Batch 120: Train Loss = 0.1665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Batch 120: Train Loss = 0.1665\n",
      "Epoch 96: Loss = 0.2084 Valid loss = 0.1567 roc = 0.8901\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9531482458114624\n",
      "precision class 0 = 0.9591625928878784\n",
      "precision class 1 = 0.8121212124824524\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8900888104668956\n",
      "AUC of PRC = 0.6328997430513371\n",
      "min(+P, Se) = 0.589041095890411\n",
      "f1_score = 0.5864332805719331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:49:25,816 - INFO - Epoch 97 Batch 0: Train Loss = 0.1974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 0: Train Loss = 0.1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:49:40,207 - INFO - Epoch 97 Batch 20: Train Loss = 0.2351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 20: Train Loss = 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:49:53,669 - INFO - Epoch 97 Batch 40: Train Loss = 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 40: Train Loss = 0.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:50:06,934 - INFO - Epoch 97 Batch 60: Train Loss = 0.2273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 60: Train Loss = 0.2273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:50:20,349 - INFO - Epoch 97 Batch 80: Train Loss = 0.1336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 80: Train Loss = 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:50:33,288 - INFO - Epoch 97 Batch 100: Train Loss = 0.1354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 100: Train Loss = 0.1354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:50:46,230 - INFO - Epoch 97 Batch 120: Train Loss = 0.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Batch 120: Train Loss = 0.1728\n",
      "Epoch 97: Loss = 0.1873 Valid loss = 0.1587 roc = 0.8853\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 156  136]]\n",
      "accuracy = 0.9536440372467041\n",
      "precision class 0 = 0.9596586227416992\n",
      "precision class 1 = 0.8143712282180786\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.465753436088562\n",
      "AUC of ROC = 0.8853435273789564\n",
      "AUC of PRC = 0.6214965291737403\n",
      "min(+P, Se) = 0.5753424657534246\n",
      "f1_score = 0.592592594096564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:50:56,452 - INFO - Epoch 98 Batch 0: Train Loss = 0.2422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 0: Train Loss = 0.2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:51:11,443 - INFO - Epoch 98 Batch 20: Train Loss = 0.2473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 20: Train Loss = 0.2473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:51:26,578 - INFO - Epoch 98 Batch 40: Train Loss = 0.2246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 40: Train Loss = 0.2246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:51:39,446 - INFO - Epoch 98 Batch 60: Train Loss = 0.2191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 60: Train Loss = 0.2191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:51:53,191 - INFO - Epoch 98 Batch 80: Train Loss = 0.1420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 80: Train Loss = 0.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:52:06,281 - INFO - Epoch 98 Batch 100: Train Loss = 0.1323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 100: Train Loss = 0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:52:19,516 - INFO - Epoch 98 Batch 120: Train Loss = 0.1935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Batch 120: Train Loss = 0.1935\n",
      "Epoch 98: Loss = 0.1951 Valid loss = 0.1605 roc = 0.8853\n",
      "confusion matrix:\n",
      "[[3710   32]\n",
      " [ 158  134]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9591520428657532\n",
      "precision class 1 = 0.8072289228439331\n",
      "recall class 0 = 0.9914484024047852\n",
      "recall class 1 = 0.45890411734580994\n",
      "AUC of ROC = 0.8853476457538639\n",
      "AUC of PRC = 0.6146296502443286\n",
      "min(+P, Se) = 0.5616438356164384\n",
      "f1_score = 0.5851528328472227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/torch/nn/functional.py:2905: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "2023-11-08 16:52:29,746 - INFO - Epoch 99 Batch 0: Train Loss = 0.2497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 0: Train Loss = 0.2497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:52:43,702 - INFO - Epoch 99 Batch 20: Train Loss = 0.2323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 20: Train Loss = 0.2323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:52:56,743 - INFO - Epoch 99 Batch 40: Train Loss = 0.2162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 40: Train Loss = 0.2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:53:09,400 - INFO - Epoch 99 Batch 60: Train Loss = 0.2058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 60: Train Loss = 0.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:53:22,166 - INFO - Epoch 99 Batch 80: Train Loss = 0.1648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 80: Train Loss = 0.1648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:53:34,945 - INFO - Epoch 99 Batch 100: Train Loss = 0.1276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 100: Train Loss = 0.1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:53:47,933 - INFO - Epoch 99 Batch 120: Train Loss = 0.1789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 120: Train Loss = 0.1789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:53:56,978 - INFO - auroc 0.8922\n",
      "2023-11-08 16:53:56,979 - INFO - auprc 0.6316\n",
      "2023-11-08 16:53:56,981 - INFO - minpse 0.5892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Loss = 0.1929 Valid loss = 0.1608 roc = 0.8797\n",
      "confusion matrix:\n",
      "[[3711   31]\n",
      " [ 159  133]]\n",
      "accuracy = 0.9529003500938416\n",
      "precision class 0 = 0.9589147567749023\n",
      "precision class 1 = 0.8109756112098694\n",
      "recall class 0 = 0.991715669631958\n",
      "recall class 1 = 0.4554794430732727\n",
      "AUC of ROC = 0.87966108520094\n",
      "AUC of PRC = 0.6159461362308065\n",
      "min(+P, Se) = 0.5582191780821918\n",
      "f1_score = 0.5833333263436843\n",
      "auroc 0.8922\n",
      "auprc 0.6316\n",
      "minpse 0.5892\n"
     ]
    }
   ],
   "source": [
    "# Training Student\n",
    "# If you don't want to train Student Model:\n",
    "# - The pretrained student model is in direcrtory './model/', and can be directly loaded, \n",
    "# - Simply skip this cell and load the model to validate on Dev Dataset.\n",
    "\n",
    "logger.info('Training Student')\n",
    "teacher_flag = True\n",
    "# epochs = 200\n",
    "epochs = 100\n",
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "global_best = 0\n",
    "auroc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "history = []\n",
    "\n",
    "pad_token = np.zeros(34)\n",
    "# begin_time = time.time()\n",
    "best_auroc = 0\n",
    "best_auprc = 0\n",
    "best_minpse = 0\n",
    "\n",
    "if target_dataset == 'PD':    \n",
    "    data_str = 'pd'\n",
    "\n",
    "if teacher_flag:\n",
    "    file_name = './model/pretrained-challenge-front-fill-2'+ data_str + '-lstm'\n",
    "else: \n",
    "    file_name = './model/pretrained-challenge-front-fill-2'+ data_str + '-noteacher' + '-lstm'\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "    counter_batch = 0\n",
    "    model_student.train()  \n",
    "    model.eval()\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(train_x, train_y, train_mask_x, train_x_len, batch_size, shuffle=False)):  \n",
    "        optimizer_student.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "#        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "        opt_student, decov_loss_student, emb_student, tar_result = model_student(batch_x[:,:,:subset_cnt], batch_x[:,:,subset_cnt:], batch_lens, [tar_all_x, tar_all_x_len], True)\n",
    "        emb_teacher = torch.tensor(train_teacher_emb[step], dtype=torch.float32).to(device)\n",
    "        # opt_teacher, decov_loss_teacher, emb_teacher = model(batch_x, batch_lens)\n",
    "#         BCE_Loss = get_loss(opt_student, batch_y.unsqueeze(-1)) # b t 1\n",
    "        #emb_Loss = 0.1 * get_re_loss(emb_student, emb_teacher.detach())\n",
    "        if teacher_flag:\n",
    "            emb_student = F.log_softmax(emb_student, dim=1)\n",
    "            emb_teacher = F.softmax(emb_teacher.detach(), dim=1)\n",
    "#             emb_Loss = get_kl_loss(emb_student, emb_teacher)\n",
    "            \n",
    "            tar_source = F.softmax(tar_result[0].squeeze(), dim=-1)\n",
    "            tar_tar = F.softmax(tar_result[1].squeeze(), dim=-1)\n",
    "#             shrink_indices = torch.tensor(np.random.choice(range(len(tar_tar)), len(tar_source))).to(device)\n",
    "#             tar_tar = torch.index_select(tar_tar, 0, shrink_indices)\n",
    "#             tar_Loss = get_kl_loss(tar_source, tar_tar)\n",
    "#             logger.info(tar_tar)\n",
    "#             logger.info(tar_source)\n",
    "#             logger.info(tar_Loss)\n",
    "            loss = get_multitask_loss(opt_student, batch_y.unsqueeze(-1), emb_student, emb_teacher, tar_source, tar_tar)\n",
    "        # emb_Loss = 0.1 * get_wass_dist(emb_student, emb_teacher.detach())\n",
    "#             REC_Loss = F.mse_loss(masks * recon, masks * batch_x, reduction='mean').to(device)\n",
    "        else:\n",
    "            loss = BCE_Loss #+ decov_loss_student\n",
    "\n",
    "        epoch_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_student.parameters(), 20)\n",
    "        optimizer_student.step()\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, loss.cpu().detach().numpy()))\n",
    "            logger.info('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, loss.cpu().detach().numpy()))\n",
    "\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    total_train_loss.append(epoch_loss)\n",
    "\n",
    "    #Validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        model_student.eval()\n",
    "        valid_loss = []\n",
    "        valid_true = []\n",
    "        valid_pred = []\n",
    "        for batch_x, batch_y, batch_mask_x, batch_lens in batch_iter(dev_x, dev_y, dev_mask_x, dev_x_len, batch_size):\n",
    "            batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "            batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "            batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "#            masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "\n",
    "            opt_student, decov_loss_student, emb, tar_result = model_student(batch_x[:,:,:subset_cnt], batch_x[:,:,subset_cnt:], batch_lens, [[], []], False)\n",
    "\n",
    "            BCE_Loss = get_loss(opt_student, batch_y.unsqueeze(-1))\n",
    "#                 REC_Loss = F.mse_loss(recon, batch_x, reduction='mean').to(device)\n",
    "\n",
    "            valid_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "\n",
    "            y_pred += list(opt_student.cpu().detach().numpy().flatten())\n",
    "            y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "        valid_loss = np.mean(valid_loss)\n",
    "        total_valid_loss.append(valid_loss)\n",
    "        ret = metrics.print_metrics_binary(y_true, y_pred,verbose = 0)\n",
    "        history.append(ret)\n",
    "        #print()\n",
    "\n",
    "        print('Epoch %d: Loss = %.4f Valid loss = %.4f roc = %.4f'%(each_epoch, total_train_loss[-1], total_valid_loss[-1], ret['auroc']))\n",
    "        metrics.print_metrics_binary(y_true, y_pred)\n",
    "\n",
    "        cur_auroc = ret['auroc']\n",
    "        if cur_auroc > best_auroc:\n",
    "            best_auroc = cur_auroc\n",
    "            best_auprc = ret['auprc']\n",
    "            best_minpse = ret['minpse']\n",
    "            state = {\n",
    "                'net': model_student.state_dict(),\n",
    "                'optimizer': optimizer_student.state_dict(),\n",
    "                'epoch': each_epoch\n",
    "            }\n",
    "            torch.save(state, file_name)\n",
    "            print('------------ Save best model - AUROC: %.4f ------------'%cur_auroc)\n",
    "            logger.info('------------ Save best model - AUROC: %.4f ------------'%cur_auroc)\n",
    "\n",
    "print('auroc %.4f'%(best_auroc))\n",
    "print('auprc %.4f'%(best_auprc))\n",
    "print('minpse %.4f'%(best_minpse)) \n",
    "logger.info('auroc %.4f'%(best_auroc))\n",
    "logger.info('auprc %.4f'%(best_auprc))\n",
    "logger.info('minpse %.4f'%(best_minpse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:17.118640Z",
     "start_time": "2021-02-10T15:06:15.660556Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:53:57,064 - INFO - last saved model is in epoch 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last saved model is in epoch 58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "distcare_student(\n",
       "  (PositionalEncoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (LSTMs): ModuleList(\n",
       "    (0): LSTM(1, 32, batch_first=True)\n",
       "    (1): LSTM(1, 32, batch_first=True)\n",
       "    (2): LSTM(1, 32, batch_first=True)\n",
       "    (3): LSTM(1, 32, batch_first=True)\n",
       "    (4): LSTM(1, 32, batch_first=True)\n",
       "    (5): LSTM(1, 32, batch_first=True)\n",
       "    (6): LSTM(1, 32, batch_first=True)\n",
       "    (7): LSTM(1, 32, batch_first=True)\n",
       "    (8): LSTM(1, 32, batch_first=True)\n",
       "    (9): LSTM(1, 32, batch_first=True)\n",
       "    (10): LSTM(1, 32, batch_first=True)\n",
       "    (11): LSTM(1, 32, batch_first=True)\n",
       "    (12): LSTM(1, 32, batch_first=True)\n",
       "    (13): LSTM(1, 32, batch_first=True)\n",
       "    (14): LSTM(1, 32, batch_first=True)\n",
       "    (15): LSTM(1, 32, batch_first=True)\n",
       "  )\n",
       "  (generalLSTM): LSTM(1, 32, batch_first=True)\n",
       "  (LastStepAttentions): ModuleList(\n",
       "    (0): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (1): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (2): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (3): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (4): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (5): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (6): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (7): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (8): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (9): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (10): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (11): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (12): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (13): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (14): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "    (15): SingleAttention(\n",
       "      (tanh): Tanh()\n",
       "      (softmax): Softmax(dim=None)\n",
       "    )\n",
       "  )\n",
       "  (FinalAttentionQKV): FinalAttentionQKV(\n",
       "    (W_q): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_k): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_v): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (W_out): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (tanh): Tanh()\n",
       "    (softmax): Softmax(dim=None)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (MultiHeadedAttention): MultiHeadedAttention(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (final_linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (SublayerConnection): SublayerConnection(\n",
       "    (norm): LayerNorm()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (PositionwiseFeedForward): PositionwiseFeedForward(\n",
       "    (w_1): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (w_2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (demo_proj_main): Linear(in_features=12, out_features=32, bias=True)\n",
       "  (demo_proj): Linear(in_features=12, out_features=32, bias=True)\n",
       "  (Linear): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (output): Linear(in_features=34, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (FC_embed): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (softmax): Softmax(dim=None)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       "  (to_MMD): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_flag = True\n",
    "\n",
    "if target_dataset == 'PD':    \n",
    "    data_str = 'pd'\n",
    "\n",
    "if teacher_flag:\n",
    "    file_name = './model/pretrained-challenge-front-fill-2'+ data_str + '-lstm'\n",
    "else: \n",
    "    file_name = './model/pretrained-challenge-front-fill-2'+ data_str + '-noteacher' + '-lstm'\n",
    "\n",
    "checkpoint = torch.load(file_name, \\\n",
    "                        map_location=torch.device(\"cuda:2\" if torch.cuda.is_available() == True else 'cpu') )\n",
    "save_epoch = checkpoint['epoch']\n",
    "print(\"last saved model is in epoch {}\".format(save_epoch))\n",
    "logger.info(\"last saved model is in epoch {}\".format(save_epoch))\n",
    "model_student.load_state_dict(checkpoint['net'])\n",
    "optimizer_student.load_state_dict(checkpoint['optimizer'])\n",
    "model_student.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T15:40:05.462185Z",
     "start_time": "2021-01-30T15:40:00.917653Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:53:57,528 - INFO - Batch 0: Test Loss = 0.2240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Test Loss = 0.2240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:02,991 - INFO - \n",
      "==>Predicting on test\n",
      "2023-11-08 16:54:02,994 - INFO - Test Loss = 0.1453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==>Predicting on test\n",
      "Test Loss = 0.1453\n",
      "confusion matrix:\n",
      "[[3716   20]\n",
      " [ 152  145]]\n",
      "accuracy = 0.9573518633842468\n",
      "precision class 0 = 0.9607031941413879\n",
      "precision class 1 = 0.8787878751754761\n",
      "recall class 0 = 0.9946466684341431\n",
      "recall class 1 = 0.48821547627449036\n",
      "AUC of ROC = 0.9109429411891938\n",
      "AUC of PRC = 0.6883074807781097\n",
      "min(+P, Se) = 0.6531986531986532\n",
      "f1_score = 0.6277056305992361\n"
     ]
    }
   ],
   "source": [
    "batch_loss = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    model_student.eval()\n",
    "    for step, (batch_x, batch_y, batch_mask_x, batch_lens) in enumerate(batch_iter(test_x, test_y, test_mask_x, test_x_len, batch_size, shuffle=True)):  \n",
    "        optimizer_student.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "\n",
    "        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "        opt, decov_loss, emb, tar_result = model_student(batch_x[:,:,:subset_cnt], batch_x[:,:,subset_cnt:], batch_lens, [[], []], False)\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "#             REC_Loss = F.mse_loss(masks * recon, masks * batch_x, reduction='mean').to(device)\n",
    "\n",
    "        model_loss =  BCE_Loss \n",
    "\n",
    "        loss = model_loss\n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        if step % 20 == 0:\n",
    "            print('Batch %d: Test Loss = %.4f'%(step, loss.cpu().detach().numpy()))\n",
    "            logger.info('Batch %d: Test Loss = %.4f'%(step, loss.cpu().detach().numpy()))\n",
    "        y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "print(\"\\n==>Predicting on test\")\n",
    "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "logger.info(\"\\n==>Predicting on test\")\n",
    "logger.info('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "test_res = metrics.print_metrics_binary(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Target Dataset & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:28.889438Z",
     "start_time": "2021-02-10T15:06:28.597765Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:03,037 - INFO - Transfer Target Dataset & Model\n",
      "2023-11-08 16:54:03,113 - INFO - [[-0.8427648213988651, 0.3744020210323477, 0.6796123704286434, -1.398975413973587, -0.4831419202847951, -0.2120300841305121, 1.5887596625600091, 0.7945789587268225, -0.8612693268611251, -0.4819729243606949, -0.6745224313841819, 0.7137208435891645, -1.447089954740047, -0.7710128163592748, -1.4231815568069368, -0.5851405270139463, -0.5641898854144399, 0.5775106850669863, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, 0.1700684310067274, -0.2031244129114749, -0.9752387057279804, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, -0.0343615044915247, -1.3314821107815475, 0.3379315521074886, -0.3880554131475662, 0.8285543981909917, 2.770245567717861, 0.0776143028335215, -0.1259757336723928, 0.0863841325254607, -0.1474826847594624, -0.3999358135056357, -0.0116277505661367, -0.0886088512738706, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.211245000207003, -0.1237195765566573, -0.1259757336723928, 0.0421701504838569, -0.1474826847594624, -0.5354516373428909, -0.0075043080636137, -0.0934220672822521, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.1716333969449267, 2.9568603317603377, 4.808428260230306, -0.1299430434915742, 1.4769583166408096, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.8427648213988651, 0.3744020210323477, 0.6796123704286434, -1.398975413973587, -0.4831419202847951, -0.2120300841305121, 1.5887596625600091, 0.7945789587268225, -0.8612693268611251, -0.4819729243606949, -0.6745224313841819, 0.7137208435891645, -1.447089954740047, -0.7710128163592748, -1.4231815568069368, -0.5851405270139463, -0.5641898854144399, 0.5775106850669863, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, 0.1700684310067274, -0.2031244129114749, -0.9752387057279804, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, -0.0343615044915247, -1.3314821107815475, 0.3379315521074886, -0.3880554131475662, 0.8374745525934485, 2.8093811444689463, 0.0776143028335215, -0.1259757336723928, 0.0863841325254607, -0.1474826847594624, -0.3999358135056357, -0.0116277505661367, -0.0886088512738706, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.211245000207003, -0.1237195765566573, -0.1259757336723928, 0.0421701504838569, -0.1474826847594624, -0.5354516373428909, -0.0075043080636137, -0.0934220672822521, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.1716333969449267, 2.9568603317603377, 4.808428260230306, -0.1299430434915742, 1.4769583166408096, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.5338330207864587, 0.431156978499758, 0.8964660630930379, -1.342421748214616, -0.6946051308187712, -0.2120300841305121, 0.8952797203562032, 0.0387041303378994, -0.8612693268611251, 0.0726334784031089, -0.5051102137388988, -0.2865727201409924, 0.3988826585206329, -1.3794377690564883, -0.8237089728907875, -0.9221119476695248, -1.6036614531597553, -0.2379932071009605, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, 0.1700684310067274, -0.2031244129114749, -1.1501193786706505, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, 1.0826051686869729, -0.609009148503521, 0.9684393533852332, -0.3880554131475662, 0.8439788318452395, 2.837917502516613, 0.0776143028335215, -0.1259757336723928, 0.0863841325254607, -0.1474826847594624, -0.3999358135056357, -0.0116277505661367, -0.0886088512738706, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.211245000207003, -0.1237195765566573, -0.1259757336723928, 0.0421701504838569, -0.1474826847594624, -0.5354516373428909, -0.0075043080636137, -0.0934220672822521, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.1716333969449267, 0.278477698357045, 1.2505677424119097, -0.6305581644917595, -0.9062745442328174, -0.7536814885080627, -0.4374103947888615, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.7113800326326694, 0.0906272336952961, 0.5576321683049205, -1.398975413973587, -0.8637756992459511, -0.2120300841305121, 0.4685228328461679, 0.3356549557764047, -0.8612693268611251, -0.574407324821329, -0.5014273394422621, -0.1711542320182811, -0.2539613144618027, -0.7710128163592748, -0.6738408269117502, -2.438483340619628, -0.5641898854144399, 0.1697587389830128, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, -0.2977155549892737, -0.2031244129114749, -0.725409172952738, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, -0.416884337771832, -1.3888212347718671, 0.4897491553635549, -0.7942874573364652, 0.8608899578998963, 2.912112033440545, 0.0776143028335215, -0.2834309446219887, 0.0790528888855871, -0.1474826847594624, -0.3999358135056357, -0.0186903386836148, -0.0954522063493915, -0.1491049589303728, 0.0386929407875269, -0.0467618786482574, -0.2380657795779712, -0.3380281643183785, -0.2834309446219887, -0.1096727847689199, -0.1474826847594624, -0.5354516373428909, -0.0015148687509932, -0.087488649839324, -0.1491049589303728, 0.0386929407875269, -0.0467618786482574, -0.158735060378334, 0.278477698357045, 1.2505677424119097, -0.3396023676711391, 1.4769583166408096, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.7113800326326694, 0.0906272336952961, 0.5576321683049205, -1.398975413973587, -0.8637756992459511, -0.2120300841305121, 0.4685228328461679, 0.3356549557764047, -0.8612693268611251, -0.574407324821329, -0.5014273394422621, -0.1711542320182811, -0.2539613144618027, 0.6486454066008902, 0.0754999029834364, -0.5851405270139463, -0.5641898854144399, 0.1697587389830128, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, -0.2977155549892737, -0.2031244129114749, -0.725409172952738, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, -0.416884337771832, -1.3888212347718671, 0.4897491553635549, -0.7942874573364652, 0.8763143915541441, 2.979783968239297, 0.0776143028335215, -0.2834309446219887, 0.0790528888855871, -0.1474826847594624, -0.3999358135056357, -0.0186903386836148, -0.0954522063493915, -0.1491049589303728, 0.0386929407875269, -0.0467618786482574, -0.2380657795779712, -0.3380281643183785, -0.2834309446219887, -0.1096727847689199, -0.1474826847594624, -0.5354516373428909, -0.0015148687509932, -0.087488649839324, -0.1491049589303728, 0.0386929407875269, -0.0467618786482574, -0.158735060378334, 0.278477698357045, 1.2505677424119097, -0.3310448442352384, 1.4769583166408096, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.5125273793649132, 0.601421850901989, 0.5034187451388209, -1.455529079732558, -0.5254345623915906, -0.4163803392884947, 0.7885904984786939, 0.2816638966057675, -0.5890172833864098, 0.5902661209826593, -0.3430637446868887, -0.7482466726318323, -0.1864257310498265, 0.6486454066008902, 0.0754999029834364, -0.5851405270139463, -0.2249939001501796, -0.0341172340589738, 0.3466058957088718, 0.3482841380580905, -0.2890718868318484, 0.1923438589112976, -0.2031244129114749, -1.100153472115602, -0.7598199909551685, -0.6868858002659636, 0.3602180776283341, -0.700061185363224, -0.501359972189453, -0.2332733777972843, -1.36588558517574, 0.3571411263970316, -0.7447833078367583, 0.8765002281041955, 2.9805992927549454, 0.0776143028335215, -0.2769313825285214, 0.0755136678180621, -0.1474826847594624, -0.3999358135056357, -0.0169688050451549, -0.0937841116273902, -0.1491049589303728, 0.0432268846241116, -0.0437620129498739, -0.0122781725754626, -0.3292808750219816, -0.2769313825285214, -0.107625012968948, -0.1474826847594624, -0.5354516373428909, -0.0002229391773086, -0.0862088042532133, -0.1491049589303728, 0.0432268846241116, -0.0437620129498739, 0.0766269712424727, 0.278477698357045, 1.2505677424119097, -0.3310448442352384, 1.4769583166408096, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.4628142160479743, -0.2499025111091658, -0.3775493813102845, -1.1162070851787322, -1.1739217413624488, 0.196670426185453, 0.6819012766011855, 0.4706326037029981, -0.6071674196180575, -0.1492090827024124, -0.3356979960936155, -0.4404640376379396, -1.2444832045041183, 0.3951350096437179, -0.5239726809327129, -0.8378690925056301, -0.4766554376043083, 0.3736347120249996, 0.6308857408036841, 0.0418502001162623, -0.4309446948506726, -0.2531646991801318, -0.2031244129114749, -0.5255455467325439, -0.5868915885967425, -0.6218024077192129, -0.0802984588359218, -0.3815866107489131, -0.4869285481637944, 0.424665895444844, -1.3314821107815475, 0.3571411263970316, -0.7746182501104947, 0.8988006141103361, 3.0784382346326584, 0.0776143028335215, -0.3487779453829513, 0.070457637721598, -0.1474826847594624, -0.3999358135056357, 0.0045338857876385, -0.0729488956980065, -0.1491049589303728, 0.031626468995041, -0.0514373812797239, -0.1275947723114954, -0.4255010572823463, -0.3487779453829513, -0.1777070069371955, -0.1474826847594624, -0.5354516373428909, 0.029608437271828, -0.0566564538358881, -0.1491049589303728, 0.031626468995041, -0.0514373812797239, -0.0232601678654147, 0.278477698357045, 2.1729760248092718, -0.4251776020301452, 1.4769583166408096, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.4628142160479743, -0.2499025111091658, -0.3775493813102845, -1.1162070851787322, -1.1739217413624488, 0.196670426185453, 0.6819012766011855, 0.4706326037029981, -0.6071674196180575, -0.1492090827024124, -0.3356979960936155, -0.4404640376379396, -1.2444832045041183, 0.6993474859923247, -0.6738408269117502, -0.9221119476695248, -0.4766554376043083, 0.3736347120249996, 0.6308857408036841, 0.0418502001162623, -0.4309446948506726, -0.2531646991801318, -0.2031244129114749, -0.5255455467325439, -0.5868915885967425, -0.6218024077192129, -0.0802984588359218, -0.3815866107489131, -0.4869285481637944, 0.424665895444844, -1.3314821107815475, 0.3571411263970316, -0.7746182501104947, 0.9106941533136118, 3.1306190036341057, 0.0776143028335215, -0.3487779453829513, 0.067761088336817, -0.1474826847594624, -0.3999358135056357, -0.0560864903921214, -0.131687526934778, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.3339787568372257, -0.4255010572823463, -0.3487779453829513, -0.1806223481889086, -0.1474826847594624, -0.5354516373428909, -0.036772356694307, -0.1224163589348786, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.2440563017214069, 0.278477698357045, 2.1729760248092718, -0.4251776020301452, 0.285341886203996, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.6439121681311092, 0.0338722762278857, -0.174249044437414, -1.3706985810941017, -0.553629657129454, 0.4010206813434356, 1.2420196914581063, 0.4706326037029981, -0.6071674196180575, -0.8701974062953576, -0.4351356021028035, 0.021209914852902, -1.064388315405516, 0.6993474859923247, -0.6738408269117502, -0.9221119476695248, -0.7939678109160361, 0.3736347120249996, 0.6308857408036841, 0.0418502001162623, -0.4309446948506726, -0.565020689844132, -0.2031244129114749, -1.287525621697034, -0.5868915885967425, -0.6218024077192129, -0.0802984588359218, -0.3815866107489131, -0.4454382040900255, 0.424665895444844, -1.3314821107815475, 0.6186392022095215, -0.8622687408969322, 0.9108799898636633, 3.1314343281497536, 0.0776143028335215, -0.3487779453829513, 0.067761088336817, -0.1474826847594624, -0.3999358135056357, -0.0560864903921214, -0.131687526934778, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.3339787568372257, -0.4255010572823463, -0.3487779453829513, -0.1806223481889086, -0.1474826847594624, -0.5354516373428909, -0.036772356694307, -0.1224163589348786, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.2440563017214069, 0.278477698357045, 2.1729760248092718, -0.4251776020301452, 0.285341886203996, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.6439121681311092, 0.0338722762278857, -0.174249044437414, -1.3706985810941017, -0.553629657129454, 0.4010206813434356, 1.2420196914581063, 0.4706326037029981, -0.6071674196180575, -0.8701974062953576, -0.4351356021028035, 0.021209914852902, -1.064388315405516, 1.0542620417323658, -0.6738408269117502, -0.0796833960305785, -0.7939678109160361, 0.3736347120249996, 0.6308857408036841, 0.0418502001162623, -0.4309446948506726, -0.565020689844132, -0.2031244129114749, -1.287525621697034, -0.5868915885967425, -0.6218024077192129, -0.0802984588359218, -0.3815866107489131, -0.4454382040900255, 0.424665895444844, -1.3314821107815475, 0.6186392022095215, -0.8622687408969322, 0.9222160194167848, 3.1811691236042576, 0.0776143028335215, -0.3487779453829513, 0.067761088336817, -0.1474826847594624, -0.3999358135056357, -0.0560864903921214, -0.131687526934778, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.3339787568372257, -0.4255010572823463, -0.3487779453829513, -0.1806223481889086, -0.1474826847594624, -0.5354516373428909, -0.036772356694307, -0.1224163589348786, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.2440563017214069, 0.278477698357045, 2.1729760248092718, -0.5107528363891513, 1.4769583166408096, -0.7536814885080627, -0.5709283205126147, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-1.038066534429697, 0.260892106097527, 0.1645848503507034, -1.455529079732558, -1.6391408045371951, 0.196670426185453, 1.2420196914581063, 0.4706326037029981, -0.6616178283130005, -0.5004598044528213, -0.4609157221792596, 0.021209914852902, -1.1769476210921423, 0.0909225332951111, -1.348247483817418, -1.2590833683251033, -0.9252694826312332, 0.781386658108973, -0.0798138719333467, -0.2032969502372001, -0.5728175028694968, 0.103242147293012, -0.2031244129114749, -0.6504603131201653, -0.5868915885967425, -0.6218024077192129, -0.0284729839577739, -0.3925684926321655, -0.4454382040900255, -0.2791761177909213, -1.5149673075505703, 0.3413397023846657, -0.8352815289623093, 0.9329945393197532, 3.228457945511819, 0.0776143028335215, -0.4147760464289071, 0.0627050582403518, -0.1474826847594624, -0.3999358135056357, -0.050494972406442, -0.126269577827358, -0.1491049589303728, -0.3712584158476188, -0.318004544437855, -0.2624212575170594, -0.512973950246314, -0.4147760464289071, -0.2448301849643134, -0.1474826847594624, -0.5354516373428909, -0.0251798677021788, -0.1109322996093401, -0.1491049589303728, -0.3712584158476188, -0.318004544437855, -0.1500627926219946, 0.278477698357045, 2.1729760248092718, -0.4251776020301452, 1.4769583166408096, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.8995798651896526, 0.4879119359671683, 0.1510314945591795, -1.4131138304133295, -0.6523124887119757, 0.196670426185453, 0.148455167213642, 0.4706326037029981, -0.752368509471239, -0.9441449266638648, -0.9507380036319262, 0.1751012323498492, -1.0418764542681906, 0.5472412478180213, -0.6738408269117502, -1.0063548028334193, -1.3629417216818924, 0.1697587389830128, -0.364093717028159, -0.2645837378255657, -0.2890718868318484, 0.0364158635792983, -0.2031244129114749, -1.8246591171638051, -0.4061028043129334, -0.5350245509902118, 0.0492652283594477, 0.0357249008146661, -0.4929416415078188, -0.5851943844151671, -1.170932563608653, 0.051337096981241, -0.8763418268751098, 0.9447022419729768, 3.279823389997619, 0.0776143028335215, -0.4147760464289071, 0.0627050582403518, -0.1474826847594624, -0.3999358135056357, -0.050494972406442, -0.126269577827358, -0.1491049589303728, -0.3712584158476188, -0.318004544437855, -0.2624212575170594, -0.512973950246314, -0.4147760464289071, -0.2448301849643134, -0.1474826847594624, -0.5354516373428909, -0.0251798677021788, -0.1109322996093401, -0.1491049589303728, -0.3712584158476188, -0.318004544437855, -0.1500627926219946, 0.278477698357045, 1.2505677424119097, -0.5107528363891513, -0.9062745442328174, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.5764443036295489, 0.3176470635649374, -0.1200356212713144, -1.300006498895388, -0.6382149413430442, 0.196670426185453, 0.8686074148868256, 0.4706326037029981, -0.806818918166182, -0.2416434831630464, -1.0022982437848384, -4.71094809817822, 6.994857971756963, 0.5472412478180213, -0.6738408269117502, -1.0063548028334193, -0.8377350348211018, 0.1697587389830128, -0.364093717028159, -0.1420101626488345, -0.0053262707941999, 0.5487507053844415, -0.2031244129114749, -4.805500187471612, -0.0209440899691673, -0.6001079435369626, 0.5156945022627775, 0.2883081841294641, -0.4929416415078188, -0.9218144777018374, -1.2626751619931649, -0.1547010788662775, -0.8374007701449055, 0.962914223877992, 3.359725192531085, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.5107528363891513, -0.9062745442328174, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.5764443036295489, 0.3176470635649374, -0.1200356212713144, -1.300006498895388, -0.6382149413430442, 0.196670426185453, 0.8686074148868256, 0.4706326037029981, -0.806818918166182, -0.2416434831630464, -1.0022982437848384, -4.71094809817822, 6.994857971756963, 0.2430287714694145, 0.8248406328786231, -1.4275690786528925, -0.8377350348211018, 0.1697587389830128, -0.364093717028159, -0.1420101626488345, -0.0053262707941999, 0.5487507053844415, -0.2031244129114749, -4.805500187471612, -0.0209440899691673, -0.6001079435369626, 0.5156945022627775, 0.2883081841294641, -0.4929416415078188, -0.9218144777018374, -1.2626751619931649, -0.1547010788662775, -0.8374007701449055, 0.973321070680858, 3.405383365407351, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.6819033051071632, -0.9062745442328174, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2320031006479001, -0.647187213381038, -0.4182094486848582, -1.1586223344979605, -1.3289947624206973, -0.2120300841305121, 0.2551443890911503, 1.1995119025066026, -0.752368509471239, -0.3340778836236804, -0.93600650644538, -0.0942085732698075, -0.096378286500525, 0.2430287714694145, 0.8248406328786231, -1.4275690786528925, -1.0237457364176323, -0.0341172340589738, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -1.2375597151419853, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.8912126510394129, -1.182400388406717, 0.1117543064402878, -0.8615402517404147, 0.9735069072309092, 3.4061986899229986, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.6819033051071632, -0.9062745442328174, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2320031006479001, -0.647187213381038, -0.4182094486848582, -1.1586223344979605, -1.3289947624206973, -0.2120300841305121, 0.2551443890911503, 1.1995119025066026, -0.752368509471239, -0.3340778836236804, -0.93600650644538, -0.0942085732698075, -0.096378286500525, -1.0752252927078816, -1.0485111918593435, 2.279116548558471, -1.0237457364176323, -0.0341172340589738, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -1.2375597151419853, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.8912126510394129, -1.182400388406717, 0.1117543064402878, -0.8615402517404147, 0.9980373318376644, 3.5138215259884835, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.7674785394661693, -0.9062745442328174, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2142483994632791, -0.0228826812395245, 0.0154979366439325, -1.087930252299247, -0.920165888721678, 0.196670426185453, -1.0517985789083308, 1.1995119025066026, -0.752368509471239, 0.9600037228251952, -0.7039854257572746, -0.5174096963864115, 0.6240012698938863, -1.0752252927078816, -1.0485111918593435, 2.279116548558471, -0.1702848702688472, 0.781386658108973, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -0.825340986062835, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.6004952977463793, -1.6411133803292737, 0.9483002835655512, -0.8615402517404147, 1.0340896225475933, 3.671994482024121, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.7674785394661693, -0.9062745442328174, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2142483994632791, -0.0228826812395245, 0.0154979366439325, -1.087930252299247, -0.920165888721678, 0.196670426185453, -1.0517985789083308, 1.1995119025066026, -0.752368509471239, 0.9600037228251952, -0.7039854257572746, -0.5174096963864115, 0.6240012698938863, -0.2639920224449301, -0.6738408269117502, 2.279116548558471, -0.1702848702688472, 0.781386658108973, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -0.825340986062835, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.6004952977463793, -1.6411133803292737, 0.9483002835655512, -0.8615402517404147, 1.0396647190491284, 3.696454217493548, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.7418059691584676, -0.9062745442328174, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2142483994632791, -0.0228826812395245, 0.0154979366439325, -1.087930252299247, -0.920165888721678, 0.196670426185453, -1.0517985789083308, 1.1995119025066026, -0.752368509471239, 0.9600037228251952, -0.7039854257572746, -0.5174096963864115, 0.6240012698938863, -0.7710128163592748, -0.6738408269117502, -0.6693833821778409, -0.1702848702688472, 0.781386658108973, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -0.825340986062835, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.6004952977463793, -1.6411133803292737, 0.9483002835655512, -0.8615402517404147, 1.057505027854041, 3.774725370995719, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.5792130238763558, -0.9062745442328174, -0.7536814885080627, -0.5709283205126147, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2142483994632791, -0.0228826812395245, 0.0154979366439325, -1.087930252299247, -0.920165888721678, 0.196670426185453, -1.0517985789083308, 1.1995119025066026, -0.752368509471239, 0.9600037228251952, -0.7039854257572746, -0.5174096963864115, 0.6240012698938863, -0.7710128163592748, -0.6738408269117502, 0.0888023142972107, -0.1702848702688472, 0.781386658108973, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -0.825340986062835, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.6004952977463793, -1.6411133803292737, 0.9483002835655512, -0.8615402517404147, 1.0760886828591592, 3.856257822560481, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.6819033051071632, -0.9062745442328174, -0.7536814885080627, -0.8379641719601209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:03,117 - INFO - 69\n",
      "2023-11-08 16:54:03,117 - INFO - 325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8427648213988651, 0.3744020210323477, 0.6796123704286434, -1.398975413973587, -0.4831419202847951, -0.2120300841305121, 1.5887596625600091, 0.7945789587268225, -0.8612693268611251, -0.4819729243606949, -0.6745224313841819, 0.7137208435891645, -1.447089954740047, -0.7710128163592748, -1.4231815568069368, -0.5851405270139463, -0.5641898854144399, 0.5775106850669863, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, 0.1700684310067274, -0.2031244129114749, -0.9752387057279804, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, -0.0343615044915247, -1.3314821107815475, 0.3379315521074886, -0.3880554131475662, 0.8285543981909917, 2.770245567717861, 0.0776143028335215, -0.1259757336723928, 0.0863841325254607, -0.1474826847594624, -0.3999358135056357, -0.0116277505661367, -0.0886088512738706, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.211245000207003, -0.1237195765566573, -0.1259757336723928, 0.0421701504838569, -0.1474826847594624, -0.5354516373428909, -0.0075043080636137, -0.0934220672822521, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.1716333969449267, 2.9568603317603377, 4.808428260230306, -0.1299430434915742, 1.4769583166408096, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.8427648213988651, 0.3744020210323477, 0.6796123704286434, -1.398975413973587, -0.4831419202847951, -0.2120300841305121, 1.5887596625600091, 0.7945789587268225, -0.8612693268611251, -0.4819729243606949, -0.6745224313841819, 0.7137208435891645, -1.447089954740047, -0.7710128163592748, -1.4231815568069368, -0.5851405270139463, -0.5641898854144399, 0.5775106850669863, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, 0.1700684310067274, -0.2031244129114749, -0.9752387057279804, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, -0.0343615044915247, -1.3314821107815475, 0.3379315521074886, -0.3880554131475662, 0.8374745525934485, 2.8093811444689463, 0.0776143028335215, -0.1259757336723928, 0.0863841325254607, -0.1474826847594624, -0.3999358135056357, -0.0116277505661367, -0.0886088512738706, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.211245000207003, -0.1237195765566573, -0.1259757336723928, 0.0421701504838569, -0.1474826847594624, -0.5354516373428909, -0.0075043080636137, -0.0934220672822521, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.1716333969449267, 2.9568603317603377, 4.808428260230306, -0.1299430434915742, 1.4769583166408096, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.5338330207864587, 0.431156978499758, 0.8964660630930379, -1.342421748214616, -0.6946051308187712, -0.2120300841305121, 0.8952797203562032, 0.0387041303378994, -0.8612693268611251, 0.0726334784031089, -0.5051102137388988, -0.2865727201409924, 0.3988826585206329, -1.3794377690564883, -0.8237089728907875, -0.9221119476695248, -1.6036614531597553, -0.2379932071009605, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, 0.1700684310067274, -0.2031244129114749, -1.1501193786706505, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, 1.0826051686869729, -0.609009148503521, 0.9684393533852332, -0.3880554131475662, 0.8439788318452395, 2.837917502516613, 0.0776143028335215, -0.1259757336723928, 0.0863841325254607, -0.1474826847594624, -0.3999358135056357, -0.0116277505661367, -0.0886088512738706, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.211245000207003, -0.1237195765566573, -0.1259757336723928, 0.0421701504838569, -0.1474826847594624, -0.5354516373428909, -0.0075043080636137, -0.0934220672822521, -0.1491049589303728, 0.0552791522161626, -0.0357876785866217, -0.1716333969449267, 0.278477698357045, 1.2505677424119097, -0.6305581644917595, -0.9062745442328174, -0.7536814885080627, -0.4374103947888615, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.7113800326326694, 0.0906272336952961, 0.5576321683049205, -1.398975413973587, -0.8637756992459511, -0.2120300841305121, 0.4685228328461679, 0.3356549557764047, -0.8612693268611251, -0.574407324821329, -0.5014273394422621, -0.1711542320182811, -0.2539613144618027, -0.7710128163592748, -0.6738408269117502, -2.438483340619628, -0.5641898854144399, 0.1697587389830128, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, -0.2977155549892737, -0.2031244129114749, -0.725409172952738, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, -0.416884337771832, -1.3888212347718671, 0.4897491553635549, -0.7942874573364652, 0.8608899578998963, 2.912112033440545, 0.0776143028335215, -0.2834309446219887, 0.0790528888855871, -0.1474826847594624, -0.3999358135056357, -0.0186903386836148, -0.0954522063493915, -0.1491049589303728, 0.0386929407875269, -0.0467618786482574, -0.2380657795779712, -0.3380281643183785, -0.2834309446219887, -0.1096727847689199, -0.1474826847594624, -0.5354516373428909, -0.0015148687509932, -0.087488649839324, -0.1491049589303728, 0.0386929407875269, -0.0467618786482574, -0.158735060378334, 0.278477698357045, 1.2505677424119097, -0.3396023676711391, 1.4769583166408096, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.7113800326326694, 0.0906272336952961, 0.5576321683049205, -1.398975413973587, -0.8637756992459511, -0.2120300841305121, 0.4685228328461679, 0.3356549557764047, -0.8612693268611251, -0.574407324821329, -0.5014273394422621, -0.1711542320182811, -0.2539613144618027, 0.6486454066008902, 0.0754999029834364, -0.5851405270139463, -0.5641898854144399, 0.1697587389830128, 0.3939858698913405, -0.2032969502372001, -0.2890718868318484, -0.2977155549892737, -0.2031244129114749, -0.725409172952738, -0.995631448716658, -0.7346136214669141, 0.2047416529938912, -0.7879162404292406, -0.4658827214597087, -0.416884337771832, -1.3888212347718671, 0.4897491553635549, -0.7942874573364652, 0.8763143915541441, 2.979783968239297, 0.0776143028335215, -0.2834309446219887, 0.0790528888855871, -0.1474826847594624, -0.3999358135056357, -0.0186903386836148, -0.0954522063493915, -0.1491049589303728, 0.0386929407875269, -0.0467618786482574, -0.2380657795779712, -0.3380281643183785, -0.2834309446219887, -0.1096727847689199, -0.1474826847594624, -0.5354516373428909, -0.0015148687509932, -0.087488649839324, -0.1491049589303728, 0.0386929407875269, -0.0467618786482574, -0.158735060378334, 0.278477698357045, 1.2505677424119097, -0.3310448442352384, 1.4769583166408096, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.5125273793649132, 0.601421850901989, 0.5034187451388209, -1.455529079732558, -0.5254345623915906, -0.4163803392884947, 0.7885904984786939, 0.2816638966057675, -0.5890172833864098, 0.5902661209826593, -0.3430637446868887, -0.7482466726318323, -0.1864257310498265, 0.6486454066008902, 0.0754999029834364, -0.5851405270139463, -0.2249939001501796, -0.0341172340589738, 0.3466058957088718, 0.3482841380580905, -0.2890718868318484, 0.1923438589112976, -0.2031244129114749, -1.100153472115602, -0.7598199909551685, -0.6868858002659636, 0.3602180776283341, -0.700061185363224, -0.501359972189453, -0.2332733777972843, -1.36588558517574, 0.3571411263970316, -0.7447833078367583, 0.8765002281041955, 2.9805992927549454, 0.0776143028335215, -0.2769313825285214, 0.0755136678180621, -0.1474826847594624, -0.3999358135056357, -0.0169688050451549, -0.0937841116273902, -0.1491049589303728, 0.0432268846241116, -0.0437620129498739, -0.0122781725754626, -0.3292808750219816, -0.2769313825285214, -0.107625012968948, -0.1474826847594624, -0.5354516373428909, -0.0002229391773086, -0.0862088042532133, -0.1491049589303728, 0.0432268846241116, -0.0437620129498739, 0.0766269712424727, 0.278477698357045, 1.2505677424119097, -0.3310448442352384, 1.4769583166408096, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.4628142160479743, -0.2499025111091658, -0.3775493813102845, -1.1162070851787322, -1.1739217413624488, 0.196670426185453, 0.6819012766011855, 0.4706326037029981, -0.6071674196180575, -0.1492090827024124, -0.3356979960936155, -0.4404640376379396, -1.2444832045041183, 0.3951350096437179, -0.5239726809327129, -0.8378690925056301, -0.4766554376043083, 0.3736347120249996, 0.6308857408036841, 0.0418502001162623, -0.4309446948506726, -0.2531646991801318, -0.2031244129114749, -0.5255455467325439, -0.5868915885967425, -0.6218024077192129, -0.0802984588359218, -0.3815866107489131, -0.4869285481637944, 0.424665895444844, -1.3314821107815475, 0.3571411263970316, -0.7746182501104947, 0.8988006141103361, 3.0784382346326584, 0.0776143028335215, -0.3487779453829513, 0.070457637721598, -0.1474826847594624, -0.3999358135056357, 0.0045338857876385, -0.0729488956980065, -0.1491049589303728, 0.031626468995041, -0.0514373812797239, -0.1275947723114954, -0.4255010572823463, -0.3487779453829513, -0.1777070069371955, -0.1474826847594624, -0.5354516373428909, 0.029608437271828, -0.0566564538358881, -0.1491049589303728, 0.031626468995041, -0.0514373812797239, -0.0232601678654147, 0.278477698357045, 2.1729760248092718, -0.4251776020301452, 1.4769583166408096, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.4628142160479743, -0.2499025111091658, -0.3775493813102845, -1.1162070851787322, -1.1739217413624488, 0.196670426185453, 0.6819012766011855, 0.4706326037029981, -0.6071674196180575, -0.1492090827024124, -0.3356979960936155, -0.4404640376379396, -1.2444832045041183, 0.6993474859923247, -0.6738408269117502, -0.9221119476695248, -0.4766554376043083, 0.3736347120249996, 0.6308857408036841, 0.0418502001162623, -0.4309446948506726, -0.2531646991801318, -0.2031244129114749, -0.5255455467325439, -0.5868915885967425, -0.6218024077192129, -0.0802984588359218, -0.3815866107489131, -0.4869285481637944, 0.424665895444844, -1.3314821107815475, 0.3571411263970316, -0.7746182501104947, 0.9106941533136118, 3.1306190036341057, 0.0776143028335215, -0.3487779453829513, 0.067761088336817, -0.1474826847594624, -0.3999358135056357, -0.0560864903921214, -0.131687526934778, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.3339787568372257, -0.4255010572823463, -0.3487779453829513, -0.1806223481889086, -0.1474826847594624, -0.5354516373428909, -0.036772356694307, -0.1224163589348786, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.2440563017214069, 0.278477698357045, 2.1729760248092718, -0.4251776020301452, 0.285341886203996, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.6439121681311092, 0.0338722762278857, -0.174249044437414, -1.3706985810941017, -0.553629657129454, 0.4010206813434356, 1.2420196914581063, 0.4706326037029981, -0.6071674196180575, -0.8701974062953576, -0.4351356021028035, 0.021209914852902, -1.064388315405516, 0.6993474859923247, -0.6738408269117502, -0.9221119476695248, -0.7939678109160361, 0.3736347120249996, 0.6308857408036841, 0.0418502001162623, -0.4309446948506726, -0.565020689844132, -0.2031244129114749, -1.287525621697034, -0.5868915885967425, -0.6218024077192129, -0.0802984588359218, -0.3815866107489131, -0.4454382040900255, 0.424665895444844, -1.3314821107815475, 0.6186392022095215, -0.8622687408969322, 0.9108799898636633, 3.1314343281497536, 0.0776143028335215, -0.3487779453829513, 0.067761088336817, -0.1474826847594624, -0.3999358135056357, -0.0560864903921214, -0.131687526934778, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.3339787568372257, -0.4255010572823463, -0.3487779453829513, -0.1806223481889086, -0.1474826847594624, -0.5354516373428909, -0.036772356694307, -0.1224163589348786, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.2440563017214069, 0.278477698357045, 2.1729760248092718, -0.4251776020301452, 0.285341886203996, -0.7536814885080627, -0.7044462462363678, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.6439121681311092, 0.0338722762278857, -0.174249044437414, -1.3706985810941017, -0.553629657129454, 0.4010206813434356, 1.2420196914581063, 0.4706326037029981, -0.6071674196180575, -0.8701974062953576, -0.4351356021028035, 0.021209914852902, -1.064388315405516, 1.0542620417323658, -0.6738408269117502, -0.0796833960305785, -0.7939678109160361, 0.3736347120249996, 0.6308857408036841, 0.0418502001162623, -0.4309446948506726, -0.565020689844132, -0.2031244129114749, -1.287525621697034, -0.5868915885967425, -0.6218024077192129, -0.0802984588359218, -0.3815866107489131, -0.4454382040900255, 0.424665895444844, -1.3314821107815475, 0.6186392022095215, -0.8622687408969322, 0.9222160194167848, 3.1811691236042576, 0.0776143028335215, -0.3487779453829513, 0.067761088336817, -0.1474826847594624, -0.3999358135056357, -0.0560864903921214, -0.131687526934778, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.3339787568372257, -0.4255010572823463, -0.3487779453829513, -0.1806223481889086, -0.1474826847594624, -0.5354516373428909, -0.036772356694307, -0.1224163589348786, -0.1491049589303728, 0.034748685979544, -0.0493715789733202, -0.2440563017214069, 0.278477698357045, 2.1729760248092718, -0.5107528363891513, 1.4769583166408096, -0.7536814885080627, -0.5709283205126147, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-1.038066534429697, 0.260892106097527, 0.1645848503507034, -1.455529079732558, -1.6391408045371951, 0.196670426185453, 1.2420196914581063, 0.4706326037029981, -0.6616178283130005, -0.5004598044528213, -0.4609157221792596, 0.021209914852902, -1.1769476210921423, 0.0909225332951111, -1.348247483817418, -1.2590833683251033, -0.9252694826312332, 0.781386658108973, -0.0798138719333467, -0.2032969502372001, -0.5728175028694968, 0.103242147293012, -0.2031244129114749, -0.6504603131201653, -0.5868915885967425, -0.6218024077192129, -0.0284729839577739, -0.3925684926321655, -0.4454382040900255, -0.2791761177909213, -1.5149673075505703, 0.3413397023846657, -0.8352815289623093, 0.9329945393197532, 3.228457945511819, 0.0776143028335215, -0.4147760464289071, 0.0627050582403518, -0.1474826847594624, -0.3999358135056357, -0.050494972406442, -0.126269577827358, -0.1491049589303728, -0.3712584158476188, -0.318004544437855, -0.2624212575170594, -0.512973950246314, -0.4147760464289071, -0.2448301849643134, -0.1474826847594624, -0.5354516373428909, -0.0251798677021788, -0.1109322996093401, -0.1491049589303728, -0.3712584158476188, -0.318004544437855, -0.1500627926219946, 0.278477698357045, 2.1729760248092718, -0.4251776020301452, 1.4769583166408096, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.8995798651896526, 0.4879119359671683, 0.1510314945591795, -1.4131138304133295, -0.6523124887119757, 0.196670426185453, 0.148455167213642, 0.4706326037029981, -0.752368509471239, -0.9441449266638648, -0.9507380036319262, 0.1751012323498492, -1.0418764542681906, 0.5472412478180213, -0.6738408269117502, -1.0063548028334193, -1.3629417216818924, 0.1697587389830128, -0.364093717028159, -0.2645837378255657, -0.2890718868318484, 0.0364158635792983, -0.2031244129114749, -1.8246591171638051, -0.4061028043129334, -0.5350245509902118, 0.0492652283594477, 0.0357249008146661, -0.4929416415078188, -0.5851943844151671, -1.170932563608653, 0.051337096981241, -0.8763418268751098, 0.9447022419729768, 3.279823389997619, 0.0776143028335215, -0.4147760464289071, 0.0627050582403518, -0.1474826847594624, -0.3999358135056357, -0.050494972406442, -0.126269577827358, -0.1491049589303728, -0.3712584158476188, -0.318004544437855, -0.2624212575170594, -0.512973950246314, -0.4147760464289071, -0.2448301849643134, -0.1474826847594624, -0.5354516373428909, -0.0251798677021788, -0.1109322996093401, -0.1491049589303728, -0.3712584158476188, -0.318004544437855, -0.1500627926219946, 0.278477698357045, 1.2505677424119097, -0.5107528363891513, -0.9062745442328174, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.5764443036295489, 0.3176470635649374, -0.1200356212713144, -1.300006498895388, -0.6382149413430442, 0.196670426185453, 0.8686074148868256, 0.4706326037029981, -0.806818918166182, -0.2416434831630464, -1.0022982437848384, -4.71094809817822, 6.994857971756963, 0.5472412478180213, -0.6738408269117502, -1.0063548028334193, -0.8377350348211018, 0.1697587389830128, -0.364093717028159, -0.1420101626488345, -0.0053262707941999, 0.5487507053844415, -0.2031244129114749, -4.805500187471612, -0.0209440899691673, -0.6001079435369626, 0.5156945022627775, 0.2883081841294641, -0.4929416415078188, -0.9218144777018374, -1.2626751619931649, -0.1547010788662775, -0.8374007701449055, 0.962914223877992, 3.359725192531085, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.5107528363891513, -0.9062745442328174, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.5764443036295489, 0.3176470635649374, -0.1200356212713144, -1.300006498895388, -0.6382149413430442, 0.196670426185453, 0.8686074148868256, 0.4706326037029981, -0.806818918166182, -0.2416434831630464, -1.0022982437848384, -4.71094809817822, 6.994857971756963, 0.2430287714694145, 0.8248406328786231, -1.4275690786528925, -0.8377350348211018, 0.1697587389830128, -0.364093717028159, -0.1420101626488345, -0.0053262707941999, 0.5487507053844415, -0.2031244129114749, -4.805500187471612, -0.0209440899691673, -0.6001079435369626, 0.5156945022627775, 0.2883081841294641, -0.4929416415078188, -0.9218144777018374, -1.2626751619931649, -0.1547010788662775, -0.8374007701449055, 0.973321070680858, 3.405383365407351, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.6819033051071632, -0.9062745442328174, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2320031006479001, -0.647187213381038, -0.4182094486848582, -1.1586223344979605, -1.3289947624206973, -0.2120300841305121, 0.2551443890911503, 1.1995119025066026, -0.752368509471239, -0.3340778836236804, -0.93600650644538, -0.0942085732698075, -0.096378286500525, 0.2430287714694145, 0.8248406328786231, -1.4275690786528925, -1.0237457364176323, -0.0341172340589738, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -1.2375597151419853, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.8912126510394129, -1.182400388406717, 0.1117543064402878, -0.8615402517404147, 0.9735069072309092, 3.4061986899229986, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.6819033051071632, -0.9062745442328174, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2320031006479001, -0.647187213381038, -0.4182094486848582, -1.1586223344979605, -1.3289947624206973, -0.2120300841305121, 0.2551443890911503, 1.1995119025066026, -0.752368509471239, -0.3340778836236804, -0.93600650644538, -0.0942085732698075, -0.096378286500525, -1.0752252927078816, -1.0485111918593435, 2.279116548558471, -1.0237457364176323, -0.0341172340589738, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -1.2375597151419853, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.8912126510394129, -1.182400388406717, 0.1117543064402878, -0.8615402517404147, 0.9980373318376644, 3.5138215259884835, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.7674785394661693, -0.9062745442328174, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2142483994632791, -0.0228826812395245, 0.0154979366439325, -1.087930252299247, -0.920165888721678, 0.196670426185453, -1.0517985789083308, 1.1995119025066026, -0.752368509471239, 0.9600037228251952, -0.7039854257572746, -0.5174096963864115, 0.6240012698938863, -1.0752252927078816, -1.0485111918593435, 2.279116548558471, -0.1702848702688472, 0.781386658108973, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -0.825340986062835, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.6004952977463793, -1.6411133803292737, 0.9483002835655512, -0.8615402517404147, 1.0340896225475933, 3.671994482024121, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.7674785394661693, -0.9062745442328174, -0.7536814885080627, -0.971482097683874, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2142483994632791, -0.0228826812395245, 0.0154979366439325, -1.087930252299247, -0.920165888721678, 0.196670426185453, -1.0517985789083308, 1.1995119025066026, -0.752368509471239, 0.9600037228251952, -0.7039854257572746, -0.5174096963864115, 0.6240012698938863, -0.2639920224449301, -0.6738408269117502, 2.279116548558471, -0.1702848702688472, 0.781386658108973, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -0.825340986062835, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.6004952977463793, -1.6411133803292737, 0.9483002835655512, -0.8615402517404147, 1.0396647190491284, 3.696454217493548, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.7418059691584676, -0.9062745442328174, -0.7536814885080627, -0.8379641719601209, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2142483994632791, -0.0228826812395245, 0.0154979366439325, -1.087930252299247, -0.920165888721678, 0.196670426185453, -1.0517985789083308, 1.1995119025066026, -0.752368509471239, 0.9600037228251952, -0.7039854257572746, -0.5174096963864115, 0.6240012698938863, -0.7710128163592748, -0.6738408269117502, -0.6693833821778409, -0.1702848702688472, 0.781386658108973, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -0.825340986062835, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.6004952977463793, -1.6411133803292737, 0.9483002835655512, -0.8615402517404147, 1.057505027854041, 3.774725370995719, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.5792130238763558, -0.9062745442328174, -0.7536814885080627, -0.5709283205126147, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [-0.2142483994632791, -0.0228826812395245, 0.0154979366439325, -1.087930252299247, -0.920165888721678, 0.196670426185453, -1.0517985789083308, 1.1995119025066026, -0.752368509471239, 0.9600037228251952, -0.7039854257572746, -0.5174096963864115, 0.6240012698938863, -0.7710128163592748, -0.6738408269117502, 0.0888023142972107, -0.1702848702688472, 0.781386658108973, -0.553613613758034, -0.387157313002297, -0.4309446948506726, -0.074961275943559, -0.2031244129114749, -0.825340986062835, -0.0602459995960821, -0.6304801933921129, 0.0233524909203738, 0.3761632391954809, -0.3059344385086578, -0.6004952977463793, -1.6411133803292737, 0.9483002835655512, -0.8615402517404147, 1.0760886828591592, 3.856257822560481, 0.0776143028335215, -0.5487987206266679, 0.0559215511942626, -0.1474826847594624, -0.3999358135056357, -0.1124082987567718, -0.1862610241745375, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.2941301345546859, -0.6879197361742494, -0.5487987206266679, -0.3696472341575351, -0.1474826847594624, -0.5354516373428909, -0.0838340991700614, -0.1690379121597101, -0.1491049589303728, -0.0128621414043893, -0.0808730913626546, -0.1490558177303448, 0.278477698357045, 1.2505677424119097, -0.6819033051071632, -0.9062745442328174, -0.7536814885080627, -0.8379641719601209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "69\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Transfer Target Dataset & Model\")\n",
    "# if target_dataset == 'TJ':\n",
    "#     data_path = './data/Tongji/'\n",
    "#     all_x = pickle.load(open(data_path + 'x.dat', 'rb'))\n",
    "#     all_y = pickle.load(open(data_path + 'y.dat', 'rb'))\n",
    "#     all_time = pickle.load(open(data_path + 'time_all.dat', 'rb'))\n",
    "#     all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "#     tar_subset_idx = [0,1,2,7,11,12,24,25,28,30,32,36,37,39,50,51,65,73]\n",
    "#     tar_other_idx = list(range(74))\n",
    "#     for i in tar_subset_idx:\n",
    "#         tar_other_idx.remove(i)\n",
    "#     for i in range(len(all_x)):\n",
    "#         cur = np.array(all_x[i], dtype=float)\n",
    "#         cur_subset = cur[:, tar_subset_idx]\n",
    "#         cur_other = cur[:, tar_other_idx]\n",
    "#         all_x[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "#     print(all_x[0])\n",
    "#     print(len(all_x[0][0]))\n",
    "#     logger.info(all_x[0])\n",
    "#     logger.info(len(all_x[0][0]))\n",
    "    \n",
    "# elif target_dataset == 'HM':\n",
    "#     data_path = './data/Spain/'\n",
    "#     all_x = pickle.load(open(data_path + 'x.dat', 'rb'))\n",
    "#     all_y = pickle.load(open(data_path + 'y.dat', 'rb'))\n",
    "#     all_time = pickle.load(open(data_path + 'time_all.dat', 'rb'))\n",
    "#     all_x_len = [len(i) for i in all_x]\n",
    "    \n",
    "#     tar_subset_idx = [39, 35, 23, 47, 55, 51, 22, 53, 25, 15, 43, 65, 1, 2, 48, 12, 26, 44, 49]\n",
    "#     tar_other_idx = list(range(66))\n",
    "#     for i in tar_subset_idx:\n",
    "#         tar_other_idx.remove(i)\n",
    "#     for i in range(len(all_x)):\n",
    "#         cur = np.array(all_x[i], dtype=float)\n",
    "#         cur_subset = cur[:, tar_subset_idx]\n",
    "#         cur_other = cur[:, tar_other_idx]\n",
    "#         all_x[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "#     print(all_x[0])\n",
    "#     print(len(all_x[0][0]))\n",
    "#     print(all_y[0])\n",
    "#     logger.info(all_x[0])\n",
    "#     logger.info(len(all_x[0][0]))\n",
    "#     logger.info(all_y[0])\n",
    "if target_dataset == 'PD':\n",
    "    data_path = './data/PD/'\n",
    "    all_x = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    all_time = pickle.load(open(data_path + 'y_z.pkl', 'rb'))\n",
    "    all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "    tar_subset_idx = [0, 2, 3, 4, 5, 7, 8, 9, 12, 16, 17, 19, 20, 56, 57, 58]\n",
    "    tar_other_idx = list(range(69))\n",
    "    for i in tar_subset_idx:\n",
    "        tar_other_idx.remove(i)\n",
    "    for i in range(len(all_x)):\n",
    "        cur = np.array(all_x[i], dtype=float)\n",
    "        cur_subset = cur[:, tar_subset_idx]\n",
    "        cur_other = cur[:, tar_other_idx]\n",
    "        all_x[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "    \n",
    "print(all_x[0])\n",
    "print(len(all_x[0][0]))\n",
    "print(len(all_x))\n",
    "logger.info(all_x[0])\n",
    "logger.info(len(all_x[0][0]))\n",
    "logger.info(len(all_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:34.621807Z",
     "start_time": "2021-02-10T15:06:34.616350Z"
    }
   },
   "outputs": [],
   "source": [
    "long_x = all_x\n",
    "long_time = all_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:34.845288Z",
     "start_time": "2021-02-10T15:06:34.837259Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_n2n_data(x, y, x_len):\n",
    "#     length = len(x)\n",
    "#     assert length == len(y)\n",
    "#     assert length == len(x_len)\n",
    "#     new_x = []\n",
    "#     new_y = []\n",
    "#     new_x_len = []\n",
    "#     for i in range(length):\n",
    "#         for j in range(len(x[i])):\n",
    "#             new_x.append(x[i][:j+1])\n",
    "#             new_y.append(y[i][j])\n",
    "#             new_x_len.append(j+1)\n",
    "#     return new_x, new_y, new_x_len\n",
    "def get_n2n_data(x, y, x_len):\n",
    "    length = len(x)\n",
    "    assert length == len(y)\n",
    "    assert length == len(x_len)\n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    new_x_len = []\n",
    "    for i in range(length):\n",
    "        for j in range(len(x[i])):\n",
    "            new_x.append(x[i][:j+1])\n",
    "            new_y.append(y[i][j])\n",
    "            new_x_len.append(j+1)\n",
    "    return new_x, new_y, new_x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:35.791565Z",
     "start_time": "2021-02-10T15:06:35.745700Z"
    }
   },
   "outputs": [],
   "source": [
    "class distcare_target(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(distcare_target, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
    "\n",
    "        self.LSTMs = clones(nn.LSTM(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 16, attention_type='concat', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
    "        \n",
    "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
    "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.FC_embed = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.Linear = nn.Linear(self.hidden_dim, 1)\n",
    "        self.Linear_los = nn.Linear(self.input_dim, self.output_dim)\n",
    "        self.Linear_outcome = nn.Linear(self.input_dim, self.output_dim)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, lens):\n",
    "        lens = lens.to('cpu')\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "#         demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "        # Initialization\n",
    "        #cur_hs = Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0))\n",
    "\n",
    "        # forward\n",
    "        # LSTM_embeded_input = self.LSTMs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b t h\n",
    "        # Attention_embeded_input = self.LastStepAttentions[0](LSTM_embeded_input)[0].unsqueeze(1)# b 1 h\n",
    "        # for i in range(feature_dim-1):\n",
    "        #     embeded_input = self.LSTMs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0] # b 1 h\n",
    "        #     embeded_input = self.LastStepAttentions[i+1](embeded_input)[0].unsqueeze(1)# b 1 h\n",
    "        #     Attention_embeded_input = torch.cat((Attention_embeded_input, embeded_input), 1)# b i h\n",
    "\n",
    "        # Attention_embeded_input = torch.cat((Attention_embeded_input, demo_main), 1)# b i+1 h\n",
    "        # posi_input = self.dropout(Attention_embeded_input) # batch_size * d_input+1 * hidden_dim\n",
    "\n",
    "#         input = pack_padded_sequence(input, lens, batch_first=True)\n",
    "        \n",
    "        LSTM_embeded_input = self.LSTMs[0](pack_padded_sequence(input[:,:,0].unsqueeze(-1), lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "#         print(LSTM_embeded_input.shape)\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.LSTMs[i+1](pack_padded_sequence(input[:,:,i+1].unsqueeze(-1), lens, batch_first=True))[1][0].squeeze().unsqueeze(1) # b 1 h\n",
    "            LSTM_embeded_input = torch.cat((LSTM_embeded_input, embeded_input), 1)\n",
    "        \n",
    "\n",
    "#         LSTM_embeded_input = torch.cat((LSTM_embeded_input, demo_main), 1)# b i+1 h\n",
    "        posi_input = self.dropout(LSTM_embeded_input) # batch_size * d_input * hidden_dim\n",
    "\n",
    "\n",
    "#         #mask = subsequent_mask(time_step).to(device) # 1 t t 下三角 N to 1任务不用mask\n",
    "#         contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
    "    \n",
    "#         DeCov_loss = contexts[1]\n",
    "#         contexts = contexts[0]\n",
    "\n",
    "#         contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
    "#         #contexts = contexts.view(batch_size, feature_dim * self.hidden_dim)#\n",
    "#         # contexts = torch.matmul(self.Wproj, contexts) + self.bproj\n",
    "#         # contexts = contexts.squeeze()\n",
    "#         # demo_key = self.demo_proj(demo_input)# b hidden_dim\n",
    "#         # demo_key = self.relu(demo_key)\n",
    "#         # input_dim_scores = torch.matmul(contexts, demo_key.unsqueeze(-1)).squeeze() # b i\n",
    "#         # input_dim_scores = self.dropout(self.sigmoid(input_dim_scores)).unsqueeze(1)# b i\n",
    "        \n",
    "#         # weighted_contexts = torch.matmul(input_dim_scores, contexts).squeeze()\n",
    "# #         print(contexts.shape)\n",
    "\n",
    "#         weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
    "#         #output_embed = self.FC_embed(weighted_contexts)\n",
    "        contexts = self.Linear(posi_input).squeeze()# b i\n",
    "        output = self.Linear_los(self.dropout(contexts))# b 1\n",
    "#         if self.output_dim != 1:\n",
    "#             output = F.softmax(output, dim=1)\n",
    "#         print(weighted_contexts.shape)\n",
    "          \n",
    "        return output, None, None\n",
    "    #, self.MultiHeadedAttention.attn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:37.622869Z",
     "start_time": "2021-02-10T15:06:37.615260Z"
    }
   },
   "outputs": [],
   "source": [
    "# def transfer_lstm_dict(pretrain_dict, model_dict):\n",
    "#     state_dict = {}\n",
    "#     for k, v in pretrain_dict.items():\n",
    "#         if 'LSTMs' in k:\n",
    "#             state_dict[k] = v\n",
    "#             print(\"transfered weight: {}\".format(k))\n",
    "#             logger.info(\"transfered weight: {}\".format(k))\n",
    "#         else:\n",
    "#             print(\"Other weight in model_dict: {}\".format(k))\n",
    "#             logger.info(\"Other weight in model_dict: {}\".format(k))\n",
    "#     return state_dict\n",
    "def transfer_lstm_dict(pretrain_dict, model_dict):\n",
    "    state_dict = {}\n",
    "    for k, v in model_dict.items():\n",
    "        if \"LSTMs\" in k:\n",
    "            if k in pretrain_dict:\n",
    "                state_dict[k] = pretrain_dict[k]\n",
    "            else:\n",
    "                target_k = \"generalLSTM.\"\n",
    "                point_position1 = k.find('.')\n",
    "                point_position2 = k.find('.', point_position1+1)\n",
    "                target_k += k[point_position2+1:]\n",
    "                state_dict[k] = pretrain_dict[target_k]\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:37.864449Z",
     "start_time": "2021-02-10T15:06:37.857471Z"
    }
   },
   "outputs": [],
   "source": [
    "if target_dataset == 'PD':\n",
    "    input_dim = 69\n",
    "    \n",
    "cell = 'LSTM'\n",
    "hidden_dim = 32\n",
    "d_model = 32\n",
    "MHD_num_head = 4\n",
    "d_ff = 64\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-10T15:06:39.629505Z",
     "start_time": "2021-02-10T15:06:39.615897Z"
    }
   },
   "outputs": [],
   "source": [
    "def ckd_batch_iter(x, y, lens, batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        \n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx],  lens[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "#         batch_name = [e[2] for e in examples]\n",
    "        batch_lens = [e[2] for e in examples]\n",
    "       \n",
    "\n",
    "        yield batch_x, batch_y, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_los(y, los_info):\n",
    "    return y * los_info[\"los_std\"] + los_info[\"los_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:03,257 - INFO - {'los_mean': 1055.0307777880782, 'los_std': 799.0879849276147}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'los_mean': 1055.0307777880782, 'los_std': 799.0879849276147}\n"
     ]
    }
   ],
   "source": [
    "los_info = pickle.load(open(data_path + 'los_info.pkl', 'rb'))\n",
    "print(los_info)\n",
    "logger.info(los_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-10T15:08:58.832Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:05,632 - INFO - Fold 1 Epoch 0 Batch 0: Train Loss = 1.0946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 0 Batch 0: Train Loss = 1.0946\n",
      "Fold 1, epoch 0: Loss = 0.9812 Valid loss = 1.0060 MSE = 704.8107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:23,577 - INFO - Fold 1, epoch 0: Loss = 0.9812 Valid loss = 1.0060 MSE = 704.8107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 704.8107 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:23,579 - INFO - ------------ Save FOLD-BEST model - MSE: 704.8107 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  642  453    0]\n",
      " [   0 2324 1555    0]\n",
      " [   0 1457  883    0]\n",
      " [   0  699  699    0]]\n",
      "Mean absolute deviation (MAD) = 21.53312443668867\n",
      "Mean squared error (MSE) = 704.8106527565601\n",
      "Mean absolute percentage error (MAPE) = 240.37723711131912\n",
      "Cohen kappa score = 0.012362173636899398\n",
      "------------ Save best model - MSE: 704.8107 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:23,843 - INFO - ------------ Save best model - MSE: 704.8107 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 704.8107, mad = 21.5331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:23,845 - INFO - Fold 1, mse = 704.8107, mad = 21.5331\n",
      "2023-11-08 16:54:24,503 - INFO - Fold 1 Epoch 1 Batch 0: Train Loss = 0.9723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 1 Batch 0: Train Loss = 0.9723\n",
      "------------ Save FOLD-BEST model - MSE: 698.8112 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:38,817 - INFO - ------------ Save FOLD-BEST model - MSE: 698.8112 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  594  501    0]\n",
      " [   0 2147 1732    0]\n",
      " [   0 1312 1028    0]\n",
      " [   0  588  810    0]]\n",
      "Mean absolute deviation (MAD) = 21.408309732176594\n",
      "Mean squared error (MSE) = 698.811211414537\n",
      "Mean absolute percentage error (MAPE) = 237.68921229718055\n",
      "Cohen kappa score = 0.02681417975532774\n",
      "------------ Save best model - MSE: 698.8112 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:39,059 - INFO - ------------ Save best model - MSE: 698.8112 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 698.8112, mad = 21.4083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:39,061 - INFO - Fold 1, mse = 698.8112, mad = 21.4083\n",
      "2023-11-08 16:54:39,679 - INFO - Fold 1 Epoch 2 Batch 0: Train Loss = 0.8150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 2 Batch 0: Train Loss = 0.8150\n",
      "------------ Save FOLD-BEST model - MSE: 694.4694 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:54,264 - INFO - ------------ Save FOLD-BEST model - MSE: 694.4694 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  441  654    0]\n",
      " [   0 1625 2254    0]\n",
      " [   0  925 1415    0]\n",
      " [   0  374 1024    0]]\n",
      "Mean absolute deviation (MAD) = 21.421884053139614\n",
      "Mean squared error (MSE) = 694.4693788902034\n",
      "Mean absolute percentage error (MAPE) = 241.48025976514697\n",
      "Cohen kappa score = 0.04143249500881563\n",
      "------------ Save best model - MSE: 694.4694 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:54,637 - INFO - ------------ Save best model - MSE: 694.4694 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 694.4694, mad = 21.4219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:54:54,639 - INFO - Fold 1, mse = 694.4694, mad = 21.4219\n",
      "2023-11-08 16:54:55,293 - INFO - Fold 1 Epoch 3 Batch 0: Train Loss = 0.7394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 3 Batch 0: Train Loss = 0.7394\n",
      "------------ Save FOLD-BEST model - MSE: 693.8707 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:09,697 - INFO - ------------ Save FOLD-BEST model - MSE: 693.8707 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  573  522    0]\n",
      " [   0 1973 1906    0]\n",
      " [   0 1239 1101    0]\n",
      " [   0  512  886    0]]\n",
      "Mean absolute deviation (MAD) = 21.369140228861635\n",
      "Mean squared error (MSE) = 693.8706583459912\n",
      "Mean absolute percentage error (MAPE) = 235.3942382515045\n",
      "Cohen kappa score = 0.02703230382301658\n",
      "------------ Save best model - MSE: 693.8707 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:09,945 - INFO - ------------ Save best model - MSE: 693.8707 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 693.8707, mad = 21.3691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:09,947 - INFO - Fold 1, mse = 693.8707, mad = 21.3691\n",
      "2023-11-08 16:55:10,538 - INFO - Fold 1 Epoch 4 Batch 0: Train Loss = 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 4 Batch 0: Train Loss = 0.9821\n",
      "------------ Save FOLD-BEST model - MSE: 688.9120 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:25,633 - INFO - ------------ Save FOLD-BEST model - MSE: 688.9120 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  469  626    0]\n",
      " [   0 1683 2196    0]\n",
      " [   0 1034 1306    0]\n",
      " [   0  340 1058    0]]\n",
      "Mean absolute deviation (MAD) = 21.40420416632993\n",
      "Mean squared error (MSE) = 688.9120434068662\n",
      "Mean absolute percentage error (MAPE) = 240.22485430092271\n",
      "Cohen kappa score = 0.03986860856677843\n",
      "------------ Save best model - MSE: 688.9120 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:25,907 - INFO - ------------ Save best model - MSE: 688.9120 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 688.9120, mad = 21.4042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:25,909 - INFO - Fold 1, mse = 688.9120, mad = 21.4042\n",
      "2023-11-08 16:55:26,489 - INFO - Fold 1 Epoch 5 Batch 0: Train Loss = 0.7501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 5 Batch 0: Train Loss = 0.7501\n",
      "------------ Save FOLD-BEST model - MSE: 686.7549 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:41,474 - INFO - ------------ Save FOLD-BEST model - MSE: 686.7549 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  647  448    0]\n",
      " [   0 2219 1660    0]\n",
      " [   0 1356  984    0]\n",
      " [   0  523  875    0]]\n",
      "Mean absolute deviation (MAD) = 21.241486315450373\n",
      "Mean squared error (MSE) = 686.7548507479394\n",
      "Mean absolute percentage error (MAPE) = 229.42787709573605\n",
      "Cohen kappa score = 0.04619075819895235\n",
      "------------ Save best model - MSE: 686.7549 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:41,836 - INFO - ------------ Save best model - MSE: 686.7549 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 686.7549, mad = 21.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:41,837 - INFO - Fold 1, mse = 686.7549, mad = 21.2415\n",
      "2023-11-08 16:55:42,437 - INFO - Fold 1 Epoch 6 Batch 0: Train Loss = 0.9014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 6 Batch 0: Train Loss = 0.9014\n",
      "------------ Save FOLD-BEST model - MSE: 681.2491 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:58,360 - INFO - ------------ Save FOLD-BEST model - MSE: 681.2491 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  628  467    0]\n",
      " [   0 2133 1746    0]\n",
      " [   0 1283 1057    0]\n",
      " [   0  462  936    0]]\n",
      "Mean absolute deviation (MAD) = 21.218320217777755\n",
      "Mean squared error (MSE) = 681.249117387841\n",
      "Mean absolute percentage error (MAPE) = 230.18702424294224\n",
      "Cohen kappa score = 0.055174943170401614\n",
      "------------ Save best model - MSE: 681.2491 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:58,695 - INFO - ------------ Save best model - MSE: 681.2491 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 681.2491, mad = 21.2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:55:58,696 - INFO - Fold 1, mse = 681.2491, mad = 21.2183\n",
      "2023-11-08 16:55:59,330 - INFO - Fold 1 Epoch 7 Batch 0: Train Loss = 0.8142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 7 Batch 0: Train Loss = 0.8142\n",
      "------------ Save FOLD-BEST model - MSE: 680.4464 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:56:13,854 - INFO - ------------ Save FOLD-BEST model - MSE: 680.4464 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  697  398    0]\n",
      " [   0 2393 1486    0]\n",
      " [   0 1398  942    0]\n",
      " [   0  519  879    0]]\n",
      "Mean absolute deviation (MAD) = 21.103495916148415\n",
      "Mean squared error (MSE) = 680.4463807187731\n",
      "Mean absolute percentage error (MAPE) = 223.3663195391344\n",
      "Cohen kappa score = 0.06847197155904783\n",
      "------------ Save best model - MSE: 680.4464 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:56:14,210 - INFO - ------------ Save best model - MSE: 680.4464 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 680.4464, mad = 21.1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:56:14,212 - INFO - Fold 1, mse = 680.4464, mad = 21.1035\n",
      "2023-11-08 16:56:14,841 - INFO - Fold 1 Epoch 8 Batch 0: Train Loss = 0.8044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 8 Batch 0: Train Loss = 0.8044\n",
      "Fold 1, mse = 692.2064, mad = 21.1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:56:29,611 - INFO - Fold 1, mse = 692.2064, mad = 21.1819\n",
      "2023-11-08 16:56:30,184 - INFO - Fold 1 Epoch 9 Batch 0: Train Loss = 0.7455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 9 Batch 0: Train Loss = 0.7455\n",
      "Fold 1, mse = 696.7222, mad = 21.2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:56:44,360 - INFO - Fold 1, mse = 696.7222, mad = 21.2337\n",
      "2023-11-08 16:56:44,929 - INFO - Fold 1 Epoch 10 Batch 0: Train Loss = 0.6610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 10 Batch 0: Train Loss = 0.6610\n",
      "Fold 1, epoch 10: Loss = 0.6212 Valid loss = 1.0296 MSE = 722.3647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:57:00,065 - INFO - Fold 1, epoch 10: Loss = 0.6212 Valid loss = 1.0296 MSE = 722.3647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 722.3647, mad = 21.5854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:57:00,066 - INFO - Fold 1, mse = 722.3647, mad = 21.5854\n",
      "2023-11-08 16:57:00,671 - INFO - Fold 1 Epoch 11 Batch 0: Train Loss = 0.6417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 11 Batch 0: Train Loss = 0.6417\n",
      "Fold 1, mse = 726.6819, mad = 21.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:57:15,475 - INFO - Fold 1, mse = 726.6819, mad = 21.6186\n",
      "2023-11-08 16:57:16,052 - INFO - Fold 1 Epoch 12 Batch 0: Train Loss = 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 12 Batch 0: Train Loss = 0.5312\n",
      "Fold 1, mse = 729.1454, mad = 21.7776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:57:30,491 - INFO - Fold 1, mse = 729.1454, mad = 21.7776\n",
      "2023-11-08 16:57:31,146 - INFO - Fold 1 Epoch 13 Batch 0: Train Loss = 0.5780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 13 Batch 0: Train Loss = 0.5780\n",
      "Fold 1, mse = 752.5556, mad = 21.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:57:46,784 - INFO - Fold 1, mse = 752.5556, mad = 21.9898\n",
      "2023-11-08 16:57:47,425 - INFO - Fold 1 Epoch 14 Batch 0: Train Loss = 0.6196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 14 Batch 0: Train Loss = 0.6196\n",
      "Fold 1, mse = 725.4078, mad = 21.7946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:58:03,176 - INFO - Fold 1, mse = 725.4078, mad = 21.7946\n",
      "2023-11-08 16:58:03,892 - INFO - Fold 1 Epoch 15 Batch 0: Train Loss = 0.5492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 15 Batch 0: Train Loss = 0.5492\n",
      "Fold 1, mse = 734.2600, mad = 21.8165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:58:19,728 - INFO - Fold 1, mse = 734.2600, mad = 21.8165\n",
      "2023-11-08 16:58:20,269 - INFO - Fold 1 Epoch 16 Batch 0: Train Loss = 0.5306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 16 Batch 0: Train Loss = 0.5306\n",
      "Fold 1, mse = 735.8933, mad = 22.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:58:34,832 - INFO - Fold 1, mse = 735.8933, mad = 22.0685\n",
      "2023-11-08 16:58:35,446 - INFO - Fold 1 Epoch 17 Batch 0: Train Loss = 0.5306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 17 Batch 0: Train Loss = 0.5306\n",
      "Fold 1, mse = 770.6000, mad = 22.4466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:58:50,686 - INFO - Fold 1, mse = 770.6000, mad = 22.4466\n",
      "2023-11-08 16:58:51,300 - INFO - Fold 1 Epoch 18 Batch 0: Train Loss = 0.4197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 18 Batch 0: Train Loss = 0.4197\n",
      "Fold 1, mse = 759.4420, mad = 22.3067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:59:06,108 - INFO - Fold 1, mse = 759.4420, mad = 22.3067\n",
      "2023-11-08 16:59:06,729 - INFO - Fold 1 Epoch 19 Batch 0: Train Loss = 0.4472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 19 Batch 0: Train Loss = 0.4472\n",
      "Fold 1, mse = 772.7237, mad = 22.3257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:59:21,602 - INFO - Fold 1, mse = 772.7237, mad = 22.3257\n",
      "2023-11-08 16:59:22,178 - INFO - Fold 1 Epoch 20 Batch 0: Train Loss = 0.5161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 20 Batch 0: Train Loss = 0.5161\n",
      "Fold 1, epoch 20: Loss = 0.4676 Valid loss = 1.0604 MSE = 745.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:59:38,004 - INFO - Fold 1, epoch 20: Loss = 0.4676 Valid loss = 1.0604 MSE = 745.2377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, mse = 745.2377, mad = 22.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:59:38,006 - INFO - Fold 1, mse = 745.2377, mad = 22.0778\n",
      "2023-11-08 16:59:38,665 - INFO - Fold 1 Epoch 21 Batch 0: Train Loss = 0.5074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 21 Batch 0: Train Loss = 0.5074\n",
      "Fold 1, mse = 759.2287, mad = 22.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 16:59:54,169 - INFO - Fold 1, mse = 759.2287, mad = 22.1093\n",
      "2023-11-08 16:59:54,735 - INFO - Fold 1 Epoch 22 Batch 0: Train Loss = 0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 22 Batch 0: Train Loss = 0.4769\n",
      "Fold 1, mse = 741.7155, mad = 21.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:00:09,564 - INFO - Fold 1, mse = 741.7155, mad = 21.9817\n",
      "2023-11-08 17:00:10,086 - INFO - Fold 1 Epoch 23 Batch 0: Train Loss = 0.4611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 23 Batch 0: Train Loss = 0.4611\n",
      "Fold 1, mse = 743.1299, mad = 22.0320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:00:24,651 - INFO - Fold 1, mse = 743.1299, mad = 22.0320\n",
      "2023-11-08 17:00:25,216 - INFO - Fold 1 Epoch 24 Batch 0: Train Loss = 0.5287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 24 Batch 0: Train Loss = 0.5287\n",
      "Fold 1, mse = 710.7774, mad = 21.6455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:00:39,880 - INFO - Fold 1, mse = 710.7774, mad = 21.6455\n",
      "2023-11-08 17:00:40,532 - INFO - Fold 1 Epoch 25 Batch 0: Train Loss = 0.5268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 25 Batch 0: Train Loss = 0.5268\n",
      "Fold 1, mse = 744.9190, mad = 21.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:00:55,976 - INFO - Fold 1, mse = 744.9190, mad = 21.9749\n",
      "2023-11-08 17:00:56,615 - INFO - Fold 1 Epoch 26 Batch 0: Train Loss = 0.4234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 26 Batch 0: Train Loss = 0.4234\n",
      "Fold 1, mse = 738.8849, mad = 21.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:01:11,371 - INFO - Fold 1, mse = 738.8849, mad = 21.9806\n",
      "2023-11-08 17:01:11,935 - INFO - Fold 1 Epoch 27 Batch 0: Train Loss = 0.3917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 27 Batch 0: Train Loss = 0.3917\n",
      "Fold 1, mse = 733.8549, mad = 21.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:01:26,842 - INFO - Fold 1, mse = 733.8549, mad = 21.7451\n",
      "2023-11-08 17:01:27,491 - INFO - Fold 1 Epoch 28 Batch 0: Train Loss = 0.4197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 28 Batch 0: Train Loss = 0.4197\n",
      "Fold 1, mse = 717.7623, mad = 21.5185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:01:42,002 - INFO - Fold 1, mse = 717.7623, mad = 21.5185\n",
      "2023-11-08 17:01:42,687 - INFO - Fold 1 Epoch 29 Batch 0: Train Loss = 0.3863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Epoch 29 Batch 0: Train Loss = 0.3863\n",
      "Fold 1, mse = 730.1588, mad = 21.6445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:01:57,380 - INFO - Fold 1, mse = 730.1588, mad = 21.6445\n",
      "2023-11-08 17:01:58,296 - INFO - Fold 2 Epoch 0 Batch 0: Train Loss = 0.9304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 0 Batch 0: Train Loss = 0.9304\n",
      "Fold 2, epoch 0: Loss = 0.8577 Valid loss = 1.0300 MSE = 730.8051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:02:12,984 - INFO - Fold 2, epoch 0: Loss = 0.8577 Valid loss = 1.0300 MSE = 730.8051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 730.8051 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:02:12,986 - INFO - ------------ Save FOLD-BEST model - MSE: 730.8051 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  868  222    0]\n",
      " [   0 3210  655    0]\n",
      " [   0 1827  450    0]\n",
      " [   0 1123  347    0]]\n",
      "Mean absolute deviation (MAD) = 21.660196439829136\n",
      "Mean squared error (MSE) = 730.8050938481975\n",
      "Mean absolute percentage error (MAPE) = 224.18530775175026\n",
      "Cohen kappa score = 0.023302267790157982\n",
      "Fold 2, mse = 730.8051, mad = 21.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:02:13,150 - INFO - Fold 2, mse = 730.8051, mad = 21.6602\n",
      "2023-11-08 17:02:13,800 - INFO - Fold 2 Epoch 1 Batch 0: Train Loss = 0.8428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 1 Batch 0: Train Loss = 0.8428\n",
      "------------ Save FOLD-BEST model - MSE: 726.0824 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:02:28,443 - INFO - ------------ Save FOLD-BEST model - MSE: 726.0824 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  791  299    0]\n",
      " [   0 2863 1002    0]\n",
      " [   0 1572  705    0]\n",
      " [   0  937  533    0]]\n",
      "Mean absolute deviation (MAD) = 21.635295964385417\n",
      "Mean squared error (MSE) = 726.0823837495493\n",
      "Mean absolute percentage error (MAPE) = 222.20393268633765\n",
      "Cohen kappa score = 0.04346607058222296\n",
      "Fold 2, mse = 726.0824, mad = 21.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:02:28,706 - INFO - Fold 2, mse = 726.0824, mad = 21.6353\n",
      "2023-11-08 17:02:29,455 - INFO - Fold 2 Epoch 2 Batch 0: Train Loss = 0.8018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 2 Batch 0: Train Loss = 0.8018\n",
      "------------ Save FOLD-BEST model - MSE: 719.9605 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:02:44,538 - INFO - ------------ Save FOLD-BEST model - MSE: 719.9605 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  694  396    0]\n",
      " [   0 2502 1363    0]\n",
      " [   0 1323  954    0]\n",
      " [   0  737  733    0]]\n",
      "Mean absolute deviation (MAD) = 21.658135570125957\n",
      "Mean squared error (MSE) = 719.9605426485059\n",
      "Mean absolute percentage error (MAPE) = 225.44905257432882\n",
      "Cohen kappa score = 0.05988902061606516\n",
      "Fold 2, mse = 719.9605, mad = 21.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:02:44,689 - INFO - Fold 2, mse = 719.9605, mad = 21.6581\n",
      "2023-11-08 17:02:45,191 - INFO - Fold 2 Epoch 3 Batch 0: Train Loss = 0.8697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 3 Batch 0: Train Loss = 0.8697\n",
      "------------ Save FOLD-BEST model - MSE: 716.9758 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:03:00,774 - INFO - ------------ Save FOLD-BEST model - MSE: 716.9758 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  729  361    0]\n",
      " [   0 2521 1344    0]\n",
      " [   0 1310  967    0]\n",
      " [   0  723  747    0]]\n",
      "Mean absolute deviation (MAD) = 21.592702916458173\n",
      "Mean squared error (MSE) = 716.9757638935411\n",
      "Mean absolute percentage error (MAPE) = 224.2077754341131\n",
      "Cohen kappa score = 0.07131348186367548\n",
      "Fold 2, mse = 716.9758, mad = 21.5927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:03:00,922 - INFO - Fold 2, mse = 716.9758, mad = 21.5927\n",
      "2023-11-08 17:03:01,575 - INFO - Fold 2 Epoch 4 Batch 0: Train Loss = 0.6721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 4 Batch 0: Train Loss = 0.6721\n",
      "------------ Save FOLD-BEST model - MSE: 715.0046 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:03:16,219 - INFO - ------------ Save FOLD-BEST model - MSE: 715.0046 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  809  281    0]\n",
      " [   0 2686 1179    0]\n",
      " [   0 1402  875    0]\n",
      " [   0  760  710    0]]\n",
      "Mean absolute deviation (MAD) = 21.4987681104408\n",
      "Mean squared error (MSE) = 715.0046391246439\n",
      "Mean absolute percentage error (MAPE) = 218.86578016321198\n",
      "Cohen kappa score = 0.0813858859776243\n",
      "Fold 2, mse = 715.0046, mad = 21.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:03:16,440 - INFO - Fold 2, mse = 715.0046, mad = 21.4988\n",
      "2023-11-08 17:03:17,080 - INFO - Fold 2 Epoch 5 Batch 0: Train Loss = 0.6629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 5 Batch 0: Train Loss = 0.6629\n",
      "Fold 2, mse = 718.3357, mad = 21.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:03:32,927 - INFO - Fold 2, mse = 718.3357, mad = 21.5022\n",
      "2023-11-08 17:03:33,673 - INFO - Fold 2 Epoch 6 Batch 0: Train Loss = 0.5917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 6 Batch 0: Train Loss = 0.5917\n",
      "Fold 2, mse = 719.8253, mad = 21.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:03:49,196 - INFO - Fold 2, mse = 719.8253, mad = 21.5522\n",
      "2023-11-08 17:03:49,928 - INFO - Fold 2 Epoch 7 Batch 0: Train Loss = 0.6032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 7 Batch 0: Train Loss = 0.6032\n",
      "Fold 2, mse = 731.0781, mad = 21.5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:04:06,065 - INFO - Fold 2, mse = 731.0781, mad = 21.5386\n",
      "2023-11-08 17:04:06,648 - INFO - Fold 2 Epoch 8 Batch 0: Train Loss = 0.6054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 8 Batch 0: Train Loss = 0.6054\n",
      "Fold 2, mse = 725.1255, mad = 21.4208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:04:22,778 - INFO - Fold 2, mse = 725.1255, mad = 21.4208\n",
      "2023-11-08 17:04:23,535 - INFO - Fold 2 Epoch 9 Batch 0: Train Loss = 0.5558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 9 Batch 0: Train Loss = 0.5558\n",
      "Fold 2, mse = 726.9028, mad = 21.5060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:04:38,314 - INFO - Fold 2, mse = 726.9028, mad = 21.5060\n",
      "2023-11-08 17:04:38,826 - INFO - Fold 2 Epoch 10 Batch 0: Train Loss = 0.6412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 10 Batch 0: Train Loss = 0.6412\n",
      "Fold 2, epoch 10: Loss = 0.5135 Valid loss = 1.0159 MSE = 720.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:04:53,505 - INFO - Fold 2, epoch 10: Loss = 0.5135 Valid loss = 1.0159 MSE = 720.5514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, mse = 720.5514, mad = 21.4116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:04:53,508 - INFO - Fold 2, mse = 720.5514, mad = 21.4116\n",
      "2023-11-08 17:04:54,002 - INFO - Fold 2 Epoch 11 Batch 0: Train Loss = 0.4961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 11 Batch 0: Train Loss = 0.4961\n",
      "Fold 2, mse = 723.5347, mad = 21.4795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:05:07,564 - INFO - Fold 2, mse = 723.5347, mad = 21.4795\n",
      "2023-11-08 17:05:08,113 - INFO - Fold 2 Epoch 12 Batch 0: Train Loss = 0.4897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 12 Batch 0: Train Loss = 0.4897\n",
      "Fold 2, mse = 750.6783, mad = 21.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:05:22,788 - INFO - Fold 2, mse = 750.6783, mad = 21.5419\n",
      "2023-11-08 17:05:23,301 - INFO - Fold 2 Epoch 13 Batch 0: Train Loss = 0.5196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 13 Batch 0: Train Loss = 0.5196\n",
      "Fold 2, mse = 738.2691, mad = 21.4313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:05:37,996 - INFO - Fold 2, mse = 738.2691, mad = 21.4313\n",
      "2023-11-08 17:05:38,612 - INFO - Fold 2 Epoch 14 Batch 0: Train Loss = 0.5567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 14 Batch 0: Train Loss = 0.5567\n",
      "Fold 2, mse = 728.5671, mad = 21.3846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:05:53,459 - INFO - Fold 2, mse = 728.5671, mad = 21.3846\n",
      "2023-11-08 17:05:54,044 - INFO - Fold 2 Epoch 15 Batch 0: Train Loss = 0.4836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 15 Batch 0: Train Loss = 0.4836\n",
      "Fold 2, mse = 726.2787, mad = 21.2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:06:08,970 - INFO - Fold 2, mse = 726.2787, mad = 21.2235\n",
      "2023-11-08 17:06:09,524 - INFO - Fold 2 Epoch 16 Batch 0: Train Loss = 0.5108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 16 Batch 0: Train Loss = 0.5108\n",
      "Fold 2, mse = 720.3223, mad = 21.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:06:24,720 - INFO - Fold 2, mse = 720.3223, mad = 21.1993\n",
      "2023-11-08 17:06:25,255 - INFO - Fold 2 Epoch 17 Batch 0: Train Loss = 0.3243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 17 Batch 0: Train Loss = 0.3243\n",
      "Fold 2, mse = 734.4516, mad = 21.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:06:40,416 - INFO - Fold 2, mse = 734.4516, mad = 21.4447\n",
      "2023-11-08 17:06:40,983 - INFO - Fold 2 Epoch 18 Batch 0: Train Loss = 0.3953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 18 Batch 0: Train Loss = 0.3953\n",
      "Fold 2, mse = 737.1839, mad = 21.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:06:55,952 - INFO - Fold 2, mse = 737.1839, mad = 21.5742\n",
      "2023-11-08 17:06:56,499 - INFO - Fold 2 Epoch 19 Batch 0: Train Loss = 0.4300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 19 Batch 0: Train Loss = 0.4300\n",
      "Fold 2, mse = 723.9039, mad = 21.2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:07:10,920 - INFO - Fold 2, mse = 723.9039, mad = 21.2055\n",
      "2023-11-08 17:07:11,506 - INFO - Fold 2 Epoch 20 Batch 0: Train Loss = 0.4478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 20 Batch 0: Train Loss = 0.4478\n",
      "Fold 2, epoch 20: Loss = 0.4278 Valid loss = 0.9953 MSE = 705.5965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:07:25,939 - INFO - Fold 2, epoch 20: Loss = 0.4278 Valid loss = 0.9953 MSE = 705.5965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 705.5965 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:07:25,942 - INFO - ------------ Save FOLD-BEST model - MSE: 705.5965 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[  85  757  248    0]\n",
      " [ 212 2518 1132    3]\n",
      " [  49 1236  992    0]\n",
      " [   0  593  859   18]]\n",
      "Mean absolute deviation (MAD) = 20.95915412184427\n",
      "Mean squared error (MSE) = 705.5964908873382\n",
      "Mean absolute percentage error (MAPE) = 186.10605841130425\n",
      "Cohen kappa score = 0.14927681108393287\n",
      "Fold 2, mse = 705.5965, mad = 20.9592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:07:26,192 - INFO - Fold 2, mse = 705.5965, mad = 20.9592\n",
      "2023-11-08 17:07:26,836 - INFO - Fold 2 Epoch 21 Batch 0: Train Loss = 0.4304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 21 Batch 0: Train Loss = 0.4304\n",
      "Fold 2, mse = 717.6937, mad = 21.1882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:07:41,055 - INFO - Fold 2, mse = 717.6937, mad = 21.1882\n",
      "2023-11-08 17:07:41,560 - INFO - Fold 2 Epoch 22 Batch 0: Train Loss = 0.4971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 22 Batch 0: Train Loss = 0.4971\n",
      "Fold 2, mse = 719.0783, mad = 21.3049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:07:56,158 - INFO - Fold 2, mse = 719.0783, mad = 21.3049\n",
      "2023-11-08 17:07:56,704 - INFO - Fold 2 Epoch 23 Batch 0: Train Loss = 0.3789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 23 Batch 0: Train Loss = 0.3789\n",
      "Fold 2, mse = 738.4520, mad = 21.5651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:08:11,851 - INFO - Fold 2, mse = 738.4520, mad = 21.5651\n",
      "2023-11-08 17:08:12,497 - INFO - Fold 2 Epoch 24 Batch 0: Train Loss = 0.3248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 24 Batch 0: Train Loss = 0.3248\n",
      "Fold 2, mse = 737.7259, mad = 21.4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:08:28,784 - INFO - Fold 2, mse = 737.7259, mad = 21.4065\n",
      "2023-11-08 17:08:29,436 - INFO - Fold 2 Epoch 25 Batch 0: Train Loss = 0.4086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 25 Batch 0: Train Loss = 0.4086\n",
      "Fold 2, mse = 751.2327, mad = 21.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:08:44,030 - INFO - Fold 2, mse = 751.2327, mad = 21.5173\n",
      "2023-11-08 17:08:44,623 - INFO - Fold 2 Epoch 26 Batch 0: Train Loss = 0.3854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 26 Batch 0: Train Loss = 0.3854\n",
      "Fold 2, mse = 742.0209, mad = 21.5399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:09:00,496 - INFO - Fold 2, mse = 742.0209, mad = 21.5399\n",
      "2023-11-08 17:09:01,150 - INFO - Fold 2 Epoch 27 Batch 0: Train Loss = 0.3767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 27 Batch 0: Train Loss = 0.3767\n",
      "Fold 2, mse = 737.5883, mad = 21.4365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:09:15,899 - INFO - Fold 2, mse = 737.5883, mad = 21.4365\n",
      "2023-11-08 17:09:16,513 - INFO - Fold 2 Epoch 28 Batch 0: Train Loss = 0.4467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 28 Batch 0: Train Loss = 0.4467\n",
      "Fold 2, mse = 732.4642, mad = 21.3917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:09:31,593 - INFO - Fold 2, mse = 732.4642, mad = 21.3917\n",
      "2023-11-08 17:09:32,151 - INFO - Fold 2 Epoch 29 Batch 0: Train Loss = 0.3926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 29 Batch 0: Train Loss = 0.3926\n",
      "Fold 2, mse = 740.0006, mad = 21.4781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:09:46,823 - INFO - Fold 2, mse = 740.0006, mad = 21.4781\n",
      "2023-11-08 17:09:47,556 - INFO - Fold 3 Epoch 0 Batch 0: Train Loss = 0.9962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 0 Batch 0: Train Loss = 0.9962\n",
      "Fold 3, epoch 0: Loss = 0.9679 Valid loss = 1.0142 MSE = 714.4655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:10:03,051 - INFO - Fold 3, epoch 0: Loss = 0.9679 Valid loss = 1.0142 MSE = 714.4655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 714.4655 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:10:03,054 - INFO - ------------ Save FOLD-BEST model - MSE: 714.4655 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  464  616    0]\n",
      " [   0 1617 2102    0]\n",
      " [   0  892 1263    0]\n",
      " [   0  345  998    0]]\n",
      "Mean absolute deviation (MAD) = 22.016131511346043\n",
      "Mean squared error (MSE) = 714.4654860056014\n",
      "Mean absolute percentage error (MAPE) = 269.63125785789794\n",
      "Cohen kappa score = 0.04830479041373403\n",
      "Fold 3, mse = 714.4655, mad = 22.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:10:03,254 - INFO - Fold 3, mse = 714.4655, mad = 22.0161\n",
      "2023-11-08 17:10:03,840 - INFO - Fold 3 Epoch 1 Batch 0: Train Loss = 1.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 1 Batch 0: Train Loss = 1.0149\n",
      "------------ Save FOLD-BEST model - MSE: 707.4648 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:10:19,544 - INFO - ------------ Save FOLD-BEST model - MSE: 707.4648 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  475  605    0]\n",
      " [   0 1623 2096    0]\n",
      " [   0  888 1267    0]\n",
      " [   0  355  988    0]]\n",
      "Mean absolute deviation (MAD) = 21.897144715955932\n",
      "Mean squared error (MSE) = 707.4647873318213\n",
      "Mean absolute percentage error (MAPE) = 268.1816413191592\n",
      "Cohen kappa score = 0.04943461898831536\n",
      "Fold 3, mse = 707.4648, mad = 21.8971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:10:19,704 - INFO - Fold 3, mse = 707.4648, mad = 21.8971\n",
      "2023-11-08 17:10:20,502 - INFO - Fold 3 Epoch 2 Batch 0: Train Loss = 0.8430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 2 Batch 0: Train Loss = 0.8430\n",
      "------------ Save FOLD-BEST model - MSE: 703.0256 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:10:36,598 - INFO - ------------ Save FOLD-BEST model - MSE: 703.0256 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  458  622    0]\n",
      " [   0 1580 2139    0]\n",
      " [   0  842 1313    0]\n",
      " [   0  327 1016    0]]\n",
      "Mean absolute deviation (MAD) = 21.79549715235338\n",
      "Mean squared error (MSE) = 703.0255806822416\n",
      "Mean absolute percentage error (MAPE) = 265.57214059204705\n",
      "Cohen kappa score = 0.054490776965682164\n",
      "Fold 3, mse = 703.0256, mad = 21.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:10:36,791 - INFO - Fold 3, mse = 703.0256, mad = 21.7955\n",
      "2023-11-08 17:10:37,387 - INFO - Fold 3 Epoch 3 Batch 0: Train Loss = 0.9823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 3 Batch 0: Train Loss = 0.9823\n",
      "Fold 3, mse = 704.6070, mad = 21.7428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:10:51,954 - INFO - Fold 3, mse = 704.6070, mad = 21.7428\n",
      "2023-11-08 17:10:52,533 - INFO - Fold 3 Epoch 4 Batch 0: Train Loss = 0.8317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 4 Batch 0: Train Loss = 0.8317\n",
      "Fold 3, mse = 712.5207, mad = 21.7307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:11:08,014 - INFO - Fold 3, mse = 712.5207, mad = 21.7307\n",
      "2023-11-08 17:11:08,601 - INFO - Fold 3 Epoch 5 Batch 0: Train Loss = 0.7380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 5 Batch 0: Train Loss = 0.7380\n",
      "Fold 3, mse = 728.8591, mad = 21.8598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:11:23,900 - INFO - Fold 3, mse = 728.8591, mad = 21.8598\n",
      "2023-11-08 17:11:24,489 - INFO - Fold 3 Epoch 6 Batch 0: Train Loss = 0.6986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 6 Batch 0: Train Loss = 0.6986\n",
      "Fold 3, mse = 753.6590, mad = 22.1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:11:39,216 - INFO - Fold 3, mse = 753.6590, mad = 22.1289\n",
      "2023-11-08 17:11:39,923 - INFO - Fold 3 Epoch 7 Batch 0: Train Loss = 0.6702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 7 Batch 0: Train Loss = 0.6702\n",
      "Fold 3, mse = 784.5359, mad = 22.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:11:54,849 - INFO - Fold 3, mse = 784.5359, mad = 22.4821\n",
      "2023-11-08 17:11:55,423 - INFO - Fold 3 Epoch 8 Batch 0: Train Loss = 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 8 Batch 0: Train Loss = 0.6100\n",
      "Fold 3, mse = 789.1584, mad = 22.4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:12:13,092 - INFO - Fold 3, mse = 789.1584, mad = 22.4501\n",
      "2023-11-08 17:12:13,754 - INFO - Fold 3 Epoch 9 Batch 0: Train Loss = 0.4976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 9 Batch 0: Train Loss = 0.4976\n",
      "Fold 3, mse = 792.9618, mad = 22.4377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:12:28,717 - INFO - Fold 3, mse = 792.9618, mad = 22.4377\n",
      "2023-11-08 17:12:29,364 - INFO - Fold 3 Epoch 10 Batch 0: Train Loss = 0.5445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 10 Batch 0: Train Loss = 0.5445\n",
      "Fold 3, epoch 10: Loss = 0.4918 Valid loss = 1.1875 MSE = 828.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:12:46,203 - INFO - Fold 3, epoch 10: Loss = 0.4918 Valid loss = 1.1875 MSE = 828.7936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, mse = 828.7936, mad = 22.9245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:12:46,205 - INFO - Fold 3, mse = 828.7936, mad = 22.9245\n",
      "2023-11-08 17:12:46,870 - INFO - Fold 3 Epoch 11 Batch 0: Train Loss = 0.3767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 11 Batch 0: Train Loss = 0.3767\n",
      "Fold 3, mse = 821.6332, mad = 22.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:13:02,206 - INFO - Fold 3, mse = 821.6332, mad = 22.8909\n",
      "2023-11-08 17:13:02,907 - INFO - Fold 3 Epoch 12 Batch 0: Train Loss = 0.4134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 12 Batch 0: Train Loss = 0.4134\n",
      "Fold 3, mse = 805.9200, mad = 22.7440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:13:18,403 - INFO - Fold 3, mse = 805.9200, mad = 22.7440\n",
      "2023-11-08 17:13:19,186 - INFO - Fold 3 Epoch 13 Batch 0: Train Loss = 0.4634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 13 Batch 0: Train Loss = 0.4634\n",
      "Fold 3, mse = 844.6015, mad = 23.0696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:13:34,567 - INFO - Fold 3, mse = 844.6015, mad = 23.0696\n",
      "2023-11-08 17:13:35,161 - INFO - Fold 3 Epoch 14 Batch 0: Train Loss = 0.4456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 14 Batch 0: Train Loss = 0.4456\n",
      "Fold 3, mse = 848.8634, mad = 23.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:13:50,960 - INFO - Fold 3, mse = 848.8634, mad = 23.1726\n",
      "2023-11-08 17:13:51,534 - INFO - Fold 3 Epoch 15 Batch 0: Train Loss = 0.4897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 15 Batch 0: Train Loss = 0.4897\n",
      "Fold 3, mse = 827.4917, mad = 22.8330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:14:06,631 - INFO - Fold 3, mse = 827.4917, mad = 22.8330\n",
      "2023-11-08 17:14:07,198 - INFO - Fold 3 Epoch 16 Batch 0: Train Loss = 0.4349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 16 Batch 0: Train Loss = 0.4349\n",
      "Fold 3, mse = 826.1342, mad = 22.8588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:14:22,784 - INFO - Fold 3, mse = 826.1342, mad = 22.8588\n",
      "2023-11-08 17:14:23,480 - INFO - Fold 3 Epoch 17 Batch 0: Train Loss = 0.4370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 17 Batch 0: Train Loss = 0.4370\n",
      "Fold 3, mse = 835.6353, mad = 23.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:14:39,089 - INFO - Fold 3, mse = 835.6353, mad = 23.0228\n",
      "2023-11-08 17:14:39,673 - INFO - Fold 3 Epoch 18 Batch 0: Train Loss = 0.4188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 18 Batch 0: Train Loss = 0.4188\n",
      "Fold 3, mse = 834.2996, mad = 22.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:14:55,094 - INFO - Fold 3, mse = 834.2996, mad = 22.9950\n",
      "2023-11-08 17:14:55,687 - INFO - Fold 3 Epoch 19 Batch 0: Train Loss = 0.4055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 19 Batch 0: Train Loss = 0.4055\n",
      "Fold 3, mse = 842.7365, mad = 23.0895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:15:11,138 - INFO - Fold 3, mse = 842.7365, mad = 23.0895\n",
      "2023-11-08 17:15:11,759 - INFO - Fold 3 Epoch 20 Batch 0: Train Loss = 0.4209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 20 Batch 0: Train Loss = 0.4209\n",
      "Fold 3, epoch 20: Loss = 0.3874 Valid loss = 1.2610 MSE = 854.8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:15:27,342 - INFO - Fold 3, epoch 20: Loss = 0.3874 Valid loss = 1.2610 MSE = 854.8079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, mse = 854.8079, mad = 23.2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:15:27,345 - INFO - Fold 3, mse = 854.8079, mad = 23.2901\n",
      "2023-11-08 17:15:28,031 - INFO - Fold 3 Epoch 21 Batch 0: Train Loss = 0.4552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 21 Batch 0: Train Loss = 0.4552\n",
      "Fold 3, mse = 820.5413, mad = 22.8390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:15:43,863 - INFO - Fold 3, mse = 820.5413, mad = 22.8390\n",
      "2023-11-08 17:15:44,533 - INFO - Fold 3 Epoch 22 Batch 0: Train Loss = 0.3202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 22 Batch 0: Train Loss = 0.3202\n",
      "Fold 3, mse = 856.6522, mad = 23.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:15:59,860 - INFO - Fold 3, mse = 856.6522, mad = 23.1634\n",
      "2023-11-08 17:16:00,642 - INFO - Fold 3 Epoch 23 Batch 0: Train Loss = 0.4221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 23 Batch 0: Train Loss = 0.4221\n",
      "Fold 3, mse = 840.0885, mad = 23.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:16:16,348 - INFO - Fold 3, mse = 840.0885, mad = 23.0286\n",
      "2023-11-08 17:16:17,040 - INFO - Fold 3 Epoch 24 Batch 0: Train Loss = 0.4065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 24 Batch 0: Train Loss = 0.4065\n",
      "Fold 3, mse = 831.4609, mad = 22.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:16:32,579 - INFO - Fold 3, mse = 831.4609, mad = 22.9385\n",
      "2023-11-08 17:16:33,146 - INFO - Fold 3 Epoch 25 Batch 0: Train Loss = 0.3479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 25 Batch 0: Train Loss = 0.3479\n",
      "Fold 3, mse = 853.2305, mad = 23.1674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:16:49,677 - INFO - Fold 3, mse = 853.2305, mad = 23.1674\n",
      "2023-11-08 17:16:50,396 - INFO - Fold 3 Epoch 26 Batch 0: Train Loss = 0.3991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 26 Batch 0: Train Loss = 0.3991\n",
      "Fold 3, mse = 865.9003, mad = 23.2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:17:07,408 - INFO - Fold 3, mse = 865.9003, mad = 23.2949\n",
      "2023-11-08 17:17:08,153 - INFO - Fold 3 Epoch 27 Batch 0: Train Loss = 0.4437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 27 Batch 0: Train Loss = 0.4437\n",
      "Fold 3, mse = 864.0394, mad = 23.3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:17:23,230 - INFO - Fold 3, mse = 864.0394, mad = 23.3112\n",
      "2023-11-08 17:17:23,826 - INFO - Fold 3 Epoch 28 Batch 0: Train Loss = 0.3722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 28 Batch 0: Train Loss = 0.3722\n",
      "Fold 3, mse = 860.0411, mad = 23.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:17:37,837 - INFO - Fold 3, mse = 860.0411, mad = 23.0625\n",
      "2023-11-08 17:17:38,532 - INFO - Fold 3 Epoch 29 Batch 0: Train Loss = 0.3913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 29 Batch 0: Train Loss = 0.3913\n",
      "Fold 3, mse = 842.9297, mad = 23.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:17:53,417 - INFO - Fold 3, mse = 842.9297, mad = 23.0403\n",
      "2023-11-08 17:17:54,227 - INFO - Fold 4 Epoch 0 Batch 0: Train Loss = 1.2248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 0 Batch 0: Train Loss = 1.2248\n",
      "Fold 4, epoch 0: Loss = 1.1806 Valid loss = 0.9651 MSE = 684.5031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:10,199 - INFO - Fold 4, epoch 0: Loss = 1.1806 Valid loss = 0.9651 MSE = 684.5031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 684.5031 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:10,202 - INFO - ------------ Save FOLD-BEST model - MSE: 684.5031 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  120  991    0]\n",
      " [   0  329 3632    0]\n",
      " [   0   85 2208    0]\n",
      " [   0    0 1320    0]]\n",
      "Mean absolute deviation (MAD) = 21.859503337090572\n",
      "Mean squared error (MSE) = 684.5031103680776\n",
      "Mean absolute percentage error (MAPE) = 280.90713930998146\n",
      "Cohen kappa score = 0.0370001457960758\n",
      "Fold 4, mse = 684.5031, mad = 21.8595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:10,483 - INFO - Fold 4, mse = 684.5031, mad = 21.8595\n",
      "2023-11-08 17:18:11,177 - INFO - Fold 4 Epoch 1 Batch 0: Train Loss = 1.0944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 1 Batch 0: Train Loss = 1.0944\n",
      "Fold 4, mse = 686.8931, mad = 21.8846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:26,306 - INFO - Fold 4, mse = 686.8931, mad = 21.8846\n",
      "2023-11-08 17:18:26,903 - INFO - Fold 4 Epoch 2 Batch 0: Train Loss = 1.1937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 2 Batch 0: Train Loss = 1.1937\n",
      "------------ Save FOLD-BEST model - MSE: 670.7075 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:42,155 - INFO - ------------ Save FOLD-BEST model - MSE: 670.7075 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  224  887    0]\n",
      " [   0  589 3372    0]\n",
      " [   0  135 2158    0]\n",
      " [   0   25 1295    0]]\n",
      "Mean absolute deviation (MAD) = 21.54783423678054\n",
      "Mean squared error (MSE) = 670.7074501928612\n",
      "Mean absolute percentage error (MAPE) = 274.36790031308925\n",
      "Cohen kappa score = 0.06669963397937018\n",
      "------------ Save best model - MSE: 670.7075 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:42,412 - INFO - ------------ Save best model - MSE: 670.7075 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 670.7075, mad = 21.5478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:42,414 - INFO - Fold 4, mse = 670.7075, mad = 21.5478\n",
      "2023-11-08 17:18:42,978 - INFO - Fold 4 Epoch 3 Batch 0: Train Loss = 1.1828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 3 Batch 0: Train Loss = 1.1828\n",
      "------------ Save FOLD-BEST model - MSE: 654.2449 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:58,454 - INFO - ------------ Save FOLD-BEST model - MSE: 654.2449 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  345  766    0]\n",
      " [   0 1008 2953    0]\n",
      " [   0  279 2014    0]\n",
      " [   0  135 1185    0]]\n",
      "Mean absolute deviation (MAD) = 21.200175741252835\n",
      "Mean squared error (MSE) = 654.2449465912761\n",
      "Mean absolute percentage error (MAPE) = 267.2148113518395\n",
      "Cohen kappa score = 0.08911268299805275\n",
      "------------ Save best model - MSE: 654.2449 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:58,821 - INFO - ------------ Save best model - MSE: 654.2449 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 654.2449, mad = 21.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:18:58,823 - INFO - Fold 4, mse = 654.2449, mad = 21.2002\n",
      "2023-11-08 17:18:59,468 - INFO - Fold 4 Epoch 4 Batch 0: Train Loss = 0.8803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 4 Batch 0: Train Loss = 0.8803\n",
      "------------ Save FOLD-BEST model - MSE: 645.3749 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:19:14,313 - INFO - ------------ Save FOLD-BEST model - MSE: 645.3749 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  450  661    0]\n",
      " [   0 1320 2641    0]\n",
      " [   0  472 1821    0]\n",
      " [   0  180 1140    0]]\n",
      "Mean absolute deviation (MAD) = 20.991800626558117\n",
      "Mean squared error (MSE) = 645.3748642114749\n",
      "Mean absolute percentage error (MAPE) = 262.1167321382117\n",
      "Cohen kappa score = 0.10021331057120586\n",
      "------------ Save best model - MSE: 645.3749 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:19:14,682 - INFO - ------------ Save best model - MSE: 645.3749 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 645.3749, mad = 20.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:19:14,683 - INFO - Fold 4, mse = 645.3749, mad = 20.9918\n",
      "2023-11-08 17:19:15,411 - INFO - Fold 4 Epoch 5 Batch 0: Train Loss = 0.9021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 5 Batch 0: Train Loss = 0.9021\n",
      "------------ Save FOLD-BEST model - MSE: 629.6928 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:19:30,534 - INFO - ------------ Save FOLD-BEST model - MSE: 629.6928 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  594  517    0]\n",
      " [   0 1802 2159    0]\n",
      " [   0  666 1627    0]\n",
      " [   0  273 1047    0]]\n",
      "Mean absolute deviation (MAD) = 20.491530533788943\n",
      "Mean squared error (MSE) = 629.6927763302558\n",
      "Mean absolute percentage error (MAPE) = 248.00909607823064\n",
      "Cohen kappa score = 0.12916360616201683\n",
      "------------ Save best model - MSE: 629.6928 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:19:30,901 - INFO - ------------ Save best model - MSE: 629.6928 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 629.6928, mad = 20.4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:19:30,903 - INFO - Fold 4, mse = 629.6928, mad = 20.4915\n",
      "2023-11-08 17:19:31,593 - INFO - Fold 4 Epoch 6 Batch 0: Train Loss = 0.9272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 6 Batch 0: Train Loss = 0.9272\n",
      "Fold 4, mse = 631.1834, mad = 20.3796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:19:48,438 - INFO - Fold 4, mse = 631.1834, mad = 20.3796\n",
      "2023-11-08 17:19:49,158 - INFO - Fold 4 Epoch 7 Batch 0: Train Loss = 0.7558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 7 Batch 0: Train Loss = 0.7558\n",
      "Fold 4, mse = 632.9747, mad = 20.2914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:20:03,995 - INFO - Fold 4, mse = 632.9747, mad = 20.2914\n",
      "2023-11-08 17:20:04,662 - INFO - Fold 4 Epoch 8 Batch 0: Train Loss = 0.6259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 8 Batch 0: Train Loss = 0.6259\n",
      "Fold 4, mse = 638.1502, mad = 20.2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:20:19,035 - INFO - Fold 4, mse = 638.1502, mad = 20.2635\n",
      "2023-11-08 17:20:19,623 - INFO - Fold 4 Epoch 9 Batch 0: Train Loss = 0.6085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 9 Batch 0: Train Loss = 0.6085\n",
      "Fold 4, mse = 641.9306, mad = 20.3029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:20:34,882 - INFO - Fold 4, mse = 641.9306, mad = 20.3029\n",
      "2023-11-08 17:20:35,451 - INFO - Fold 4 Epoch 10 Batch 0: Train Loss = 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 10 Batch 0: Train Loss = 0.7041\n",
      "Fold 4, epoch 10: Loss = 0.6358 Valid loss = 0.8942 MSE = 634.4354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:20:51,416 - INFO - Fold 4, epoch 10: Loss = 0.6358 Valid loss = 0.8942 MSE = 634.4354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 634.4354, mad = 20.2599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:20:51,418 - INFO - Fold 4, mse = 634.4354, mad = 20.2599\n",
      "2023-11-08 17:20:52,058 - INFO - Fold 4 Epoch 11 Batch 0: Train Loss = 0.6890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 11 Batch 0: Train Loss = 0.6890\n",
      "------------ Save FOLD-BEST model - MSE: 627.9062 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:07,627 - INFO - ------------ Save FOLD-BEST model - MSE: 627.9062 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[  40  702  359   10]\n",
      " [  72 2163 1709   17]\n",
      " [   8  985 1297    3]\n",
      " [   0  382  896   42]]\n",
      "Mean absolute deviation (MAD) = 20.07706337076483\n",
      "Mean squared error (MSE) = 627.9062022086302\n",
      "Mean absolute percentage error (MAPE) = 218.54952700714833\n",
      "Cohen kappa score = 0.14213164971330927\n",
      "------------ Save best model - MSE: 627.9062 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:07,881 - INFO - ------------ Save best model - MSE: 627.9062 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 627.9062, mad = 20.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:07,883 - INFO - Fold 4, mse = 627.9062, mad = 20.0771\n",
      "2023-11-08 17:21:08,561 - INFO - Fold 4 Epoch 12 Batch 0: Train Loss = 0.6895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 12 Batch 0: Train Loss = 0.6895\n",
      "Fold 4, mse = 634.2557, mad = 20.2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:25,140 - INFO - Fold 4, mse = 634.2557, mad = 20.2452\n",
      "2023-11-08 17:21:25,867 - INFO - Fold 4 Epoch 13 Batch 0: Train Loss = 0.4611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 13 Batch 0: Train Loss = 0.4611\n",
      "------------ Save FOLD-BEST model - MSE: 625.5510 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:41,362 - INFO - ------------ Save FOLD-BEST model - MSE: 625.5510 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[  53  711  337   10]\n",
      " [  88 2229 1623   21]\n",
      " [   1 1035 1257    0]\n",
      " [   0  381  921   18]]\n",
      "Mean absolute deviation (MAD) = 20.043024718635476\n",
      "Mean squared error (MSE) = 625.5509922186908\n",
      "Mean absolute percentage error (MAPE) = 215.3533889525671\n",
      "Cohen kappa score = 0.1450748980304647\n",
      "------------ Save best model - MSE: 625.5510 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:41,728 - INFO - ------------ Save best model - MSE: 625.5510 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 625.5510, mad = 20.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:41,730 - INFO - Fold 4, mse = 625.5510, mad = 20.0430\n",
      "2023-11-08 17:21:42,423 - INFO - Fold 4 Epoch 14 Batch 0: Train Loss = 0.5133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 14 Batch 0: Train Loss = 0.5133\n",
      "------------ Save FOLD-BEST model - MSE: 620.9622 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:57,923 - INFO - ------------ Save FOLD-BEST model - MSE: 620.9622 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[  72  709  320   10]\n",
      " [ 119 2343 1478   21]\n",
      " [   3 1096 1187    7]\n",
      " [   0  419  864   37]]\n",
      "Mean absolute deviation (MAD) = 19.871521017142058\n",
      "Mean squared error (MSE) = 620.9622487472597\n",
      "Mean absolute percentage error (MAPE) = 207.4462000675229\n",
      "Cohen kappa score = 0.1551885338027199\n",
      "------------ Save best model - MSE: 620.9622 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:58,292 - INFO - ------------ Save best model - MSE: 620.9622 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 620.9622, mad = 19.8715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:21:58,293 - INFO - Fold 4, mse = 620.9622, mad = 19.8715\n",
      "2023-11-08 17:21:58,895 - INFO - Fold 4 Epoch 15 Batch 0: Train Loss = 0.4940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 15 Batch 0: Train Loss = 0.4940\n",
      "------------ Save FOLD-BEST model - MSE: 615.5759 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:22:14,807 - INFO - ------------ Save FOLD-BEST model - MSE: 615.5759 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[  85  711  306    9]\n",
      " [ 146 2364 1424   27]\n",
      " [   0 1116 1175    2]\n",
      " [   0  412  887   21]]\n",
      "Mean absolute deviation (MAD) = 19.8030216676819\n",
      "Mean squared error (MSE) = 615.5759049674701\n",
      "Mean absolute percentage error (MAPE) = 203.63416952806\n",
      "Cohen kappa score = 0.15946039147165192\n",
      "------------ Save best model - MSE: 615.5759 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:22:15,118 - INFO - ------------ Save best model - MSE: 615.5759 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 615.5759, mad = 19.8030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:22:15,121 - INFO - Fold 4, mse = 615.5759, mad = 19.8030\n",
      "2023-11-08 17:22:15,738 - INFO - Fold 4 Epoch 16 Batch 0: Train Loss = 0.6448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 16 Batch 0: Train Loss = 0.6448\n",
      "Fold 4, mse = 625.2642, mad = 20.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:22:31,074 - INFO - Fold 4, mse = 625.2642, mad = 20.0349\n",
      "2023-11-08 17:22:31,668 - INFO - Fold 4 Epoch 17 Batch 0: Train Loss = 0.4848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 17 Batch 0: Train Loss = 0.4848\n",
      "Fold 4, mse = 620.3527, mad = 20.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:22:47,196 - INFO - Fold 4, mse = 620.3527, mad = 20.0577\n",
      "2023-11-08 17:22:47,918 - INFO - Fold 4 Epoch 18 Batch 0: Train Loss = 0.5103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 18 Batch 0: Train Loss = 0.5103\n",
      "Fold 4, mse = 623.6733, mad = 19.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:03,736 - INFO - Fold 4, mse = 623.6733, mad = 19.9119\n",
      "2023-11-08 17:23:04,405 - INFO - Fold 4 Epoch 19 Batch 0: Train Loss = 0.4586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 19 Batch 0: Train Loss = 0.4586\n",
      "------------ Save FOLD-BEST model - MSE: 613.1711 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:18,957 - INFO - ------------ Save FOLD-BEST model - MSE: 613.1711 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[  54  693  354   10]\n",
      " [  93 2208 1621   39]\n",
      " [   0 1047 1228   18]\n",
      " [   0  405  897   18]]\n",
      "Mean absolute deviation (MAD) = 19.900070258621504\n",
      "Mean squared error (MSE) = 613.1710965420564\n",
      "Mean absolute percentage error (MAPE) = 215.44877722878337\n",
      "Cohen kappa score = 0.13311867493592988\n",
      "------------ Save best model - MSE: 613.1711 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:19,205 - INFO - ------------ Save best model - MSE: 613.1711 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 613.1711, mad = 19.9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:19,207 - INFO - Fold 4, mse = 613.1711, mad = 19.9001\n",
      "2023-11-08 17:23:19,763 - INFO - Fold 4 Epoch 20 Batch 0: Train Loss = 0.5408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 20 Batch 0: Train Loss = 0.5408\n",
      "Fold 4, epoch 20: Loss = 0.5026 Valid loss = 0.8688 MSE = 616.2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:35,255 - INFO - Fold 4, epoch 20: Loss = 0.5026 Valid loss = 0.8688 MSE = 616.2459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 616.2459, mad = 19.9445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:35,258 - INFO - Fold 4, mse = 616.2459, mad = 19.9445\n",
      "2023-11-08 17:23:35,988 - INFO - Fold 4 Epoch 21 Batch 0: Train Loss = 0.4763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 21 Batch 0: Train Loss = 0.4763\n",
      "------------ Save FOLD-BEST model - MSE: 610.9017 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:51,212 - INFO - ------------ Save FOLD-BEST model - MSE: 610.9017 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[  62  652  388    9]\n",
      " [  78 2136 1712   35]\n",
      " [   0  974 1301   18]\n",
      " [   0  338  949   33]]\n",
      "Mean absolute deviation (MAD) = 19.903956473031812\n",
      "Mean squared error (MSE) = 610.901665024777\n",
      "Mean absolute percentage error (MAPE) = 218.1257277963455\n",
      "Cohen kappa score = 0.14782647818290473\n",
      "------------ Save best model - MSE: 610.9017 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:51,505 - INFO - ------------ Save best model - MSE: 610.9017 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, mse = 610.9017, mad = 19.9040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:23:51,507 - INFO - Fold 4, mse = 610.9017, mad = 19.9040\n",
      "2023-11-08 17:23:52,169 - INFO - Fold 4 Epoch 22 Batch 0: Train Loss = 0.4939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 22 Batch 0: Train Loss = 0.4939\n",
      "Fold 4, mse = 623.4927, mad = 20.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:24:07,543 - INFO - Fold 4, mse = 623.4927, mad = 20.0953\n",
      "2023-11-08 17:24:08,219 - INFO - Fold 4 Epoch 23 Batch 0: Train Loss = 0.4638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 23 Batch 0: Train Loss = 0.4638\n",
      "Fold 4, mse = 614.4404, mad = 19.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:24:22,761 - INFO - Fold 4, mse = 614.4404, mad = 19.8768\n",
      "2023-11-08 17:24:23,424 - INFO - Fold 4 Epoch 24 Batch 0: Train Loss = 0.4524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 24 Batch 0: Train Loss = 0.4524\n",
      "Fold 4, mse = 615.3014, mad = 20.0648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:24:38,277 - INFO - Fold 4, mse = 615.3014, mad = 20.0648\n",
      "2023-11-08 17:24:38,906 - INFO - Fold 4 Epoch 25 Batch 0: Train Loss = 0.4705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 25 Batch 0: Train Loss = 0.4705\n",
      "Fold 4, mse = 631.7523, mad = 20.1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:24:54,332 - INFO - Fold 4, mse = 631.7523, mad = 20.1081\n",
      "2023-11-08 17:24:54,879 - INFO - Fold 4 Epoch 26 Batch 0: Train Loss = 0.4242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 26 Batch 0: Train Loss = 0.4242\n",
      "Fold 4, mse = 615.1992, mad = 20.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:25:10,890 - INFO - Fold 4, mse = 615.1992, mad = 20.0213\n",
      "2023-11-08 17:25:11,523 - INFO - Fold 4 Epoch 27 Batch 0: Train Loss = 0.4695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 27 Batch 0: Train Loss = 0.4695\n",
      "Fold 4, mse = 635.7979, mad = 20.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:25:26,880 - INFO - Fold 4, mse = 635.7979, mad = 20.1140\n",
      "2023-11-08 17:25:27,554 - INFO - Fold 4 Epoch 28 Batch 0: Train Loss = 0.4350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 28 Batch 0: Train Loss = 0.4350\n",
      "Fold 4, mse = 619.7320, mad = 19.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:25:43,109 - INFO - Fold 4, mse = 619.7320, mad = 19.9569\n",
      "2023-11-08 17:25:43,789 - INFO - Fold 4 Epoch 29 Batch 0: Train Loss = 0.5613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 29 Batch 0: Train Loss = 0.5613\n",
      "Fold 4, mse = 620.8091, mad = 19.9124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:25:59,025 - INFO - Fold 4, mse = 620.8091, mad = 19.9124\n",
      "2023-11-08 17:25:59,776 - INFO - Fold 5 Epoch 0 Batch 0: Train Loss = 1.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 0 Batch 0: Train Loss = 1.0700\n",
      "Fold 5, epoch 0: Loss = 1.0463 Valid loss = 0.9937 MSE = 696.6147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:13,783 - INFO - Fold 5, epoch 0: Loss = 1.0463 Valid loss = 0.9937 MSE = 696.6147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 696.6147 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:13,785 - INFO - ------------ Save FOLD-BEST model - MSE: 696.6147 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  608  460    0]\n",
      " [   0 1826 2102    0]\n",
      " [   0 1078 1249    0]\n",
      " [   0  555  874    0]]\n",
      "Mean absolute deviation (MAD) = 21.4678890549717\n",
      "Mean squared error (MSE) = 696.6147073791137\n",
      "Mean absolute percentage error (MAPE) = 238.20907090833416\n",
      "Cohen kappa score = 0.032497739844431384\n",
      "Fold 5, mse = 696.6147, mad = 21.4679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:13,995 - INFO - Fold 5, mse = 696.6147, mad = 21.4679\n",
      "2023-11-08 17:26:14,551 - INFO - Fold 5 Epoch 1 Batch 0: Train Loss = 1.0346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 1 Batch 0: Train Loss = 1.0346\n",
      "------------ Save FOLD-BEST model - MSE: 684.5840 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:28,905 - INFO - ------------ Save FOLD-BEST model - MSE: 684.5840 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  661  407    0]\n",
      " [   0 2206 1722    0]\n",
      " [   0 1235 1092    0]\n",
      " [   0  488  941    0]]\n",
      "Mean absolute deviation (MAD) = 21.219465023715518\n",
      "Mean squared error (MSE) = 684.5839992914293\n",
      "Mean absolute percentage error (MAPE) = 232.52415457685802\n",
      "Cohen kappa score = 0.07214718032266565\n",
      "Fold 5, mse = 684.5840, mad = 21.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:29,154 - INFO - Fold 5, mse = 684.5840, mad = 21.2195\n",
      "2023-11-08 17:26:29,793 - INFO - Fold 5 Epoch 2 Batch 0: Train Loss = 0.8454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 2 Batch 0: Train Loss = 0.8454\n",
      "------------ Save FOLD-BEST model - MSE: 675.0285 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:43,527 - INFO - ------------ Save FOLD-BEST model - MSE: 675.0285 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  741  327    0]\n",
      " [   0 2448 1480    0]\n",
      " [   0 1299 1028    0]\n",
      " [   0  532  897    0]]\n",
      "Mean absolute deviation (MAD) = 21.006204218631918\n",
      "Mean squared error (MSE) = 675.0285280652215\n",
      "Mean absolute percentage error (MAPE) = 226.71263383894447\n",
      "Cohen kappa score = 0.09536715475785795\n",
      "Fold 5, mse = 675.0285, mad = 21.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:43,674 - INFO - Fold 5, mse = 675.0285, mad = 21.0062\n",
      "2023-11-08 17:26:44,198 - INFO - Fold 5 Epoch 3 Batch 0: Train Loss = 0.9028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 3 Batch 0: Train Loss = 0.9028\n",
      "------------ Save FOLD-BEST model - MSE: 672.5578 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:58,058 - INFO - ------------ Save FOLD-BEST model - MSE: 672.5578 ------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom bins confusion matrix:\n",
      "[[   0  770  298    0]\n",
      " [   0 2544 1384    0]\n",
      " [   0 1369  958    0]\n",
      " [   0  621  808    0]]\n",
      "Mean absolute deviation (MAD) = 20.90992234722943\n",
      "Mean squared error (MSE) = 672.5578337874456\n",
      "Mean absolute percentage error (MAPE) = 221.85399297385527\n",
      "Cohen kappa score = 0.08492435888709526\n",
      "Fold 5, mse = 672.5578, mad = 20.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:26:58,252 - INFO - Fold 5, mse = 672.5578, mad = 20.9099\n",
      "2023-11-08 17:26:58,809 - INFO - Fold 5 Epoch 4 Batch 0: Train Loss = 0.8084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 4 Batch 0: Train Loss = 0.8084\n",
      "Fold 5, mse = 675.8861, mad = 20.8368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:27:12,115 - INFO - Fold 5, mse = 675.8861, mad = 20.8368\n",
      "2023-11-08 17:27:12,731 - INFO - Fold 5 Epoch 5 Batch 0: Train Loss = 0.7674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 5 Batch 0: Train Loss = 0.7674\n",
      "Fold 5, mse = 687.4293, mad = 20.9467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:27:27,256 - INFO - Fold 5, mse = 687.4293, mad = 20.9467\n",
      "2023-11-08 17:27:27,795 - INFO - Fold 5 Epoch 6 Batch 0: Train Loss = 0.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 6 Batch 0: Train Loss = 0.7976\n",
      "Fold 5, mse = 700.9905, mad = 21.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:27:42,430 - INFO - Fold 5, mse = 700.9905, mad = 21.0927\n",
      "2023-11-08 17:27:43,121 - INFO - Fold 5 Epoch 7 Batch 0: Train Loss = 0.7533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 7 Batch 0: Train Loss = 0.7533\n",
      "Fold 5, mse = 716.4093, mad = 21.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:27:57,853 - INFO - Fold 5, mse = 716.4093, mad = 21.1849\n",
      "2023-11-08 17:27:58,483 - INFO - Fold 5 Epoch 8 Batch 0: Train Loss = 0.6995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 8 Batch 0: Train Loss = 0.6995\n",
      "Fold 5, mse = 721.4573, mad = 21.3307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:28:12,851 - INFO - Fold 5, mse = 721.4573, mad = 21.3307\n",
      "2023-11-08 17:28:13,396 - INFO - Fold 5 Epoch 9 Batch 0: Train Loss = 0.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 9 Batch 0: Train Loss = 0.5736\n",
      "Fold 5, mse = 720.1019, mad = 21.4237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:28:27,381 - INFO - Fold 5, mse = 720.1019, mad = 21.4237\n",
      "2023-11-08 17:28:27,915 - INFO - Fold 5 Epoch 10 Batch 0: Train Loss = 0.6822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 10 Batch 0: Train Loss = 0.6822\n",
      "Fold 5, epoch 10: Loss = 0.6310 Valid loss = 1.0274 MSE = 725.3873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:28:43,596 - INFO - Fold 5, epoch 10: Loss = 0.6310 Valid loss = 1.0274 MSE = 725.3873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, mse = 725.3873, mad = 21.5230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:28:43,599 - INFO - Fold 5, mse = 725.3873, mad = 21.5230\n",
      "2023-11-08 17:28:44,095 - INFO - Fold 5 Epoch 11 Batch 0: Train Loss = 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 11 Batch 0: Train Loss = 0.6557\n",
      "Fold 5, mse = 706.1568, mad = 21.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:28:58,115 - INFO - Fold 5, mse = 706.1568, mad = 21.1255\n",
      "2023-11-08 17:28:58,729 - INFO - Fold 5 Epoch 12 Batch 0: Train Loss = 0.5533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 12 Batch 0: Train Loss = 0.5533\n",
      "Fold 5, mse = 734.8889, mad = 21.5558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:29:13,849 - INFO - Fold 5, mse = 734.8889, mad = 21.5558\n",
      "2023-11-08 17:29:14,466 - INFO - Fold 5 Epoch 13 Batch 0: Train Loss = 0.5533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 13 Batch 0: Train Loss = 0.5533\n",
      "Fold 5, mse = 724.0796, mad = 21.4757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:29:29,556 - INFO - Fold 5, mse = 724.0796, mad = 21.4757\n",
      "2023-11-08 17:29:30,179 - INFO - Fold 5 Epoch 14 Batch 0: Train Loss = 0.5251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 14 Batch 0: Train Loss = 0.5251\n",
      "Fold 5, mse = 743.1757, mad = 21.6117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:29:45,761 - INFO - Fold 5, mse = 743.1757, mad = 21.6117\n",
      "2023-11-08 17:29:46,309 - INFO - Fold 5 Epoch 15 Batch 0: Train Loss = 0.5495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 15 Batch 0: Train Loss = 0.5495\n",
      "Fold 5, mse = 727.2741, mad = 21.3918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:30:00,952 - INFO - Fold 5, mse = 727.2741, mad = 21.3918\n",
      "2023-11-08 17:30:01,498 - INFO - Fold 5 Epoch 16 Batch 0: Train Loss = 0.4606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 16 Batch 0: Train Loss = 0.4606\n",
      "Fold 5, mse = 747.1841, mad = 21.7029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:30:17,088 - INFO - Fold 5, mse = 747.1841, mad = 21.7029\n",
      "2023-11-08 17:30:17,755 - INFO - Fold 5 Epoch 17 Batch 0: Train Loss = 0.4454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 17 Batch 0: Train Loss = 0.4454\n",
      "Fold 5, mse = 749.9362, mad = 21.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:30:33,000 - INFO - Fold 5, mse = 749.9362, mad = 21.8028\n",
      "2023-11-08 17:30:33,631 - INFO - Fold 5 Epoch 18 Batch 0: Train Loss = 0.4894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 18 Batch 0: Train Loss = 0.4894\n",
      "Fold 5, mse = 751.6348, mad = 21.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:30:48,017 - INFO - Fold 5, mse = 751.6348, mad = 21.7944\n",
      "2023-11-08 17:30:48,576 - INFO - Fold 5 Epoch 19 Batch 0: Train Loss = 0.4632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 19 Batch 0: Train Loss = 0.4632\n",
      "Fold 5, mse = 757.2227, mad = 21.7807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:31:03,557 - INFO - Fold 5, mse = 757.2227, mad = 21.7807\n",
      "2023-11-08 17:31:04,162 - INFO - Fold 5 Epoch 20 Batch 0: Train Loss = 0.4394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 20 Batch 0: Train Loss = 0.4394\n",
      "Fold 5, epoch 20: Loss = 0.4594 Valid loss = 1.0668 MSE = 747.4766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:31:19,033 - INFO - Fold 5, epoch 20: Loss = 0.4594 Valid loss = 1.0668 MSE = 747.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, mse = 747.4766, mad = 21.7709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:31:19,035 - INFO - Fold 5, mse = 747.4766, mad = 21.7709\n",
      "2023-11-08 17:31:19,622 - INFO - Fold 5 Epoch 21 Batch 0: Train Loss = 0.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 21 Batch 0: Train Loss = 0.3709\n",
      "Fold 5, mse = 745.6022, mad = 21.7383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:31:34,122 - INFO - Fold 5, mse = 745.6022, mad = 21.7383\n",
      "2023-11-08 17:31:34,734 - INFO - Fold 5 Epoch 22 Batch 0: Train Loss = 0.4218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 22 Batch 0: Train Loss = 0.4218\n",
      "Fold 5, mse = 755.6427, mad = 21.7055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:31:48,721 - INFO - Fold 5, mse = 755.6427, mad = 21.7055\n",
      "2023-11-08 17:31:49,232 - INFO - Fold 5 Epoch 23 Batch 0: Train Loss = 0.4082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 23 Batch 0: Train Loss = 0.4082\n",
      "Fold 5, mse = 764.4572, mad = 21.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:32:03,421 - INFO - Fold 5, mse = 764.4572, mad = 21.8696\n",
      "2023-11-08 17:32:04,021 - INFO - Fold 5 Epoch 24 Batch 0: Train Loss = 0.3996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 24 Batch 0: Train Loss = 0.3996\n",
      "Fold 5, mse = 758.9320, mad = 21.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:32:19,085 - INFO - Fold 5, mse = 758.9320, mad = 21.8800\n",
      "2023-11-08 17:32:19,590 - INFO - Fold 5 Epoch 25 Batch 0: Train Loss = 0.4658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 25 Batch 0: Train Loss = 0.4658\n",
      "Fold 5, mse = 780.5985, mad = 22.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:32:33,973 - INFO - Fold 5, mse = 780.5985, mad = 22.2040\n",
      "2023-11-08 17:32:34,467 - INFO - Fold 5 Epoch 26 Batch 0: Train Loss = 0.4541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 26 Batch 0: Train Loss = 0.4541\n",
      "Fold 5, mse = 747.3853, mad = 21.6879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:32:47,736 - INFO - Fold 5, mse = 747.3853, mad = 21.6879\n",
      "2023-11-08 17:32:48,268 - INFO - Fold 5 Epoch 27 Batch 0: Train Loss = 0.3252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 27 Batch 0: Train Loss = 0.3252\n",
      "Fold 5, mse = 760.7726, mad = 21.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:33:02,301 - INFO - Fold 5, mse = 760.7726, mad = 21.8528\n",
      "2023-11-08 17:33:02,919 - INFO - Fold 5 Epoch 28 Batch 0: Train Loss = 0.4105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 28 Batch 0: Train Loss = 0.4105\n",
      "Fold 5, mse = 746.3192, mad = 21.8269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:33:17,132 - INFO - Fold 5, mse = 746.3192, mad = 21.8269\n",
      "2023-11-08 17:33:17,753 - INFO - Fold 5 Epoch 29 Batch 0: Train Loss = 0.3930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 29 Batch 0: Train Loss = 0.3930\n",
      "Fold 5, mse = 760.4849, mad = 21.7859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:33:32,079 - INFO - Fold 5, mse = 760.4849, mad = 21.7859\n",
      "2023-11-08 17:33:32,082 - INFO - mse 674.5056(34.2479)\n",
      "2023-11-08 17:33:32,084 - INFO - mad 20.9344(0.6055)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 674.5056(34.2479)\n",
      "mad 20.9344(0.6055)\n"
     ]
    }
   ],
   "source": [
    "if target_dataset == 'PD':\n",
    "    n_splits = 5\n",
    "    epochs = 30\n",
    "\n",
    "teacher_flag = True\n",
    "transfer_flag = True\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "if target_dataset == 'PD':    \n",
    "    data_str = 'pd'\n",
    "\n",
    "if teacher_flag:\n",
    "    file_name = './model/pretrained-challenge-front-fill-2'+ data_str + '-lstm'\n",
    "else: \n",
    "    file_name = './model/pretrained-challenge-front-fill-2'+ data_str + '-noteacher' + '-lstm'\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "fold_count = 0\n",
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "\n",
    "global_best = 10000\n",
    "mse = []\n",
    "mad = []\n",
    "mape = []\n",
    "kappa = []\n",
    "history = []\n",
    "\n",
    "pad_token = np.zeros(input_dim)\n",
    "# begin_time = time.time()\n",
    "\n",
    "for train, test in kfold.split(long_x):\n",
    "    train_x = [long_x[i] for i in train]\n",
    "    train_y = [long_time[i] for i in train]\n",
    "    train_x_len = [all_x_len[i] for i in train]\n",
    "    #train_static = [long_static[i] for i in train]\n",
    "    \n",
    "    train_x, train_y, train_x_len = get_n2n_data(train_x, train_y, train_x_len)\n",
    "    if len(train_x) % 256 == 1:\n",
    "        print(len(train_x))\n",
    "        print('wrong squeeze!')\n",
    "\n",
    "# for train, test in kfold.split(long_x):\n",
    "for test, train in kfold.split(long_x):\n",
    "    \n",
    "    model = distcare_target(input_dim = input_dim,output_dim=output_dim, d_model=d_model, MHD_num_head=MHD_num_head, d_ff=d_ff, hidden_dim=hidden_dim).to(device)\n",
    "    \n",
    "    if transfer_flag:\n",
    "        checkpoint = torch.load(file_name, \\\n",
    "                        map_location=torch.device(\"cuda:2\" if torch.cuda.is_available() == True else 'cpu'))\n",
    "        pretrain_dict = checkpoint['net']\n",
    "        model_dict = model.state_dict()\n",
    "        pretrain_dict = transfer_lstm_dict(pretrain_dict, model_dict)\n",
    "        model_dict.update(pretrain_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    fold_count += 1\n",
    "#     print(train)\n",
    "\n",
    "    \n",
    "    train_x = [long_x[i] for i in train]\n",
    "    train_y = [long_time[i] for i in train]\n",
    "    train_x_len = [all_x_len[i] for i in train]\n",
    "    #train_static = [long_static[i] for i in train]\n",
    "    \n",
    "    train_x, train_y, train_x_len = get_n2n_data(train_x, train_y, train_x_len)\n",
    "    \n",
    "    test_x = [long_x[i] for i in test]\n",
    "    test_y = [long_time[i] for i in test]\n",
    "    test_x_len = [all_x_len[i] for i in test]\n",
    "    #test_static = [long_static[i] for i in test]\n",
    "    \n",
    "    test_x, test_y, test_x_len = get_n2n_data(test_x, test_y, test_x_len)\n",
    "    \n",
    "    if not os.path.exists('./model/'+data_str):\n",
    "        os.mkdir('./model/'+data_str)\n",
    "        \n",
    "    if transfer_flag:\n",
    "        target_file_name = './model/'+data_str+'/distcare-trans-'+str(n_splits)+'-fold-LOS-regression' + str(fold_count)  + '-lstm'#4114\n",
    "    else:\n",
    "        target_file_name = './model/'+data_str+'/distcare-no-trans-'+str(n_splits)+'-fold-LOS-regression' + str(fold_count) + '-lstm'#4114\n",
    "    \n",
    "    fold_train_loss = []\n",
    "    fold_valid_loss = []\n",
    "    best_mse = 10000\n",
    "    best_mad = 0\n",
    "    best_mape = 0\n",
    "    best_kappa = 0\n",
    "    \n",
    "    for each_epoch in range(epochs):\n",
    "       \n",
    "        \n",
    "        epoch_loss = []\n",
    "        counter_batch = 0\n",
    "        model.train()  \n",
    "        \n",
    "        for step, (batch_x, batch_y, batch_lens) in enumerate(ckd_batch_iter(train_x, train_y, train_x_len, batch_size, shuffle=True)):  \n",
    "            optimizer.zero_grad()\n",
    "            batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "            batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "\n",
    "            masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "            opt, decov_loss, emb = model(batch_x, batch_lens)\n",
    "\n",
    "            MSE_Loss = get_re_loss(opt, batch_y.unsqueeze(-1))\n",
    "\n",
    "#             model_loss = pred_loss + 1e7*decov_loss\n",
    "            model_loss = MSE_Loss\n",
    "\n",
    "            loss = model_loss\n",
    "\n",
    "            epoch_loss.append(MSE_Loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 50 == 0:\n",
    "                print('Fold %d Epoch %d Batch %d: Train Loss = %.4f'%(fold_count,each_epoch, step, loss.cpu().detach().numpy()))\n",
    "                logger.info('Fold %d Epoch %d Batch %d: Train Loss = %.4f'%(fold_count,each_epoch, step, loss.cpu().detach().numpy()))\n",
    "            \n",
    "        epoch_loss = np.mean(epoch_loss)\n",
    "        fold_train_loss.append(epoch_loss)\n",
    "\n",
    "        #Validation\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_pred_flatten = []\n",
    "        y_true_flatten = []\n",
    "        outcome_pred_flatten = []\n",
    "        outcome_true_flatten = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            valid_loss = []\n",
    "            valid_true = []\n",
    "            valid_pred = []\n",
    "            for batch_x, batch_y, batch_lens in ckd_batch_iter(test_x, test_y, test_x_len, batch_size):\n",
    "                batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "                batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "                batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "                masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "               \n",
    "                opt, decov_loss, emb = model(batch_x, batch_lens)\n",
    "                \n",
    "                MSE_Loss = get_re_loss(opt, batch_y.unsqueeze(-1))\n",
    "                \n",
    "                valid_loss.append(MSE_Loss.cpu().detach().numpy())\n",
    "\n",
    "                y_pred_flatten += [reverse_los(x, los_info) / 30 for x in list(opt.cpu().detach().numpy().flatten())]\n",
    "                y_true_flatten += [reverse_los(x, los_info) / 30 for x in list(batch_y.cpu().numpy().flatten())]\n",
    "            \n",
    "\n",
    "            valid_loss = np.mean(valid_loss)\n",
    "            fold_valid_loss.append(valid_loss)\n",
    "            ret = metrics.print_metrics_regression(y_true_flatten, y_pred_flatten, verbose=0)\n",
    "            history.append(ret)\n",
    "            #print()\n",
    "\n",
    "            if each_epoch % 10 == 0:\n",
    "                print('Fold %d, epoch %d: Loss = %.4f Valid loss = %.4f MSE = %.4f' % (\n",
    "                    fold_count, each_epoch, fold_train_loss[-1], fold_valid_loss[-1], ret['mse']), flush=True)\n",
    "                logger.info('Fold %d, epoch %d: Loss = %.4f Valid loss = %.4f MSE = %.4f' % (\n",
    "                    fold_count, each_epoch, fold_train_loss[-1], fold_valid_loss[-1], ret['mse']))\n",
    "                # metrics.print_metrics_regression(y_true_flatten, y_pred_flatten)\n",
    "                \n",
    "            cur_mse = ret['mse']\n",
    "            if cur_mse < best_mse:\n",
    "                print('------------ Save FOLD-BEST model - MSE: %.4f ------------' % cur_mse, flush=True)\n",
    "                logger.info('------------ Save FOLD-BEST model - MSE: %.4f ------------' % cur_mse)\n",
    "                metrics.print_metrics_regression(y_true_flatten, y_pred_flatten)\n",
    "                best_mse = cur_mse\n",
    "                best_mad = ret['mad']\n",
    "                state = {\n",
    "                    'net': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': each_epoch\n",
    "                }\n",
    "                torch.save(state, target_file_name + '_' + str(fold_count))\n",
    "\n",
    "                if cur_mse < global_best:\n",
    "                    global_best = cur_mse\n",
    "                    state = {\n",
    "                        'net': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'epoch': each_epoch\n",
    "                    }\n",
    "                    torch.save(state, target_file_name)\n",
    "                    print('------------ Save best model - MSE: %.4f ------------' % cur_mse, flush=True)\n",
    "                    logger.info('------------ Save best model - MSE: %.4f ------------' % cur_mse)\n",
    "\n",
    "        print('Fold %d, mse = %.4f, mad = %.4f' % (fold_count, ret['mse'], ret['mad']), flush=True)\n",
    "        logger.info('Fold %d, mse = %.4f, mad = %.4f' % (fold_count, ret['mse'], ret['mad']))\n",
    "\n",
    "    mse.append(best_mse)\n",
    "    mad.append(best_mad)\n",
    "    total_train_loss.append(fold_train_loss)\n",
    "    total_valid_loss.append(fold_valid_loss)\n",
    "\n",
    "\n",
    "print('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "print('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "logger.info('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "logger.info('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:33:32,097 - INFO - mse 674.5056(34.2479)\n",
      "2023-11-08 17:33:32,099 - INFO - mad 20.9344(0.6055)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 674.5056(34.2479)\n",
      "mad 20.9344(0.6055)\n"
     ]
    }
   ],
   "source": [
    "print('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "print('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "logger.info('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "logger.info('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('history.pkl', 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = []\n",
    "# mad = []\n",
    "# best_mse = 99999999\n",
    "# best_mad = 0\n",
    "# i = 0\n",
    "# for each in history:\n",
    "#     i += 1\n",
    "#     if each['mse'] < best_mse:\n",
    "#         best_mse = each['mse']\n",
    "#         best_mad = each['mad']\n",
    "#     if i == 100:\n",
    "#         mse.append(best_mse / 900)\n",
    "#         mad.append(best_mad / 30)\n",
    "#         best_mse = 99999999\n",
    "#         best_mad = 0\n",
    "#         i = 0\n",
    "# print('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "# print('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "# logger.info('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "# logger.info('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
