{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle5 as pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import logging\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils\n",
    "from typing import Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "print(\"available device: {}\".format(device))\n",
    "reverse = True\n",
    "model_name = 'distcare_change4'\n",
    "target_dataset = 'HM'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reverse:\n",
    "    file_name = 'log_file' + '_' + model_name + '_' + target_dataset + '_' + 'reverse' + '.log'\n",
    "else:\n",
    "    file_name = 'log_file' + '_' + model_name + '_' + target_dataset + '.log'\n",
    "def get_logger(name, file_name):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # 以下两行是为了在jupyter notebook 中不重复输出日志\n",
    "    if logger.root.handlers:\n",
    "        logger.root.handlers[0].setLevel(logging.WARNING)\n",
    " \n",
    "    # handler_stdout = logging.StreamHandler() #need_recover\n",
    "    # handler_stdout.setLevel(logging.INFO)\n",
    "    # handler_stdout.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    # logger.addHandler(handler_stdout)#need_recover\n",
    " \n",
    "    handler_file = logging.FileHandler(filename=file_name, mode='w', encoding='utf-8')\n",
    "    handler_file.setLevel(logging.DEBUG)\n",
    "    handler_file.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler_file)\n",
    " \n",
    "    return logger\n",
    "\n",
    "logger = get_logger(__name__, file_name)\n",
    "\n",
    "logger.debug('这是希望输出的debug内容')\n",
    "logger.info('这是希望输出的info内容')\n",
    "logger.warning('这是希望输出的warning内容')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_dataset == 'TJ':\n",
    "    data_path = './data/Tongji/'\n",
    "    all_x = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    all_y = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_time = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_x_len = [len(i) for i in all_x]\n",
    "    for i in range(len(all_time)):\n",
    "        for j in range(len(all_time[i])):\n",
    "            all_time[i][j] = all_time[i][j][-1]\n",
    "            all_y[i][j] = all_y[i][j][0]\n",
    "elif target_dataset == 'HM':\n",
    "    data_path = './data/CDSL/'\n",
    "    all_x = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    all_y = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_time = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "    for i in range(len(all_time)):\n",
    "        for j in range(len(all_time[i])):\n",
    "            all_time[i][j] = all_time[i][j][-1]\n",
    "            all_y[i][j] = all_y[i][j][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_x = all_x\n",
    "long_y = all_y\n",
    "long_y_kfold = [each[-1] for each in all_y]\n",
    "long_time = all_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_visit(hidden_states, mask):\n",
    "    \"\"\"Gets the last visit from the sequence model.\n",
    "\n",
    "    Args:\n",
    "        hidden_states: [batch size, seq len, hidden_size]\n",
    "        mask: [batch size, seq len]\n",
    "\n",
    "    Returns:\n",
    "        last_visit: [batch size, hidden_size]\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        return hidden_states[:, -1, :]\n",
    "    else:\n",
    "        mask = mask.long()\n",
    "        last_visit = torch.sum(mask, 1) - 1\n",
    "        last_visit = last_visit.unsqueeze(-1)\n",
    "        last_visit = last_visit.expand(-1, hidden_states.shape[1] * hidden_states.shape[2])\n",
    "        last_visit = torch.reshape(last_visit, hidden_states.shape)\n",
    "        last_hidden_states = torch.gather(hidden_states, 1, last_visit)\n",
    "        last_hidden_state = last_hidden_states[:, 0, :]\n",
    "        return last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "\n",
    "class distcare_target(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(distcare_target, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "\n",
    "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.weight = nn.Parameter(torch.normal(0,1,(1,self.input_dim),requires_grad= True).to(device))\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.Linear = nn.Linear(self.hidden_dim, 1)\n",
    "        self.Linear_los = nn.Linear(self.input_dim, self.output_dim)\n",
    "        self.nn_output = nn.Linear(self.input_dim, self.output_dim)\n",
    "        self.nn_outcome = nn.Linear(self.input_dim, self.output_dim)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, lens):\n",
    "        lens = lens.to('cpu')\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "#         demo_main = self.tanh(self.demo_proj_main(demo_input)).unsqueeze(1)# b hidden_dim\n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "        \n",
    "        GRU_embeded_input = self.GRUs[0](pack_padded_sequence(input[:,:,0].unsqueeze(-1), lens, batch_first=True))[1].squeeze().unsqueeze(1) # b 1 h\n",
    "#         print(GRU_embeded_input.shape)\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.GRUs[i+1](pack_padded_sequence(input[:,:,i+1].unsqueeze(-1), lens, batch_first=True))[1].squeeze().unsqueeze(1) # b 1 h\n",
    "            GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
    "        \n",
    "        weight_embeded_input = self.sigmoid(self.weight).unsqueeze(-1) * GRU_embeded_input\n",
    "        \n",
    "#         GRU_embeded_input = torch.cat((GRU_embeded_input, demo_main), 1)# b i+1 h\n",
    "        posi_input = self.dropout(weight_embeded_input) # batch_size * d_input * hidden_dim\n",
    "        contexts = self.Linear(posi_input).squeeze()# b i\n",
    "        # output = self.Linear_los(self.dropout(contexts))# b 1\n",
    "        output = self.nn_output(self.dropout(contexts))\n",
    "        outcome = self.sigmoid(self.nn_outcome(self.dropout(contexts)))\n",
    "        #mask = subsequent_mask(time_step).to(device) # 1 t t 下三角 N to 1任务不用mask\n",
    "        return output, outcome\n",
    "    #, self.MultiHeadedAttention.attn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_dataset == 'TJ':\n",
    "    input_dim = 75\n",
    "    static_dim = 2\n",
    "elif target_dataset == 'HM':\n",
    "    input_dim = 99\n",
    "    static_dim = 2\n",
    "cell = 'GRU'\n",
    "hidden_dim = 32*3\n",
    "d_model = 32\n",
    "MHD_num_head = 4\n",
    "d_ff = 64\n",
    "output_dim = 1\n",
    "RANDOM_SEED = 43\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckd_batch_iter(x, y, lens, batch_size, shuffle=False, outcome=None):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        \n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx],  lens[idx], outcome[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "#         batch_name = [e[2] for e in examples]\n",
    "        batch_lens = [e[2] for e in examples]\n",
    "        batch_outcome = [e[3] for e in examples]\n",
    "       \n",
    "\n",
    "        yield batch_x, batch_y, batch_lens, batch_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n2n_data(x, y, x_len, outcome=None):\n",
    "    length = len(x)\n",
    "    assert length == len(y)\n",
    "    assert length == len(outcome)\n",
    "    assert length == len(x_len)\n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    new_outcome = []\n",
    "    new_x_len = []\n",
    "    for i in range(length):\n",
    "        for j in range(len(x[i])):\n",
    "            new_x.append(x[i][:j+1])\n",
    "            new_y.append(y[i][j])\n",
    "            new_outcome.append(outcome[i][j])\n",
    "            new_x_len.append(j+1)\n",
    "    return new_x, new_y, new_x_len, new_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_to_mask(length, max_len=None, dtype=None):\n",
    "    \"\"\"length: B.\n",
    "    return B x max_len.\n",
    "    If max_len is None, then max of length will be used.\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1, 'Length shape should be 1 dimensional.'\n",
    "    max_len = max_len or length.max().item()\n",
    "    mask = torch.arange(max_len, device=length.device,\n",
    "                        dtype=length.dtype).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "    if dtype is not None:\n",
    "        mask = torch.as_tensor(mask, dtype=dtype, device=length.device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "\n",
    "    sents_padded = []\n",
    "\n",
    "    max_length = max([len(_) for _ in sents])\n",
    "    for i in sents:\n",
    "        padded = list(i) + [pad_token]*(max_length-len(i))\n",
    "        sents_padded.append(np.array(padded))\n",
    "\n",
    "\n",
    "    return np.array(sents_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetMultitaskLoss(nn.Module):\n",
    "    def __init__(self, task_num=2):\n",
    "        super(TargetMultitaskLoss, self).__init__()\n",
    "        self.task_num = task_num\n",
    "        self.alpha = nn.Parameter(torch.ones((task_num)), requires_grad=True)\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, opt_student, los, outcome, outcome_y):\n",
    "        MSE_Loss = self.mse(opt_student, los)\n",
    "        BCE_Loss = self.bce(outcome, outcome_y)\n",
    "        return MSE_Loss * self.alpha[0] + BCE_Loss * self.alpha[1]\n",
    "\n",
    "def get_target_multitask_loss(opt_student, los, outcome, outcome_y):\n",
    "    mtl = TargetMultitaskLoss(task_num=2)\n",
    "    return mtl(opt_student, los, outcome, outcome_y)\n",
    "\n",
    "def reverse_los(y, los_info):\n",
    "    return y * los_info[\"los_std\"] + los_info[\"los_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'los_mean': 5.363315937659429, 'los_std': 4.099244607743503, 'los_median': 4.333333333333333, 'large_los': 21.291666666666668, 'threshold': 3.7605509886094994}\n"
     ]
    }
   ],
   "source": [
    "los_info = pickle.load(open(data_path + 'los_info.pkl', 'rb'))\n",
    "print(los_info)\n",
    "logger.info(los_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = []\n",
    "dynamic_data = []\n",
    "\n",
    "for i in range(len(all_x)):\n",
    "    static_data_temp = np.array(all_x[i])[0,0:2].tolist()\n",
    "    dynamic_data_temp = np.array(all_x[i])[:,2:].tolist()\n",
    "    static_data.append(static_data_temp)\n",
    "    dynamic_data.append(dynamic_data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_dataset == 'TJ':\n",
    "    n_splits = 5\n",
    "    epochs = 150\n",
    "    data_str = 'covid'\n",
    "elif target_dataset == 'HM':\n",
    "    n_splits = 3\n",
    "    epochs = 20\n",
    "    data_str = 'spain'\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "batch_size = 256\n",
    "fold_count = 0\n",
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "\n",
    "\n",
    "global_best = 10000\n",
    "mse = []\n",
    "mad = []\n",
    "mape = []\n",
    "auroc = []\n",
    "auprc = []\n",
    "kappa = []\n",
    "history = []\n",
    "\n",
    "pad_token = np.zeros(input_dim)\n",
    "# begin_time = time.time()\n",
    "\n",
    "for train, test in kfold.split(long_x, long_y_kfold):\n",
    "\n",
    "    if reverse:\n",
    "        temp = train\n",
    "        train = test\n",
    "        test = temp\n",
    "        \n",
    "    # model = StageNet(input_dim=input_dim, static_dim= static_dim, hidden_dim= hidden_dim, d_model= d_model, MHD_num_head= MHD_num_head, d_ff=d_ff, output_dim= output_dim).to(device)\n",
    "    model = distcare_target(input_dim = input_dim,output_dim=output_dim, d_model=d_model, MHD_num_head=MHD_num_head, d_ff=d_ff, hidden_dim=hidden_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    fold_count += 1\n",
    "    train_x = [long_x[i] for i in train]\n",
    "    train_y = [long_time[i] for i in train]\n",
    "    train_outcome = [long_y[i] for i in train]\n",
    "    train_x_len = [all_x_len[i] for i in train]\n",
    "    #train_static = [long_static[i] for i in train]\n",
    "    \n",
    "    train_x, train_y, train_x_len, train_outcome = get_n2n_data(train_x, train_y, train_x_len, outcome=train_outcome)\n",
    "    if len(train_x) % 256 == 1:\n",
    "        print(len(train_x))\n",
    "        print('wrong squeeze!')\n",
    "    \n",
    "    test_x = [long_x[i] for i in test]\n",
    "    test_y = [long_time[i] for i in test]\n",
    "    test_outcome = [long_y[i] for i in test]\n",
    "    test_x_len = [all_x_len[i] for i in test]\n",
    "    \n",
    "    test_x, test_y, test_x_len, test_outcome = get_n2n_data(test_x, test_y, test_x_len, outcome=test_outcome)\n",
    "    \n",
    "    target_file_name = './model/'+data_str+'/concare-'+str(n_splits)+'-fold-LOS-regression' + str(fold_count)#4114\n",
    "   \n",
    "    fold_train_loss = []\n",
    "    fold_valid_loss = []\n",
    "    best_mse = 10000\n",
    "    best_mad = 0\n",
    "    best_auroc = 0\n",
    "    beat_auprc = 0\n",
    "    best_mape = 0\n",
    "    best_kappa = 0\n",
    "    \n",
    "    for each_epoch in range(epochs):\n",
    "       \n",
    "        \n",
    "        epoch_loss = []\n",
    "        counter_batch = 0\n",
    "        model.train()  \n",
    "        \n",
    "        for step, (batch_x, batch_y, batch_lens, batch_outcome) in enumerate(ckd_batch_iter(train_x, train_y, train_x_len, batch_size, shuffle=True, outcome=train_outcome)):  \n",
    "            optimizer.zero_grad()\n",
    "            batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "            batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "            batch_outcome = torch.tensor(batch_outcome, dtype=torch.float32).to(device)\n",
    "            batch_x_static = torch.Tensor([])\n",
    "            batch_x_dynamic = torch.Tensor([])\n",
    "            batch_times = torch.ones((batch_x.size(0), batch_x.size(1))).to(device)\n",
    "            # print(f'batch_x.shape is {batch_x.shape}, batch_y.shape is {batch_y.shape}, batch_times.shape is {batch_times.shape}')\n",
    "            for i in range(len(batch_x)):\n",
    "                static_data_temp = batch_x[i,0,0:2]\n",
    "                dynamic_data_temp = batch_x[i,:,2:]\n",
    "                if i == 0:\n",
    "                    batch_x_static = torch.unsqueeze(static_data_temp,0)\n",
    "                    batch_x_dynamic = torch.unsqueeze(dynamic_data_temp,0)\n",
    "                else:\n",
    "                    batch_x_static = torch.cat((batch_x_static,torch.unsqueeze(static_data_temp,0)), 0)\n",
    "                    batch_x_dynamic = torch.cat((batch_x_dynamic,torch.unsqueeze(dynamic_data_temp,0)), 0)\n",
    "\n",
    "            masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "            # opt, outcome = model(batch_x_dynamic, batch_x_static, batch_lens)\n",
    "            opt, outcome = model(batch_x, batch_lens)\n",
    "\n",
    "#             MSE_Loss = get_re_loss(opt, batch_y.unsqueeze(-1))\n",
    "            pred_loss = get_target_multitask_loss(opt, batch_y.unsqueeze(-1), outcome, batch_outcome.unsqueeze(-1))\n",
    "\n",
    "            model_loss = pred_loss \n",
    "\n",
    "            loss = model_loss\n",
    "\n",
    "            epoch_loss.append(pred_loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 50 == 0:\n",
    "                # print('Fold %d Epoch %d Batch %d: Train Loss = %.4f'%(fold_count,each_epoch, step, loss.cpu().detach().numpy()))#need_recover\n",
    "                logger.info('Fold %d Epoch %d Batch %d: Train Loss = %.4f'%(fold_count,each_epoch, step, loss.cpu().detach().numpy()))\n",
    "            \n",
    "        epoch_loss = np.mean(epoch_loss)\n",
    "        fold_train_loss.append(epoch_loss)\n",
    "\n",
    "        #Validation\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_pred_flatten = []\n",
    "        y_true_flatten = []\n",
    "        outcome_pred_flatten = []\n",
    "        outcome_true_flatten = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            valid_loss = []\n",
    "            valid_true = []\n",
    "            valid_pred = []\n",
    "            for batch_x, batch_y, batch_lens, batch_outcome in ckd_batch_iter(test_x, test_y, test_x_len, batch_size, outcome=test_outcome):\n",
    "                batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "                batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "                batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "                batch_outcome = torch.tensor(batch_outcome, dtype=torch.float32).to(device)\n",
    "                masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "                batch_x_static = torch.Tensor([])\n",
    "                batch_x_dynamic = torch.Tensor([])\n",
    "                batch_times = torch.ones((batch_x.size(0), batch_x.size(1))).to(device)\n",
    "\n",
    "                for i in range(len(batch_x)):\n",
    "                    static_data_temp = batch_x[i,0,0:2]\n",
    "                    dynamic_data_temp = batch_x[i,:,2:]\n",
    "                    if i == 0:\n",
    "                        batch_x_static = torch.unsqueeze(static_data_temp,0)\n",
    "                        batch_x_dynamic = torch.unsqueeze(dynamic_data_temp,0)\n",
    "                    else:\n",
    "                        batch_x_static = torch.cat((batch_x_static,torch.unsqueeze(static_data_temp,0)), 0)\n",
    "                        batch_x_dynamic = torch.cat((batch_x_dynamic,torch.unsqueeze(dynamic_data_temp,0)), 0)\n",
    "               \n",
    "                # opt, outcome = model(batch_x_dynamic, batch_x_static, batch_lens)\n",
    "                # print(f'batch_x_dynamic.shape is {batch_x_dynamic.shape}, batch_x_static.shape is {batch_x_static.shape}')\n",
    "                opt, outcome =  model(batch_x, batch_lens)\n",
    "                \n",
    "#                 MSE_Loss = get_re_loss(opt, batch_y.unsqueeze(-1))\n",
    "                pred_loss = get_target_multitask_loss(opt, batch_y.unsqueeze(-1), outcome, batch_outcome.unsqueeze(-1))\n",
    "                \n",
    "                valid_loss.append(pred_loss.cpu().detach().numpy())\n",
    "\n",
    "                y_pred_flatten += [reverse_los(x, los_info) for x in list(opt.cpu().detach().numpy().flatten())]\n",
    "                y_true_flatten += [reverse_los(x, los_info) for x in list(batch_y.cpu().numpy().flatten())]\n",
    "                outcome_pred_flatten += list(outcome.cpu().detach().numpy().flatten())\n",
    "                outcome_true_flatten += list(batch_outcome.cpu().numpy().flatten())\n",
    "            \n",
    "\n",
    "            valid_loss = np.mean(valid_loss)\n",
    "            fold_valid_loss.append(valid_loss)\n",
    "            ret = metrics.print_metrics_regression(y_true_flatten, y_pred_flatten, verbose=0)\n",
    "            ret_outcome = metrics.print_metrics_binary(outcome_true_flatten, outcome_pred_flatten, verbose=0)\n",
    "            history.append((ret, ret_outcome))\n",
    "\n",
    "            if each_epoch % 10 == 0:\n",
    "                # print('Fold %d, epoch %d: Loss = %.4f Valid loss = %.4f MSE = %.4f AUROC = %.4f' % (\n",
    "                #     fold_count, each_epoch, fold_train_loss[-1], fold_valid_loss[-1], ret['mse'], ret_outcome['auroc']), flush=True) #need_recover\n",
    "                logger.info('Fold %d, epoch %d: Loss = %.4f Valid loss = %.4f MSE = %.4f AUROC = %.4f' % (\n",
    "                    fold_count, each_epoch, fold_train_loss[-1], fold_valid_loss[-1], ret['mse'], ret_outcome['auroc']))\n",
    "                # metrics.print_metrics_regression(y_true_flatten, y_pred_flatten)\n",
    "                \n",
    "            cur_mse = ret['mse']\n",
    "            if cur_mse < best_mse:\n",
    "                # print('------------ Save FOLD-BEST model - MSE: %.4f ------------' % cur_mse, flush=True) #need_recover\n",
    "                logger.info('------------ Save FOLD-BEST model - MSE: %.4f ------------' % cur_mse)\n",
    "                metrics.print_metrics_regression(y_true_flatten, y_pred_flatten)\n",
    "                best_mse = cur_mse\n",
    "                best_mad = ret['mad']\n",
    "                best_auroc = ret_outcome['auroc']\n",
    "                best_auprc = ret_outcome['auprc']\n",
    "                state = {\n",
    "                    'net': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': each_epoch\n",
    "                }\n",
    "                torch.save(state, target_file_name + '_' + str(fold_count))\n",
    "\n",
    "                if cur_mse < global_best:\n",
    "                    global_best = cur_mse\n",
    "                    state = {\n",
    "                        'net': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'epoch': each_epoch\n",
    "                    }\n",
    "                    torch.save(state, target_file_name)\n",
    "                    # print('------------ Save best model - MSE: %.4f ------------' % cur_mse, flush=True) #need_recover\n",
    "                    logger.info('------------ Save best model - MSE: %.4f ------------' % cur_mse)\n",
    "\n",
    "        # print('Fold %d, mse = %.4f, mad = %.4f' % (fold_count, ret['mse'], ret['mad']), flush=True)#need_recover\n",
    "        logger.info('Fold %d, mse = %.4f, mad = %.4f' % (fold_count, ret['mse'], ret['mad']))\n",
    "\n",
    "    mse.append(best_mse)\n",
    "    mad.append(best_mad)\n",
    "    auroc.append(best_auroc)\n",
    "    auprc.append(best_auprc)\n",
    "    total_train_loss.append(fold_train_loss)\n",
    "    total_valid_loss.append(fold_valid_loss)\n",
    "\n",
    "print('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse))) #need_recover\n",
    "print('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "print('auroc %.4f(%.4f)' % (np.mean(auroc), np.std(auroc)))\n",
    "print('auprc %.4f(%.4f)' % (np.mean(auprc), np.std(auprc)))\n",
    "logger.info('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "logger.info('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "logger.info('auroc %.4f(%.4f)' % (np.mean(auroc), np.std(auroc)))\n",
    "logger.info('auprc %.4f(%.4f)' % (np.mean(auprc), np.std(auprc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse))) #need_recover\n",
    "print('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "print('auroc %.4f(%.4f)' % (np.mean(auroc), np.std(auroc)))\n",
    "print('auprc %.4f(%.4f)' % (np.mean(auprc), np.std(auprc)))\n",
    "logger.info('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "logger.info('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "logger.info('auroc %.4f(%.4f)' % (np.mean(auroc), np.std(auroc)))\n",
    "logger.info('auprc %.4f(%.4f)' % (np.mean(auprc), np.std(auprc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reverse:\n",
    "    history_name = 'history' + '_' + model_name + '_' + target_dataset + '_' + 'reverse' + '.pkl'\n",
    "else:\n",
    "    history_name = 'history' + '_' + model_name + '_' + target_dataset + '.pkl'\n",
    "with open(history_name, 'wb') as f:\n",
    "    pickle.dump(history, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
