{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/anaconda3/envs/distcare/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle5 as pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import logging\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils\n",
    "from torch.autograd import Function\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义常量\n",
    "target_dataset = 'TJ' \n",
    "RANDOM_SEED = 43\n",
    "np.random.seed(RANDOM_SEED) #numpy\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED) # cpu\n",
    "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
    "torch.backends.cudnn.deterministic=True # cudnn\n",
    "\n",
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "# print(\"available device: {}\".format(device))\n",
    "reverse = False\n",
    "model_name = 'codats'\n",
    "\n",
    "if reverse:\n",
    "    file_name = 'log_file' + '_' + model_name + '_' + target_dataset + '_' + 'reverse' + '.log'\n",
    "else:\n",
    "    file_name = 'log_file' + '_' + model_name + '_' + target_dataset + '.log'\n",
    "def get_logger(name, file_name):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # 以下两行是为了在jupyter notebook 中不重复输出日志\n",
    "    if logger.root.handlers:\n",
    "        logger.root.handlers[0].setLevel(logging.WARNING)\n",
    " \n",
    "    handler_stdout = logging.StreamHandler()\n",
    "    handler_stdout.setLevel(logging.INFO)\n",
    "    handler_stdout.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "    # logger.addHandler(handler_stdout)\n",
    " \n",
    "    handler_file = logging.FileHandler(filename=file_name, mode='w', encoding='utf-8')\n",
    "    handler_file.setLevel(logging.DEBUG)\n",
    "    handler_file.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "    logger.addHandler(handler_file)\n",
    " \n",
    "    return logger\n",
    "\n",
    "logger = get_logger(__name__,file_name)\n",
    "\n",
    "logger.debug('这是希望输出的debug内容')\n",
    "logger.info('这是希望输出的info内容')\n",
    "logger.warning('这是希望输出的warning内容')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取源域数据集\n",
    "def get_n2n_data(x, y, x_len):\n",
    "    length = len(x)\n",
    "    assert length == len(y)\n",
    "    assert length == len(x_len)\n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    new_x_len = []\n",
    "    for i in range(length):\n",
    "        for j in range(len(x[i])):\n",
    "            new_x.append(x[i][:j+1])\n",
    "            new_y.append(y[i][j])\n",
    "            new_x_len.append(j+1)\n",
    "    return new_x, new_y, new_x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_path = './data/Challenge/'\n",
    "small_part = False\n",
    "arg_timestep = 1.0\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "all_x_source = pickle.load(open(source_data_path + 'new_x_front_fill.dat', 'rb'))\n",
    "all_y_source = pickle.load(open(source_data_path + 'new_y_front_fill.dat', 'rb'))\n",
    "all_names_source = pickle.load(open(source_data_path + 'new_name.dat', 'rb'))\n",
    "static_source = pickle.load(open(source_data_path + 'new_demo_front_fill.dat', 'rb'))\n",
    "mask_x_source = pickle.load(open(source_data_path + 'new_mask_x.dat', 'rb'))\n",
    "mask_demo_source = pickle.load(open(source_data_path + 'new_mask_demo.dat', 'rb'))\n",
    "all_x_len_source = [len(i) for i in all_x_source]\n",
    "\n",
    "if target_dataset == 'PD':\n",
    "    subset_idx_source = [31, 29, 28, 33, 25, 18, 7, 21, 16, 15, 19, 17, 24, 3, 5, 0]\n",
    "elif target_dataset == 'TJ':\n",
    "    subset_idx_source = [27, 29, 18, 16, 26, 33, 28, 31, 32, 15, 11, 25, 21, 20, 9, 17, 30, 19]\n",
    "elif target_dataset == 'HM':\n",
    "    subset_idx_source = [0, 1, 2, 3, 5, 9, 11, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
    "\n",
    "subset_cnt = len(subset_idx_source)\n",
    "other_idx = []\n",
    "for i in range(len(all_x_source[0][0])):\n",
    "    if i not in subset_idx_source:\n",
    "        other_idx.append(i)\n",
    "\n",
    "for i in range(len(all_x_source)): #将共同特征移动到最开始，非共同特征移动到末尾\n",
    "    cur = np.array(all_x_source[i], dtype=float)\n",
    "    cur_mask = np.array(mask_x_source[i])\n",
    "    cur_subset = cur[:, subset_idx_source]\n",
    "    cur_other = cur[:, other_idx]\n",
    "    cur_mask_subset = cur_mask[:, subset_idx_source]\n",
    "    cur_mask_other = cur_mask[:, other_idx]\n",
    "    all_x_source[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "    mask_x_source[i] = np.concatenate((cur_mask_subset, cur_mask_other), axis=1).tolist()\n",
    "\n",
    "\n",
    "train_num_source =int( len(all_x_source) * 0.8) + 1\n",
    "logger.info(train_num_source)\n",
    "dev_num_source =int( len(all_x_source) * 0.1) + 1\n",
    "logger.info(dev_num_source)\n",
    "test_num_source =int( len(all_x_source) * 0.1)\n",
    "logger.info(test_num_source)\n",
    "assert(train_num_source+dev_num_source+test_num_source == len(all_x_source))\n",
    "\n",
    "train_x_source = []\n",
    "train_y_source = []\n",
    "train_names_source = []\n",
    "train_static_source = []\n",
    "train_x_len_source = []\n",
    "train_mask_x_source = []\n",
    "for idx in range(train_num_source):\n",
    "    train_x_source.append(all_x_source[idx])\n",
    "    train_y_source.append(int(all_y_source[idx][-1]))\n",
    "    train_names_source.append(all_names_source[idx])\n",
    "    train_static_source.append(static_source[idx])\n",
    "    train_x_len_source.append(all_x_len_source[idx])\n",
    "    train_mask_x_source.append(mask_x_source[idx])\n",
    "\n",
    "dev_x_source = []\n",
    "dev_y_source = []\n",
    "dev_names_source = []\n",
    "dev_static_source = []\n",
    "dev_x_len_source = []\n",
    "dev_mask_x_source = []\n",
    "for idx in range(train_num_source, train_num_source + dev_num_source):\n",
    "    dev_x_source.append(all_x_source[idx])\n",
    "    dev_y_source.append(int(all_y_source[idx][-1]))\n",
    "    dev_names_source.append(all_names_source[idx])\n",
    "    dev_static_source.append(static_source[idx])\n",
    "    dev_x_len_source.append(all_x_len_source[idx])\n",
    "    dev_mask_x_source.append(mask_x_source[idx])\n",
    "\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "test_names = []\n",
    "test_static = []\n",
    "test_x_len = []\n",
    "test_mask_x = []\n",
    "for idx in range(train_num_source + dev_num_source, train_num_source + dev_num_source + test_num_source):\n",
    "    test_x.append(all_x_source[idx])\n",
    "    test_y.append(int(all_y_source[idx][-1]))\n",
    "    test_names.append(all_names_source[idx])\n",
    "    test_static.append(static_source[idx])\n",
    "    test_x_len.append(all_x_len_source[idx])\n",
    "    test_mask_x.append(mask_x_source[idx])\n",
    "\n",
    "\n",
    "assert(len(train_x_source) == train_num_source)\n",
    "assert(len(dev_x_source) == dev_num_source)\n",
    "assert(len(test_x) == test_num_source)\n",
    "\n",
    "long_x_source = all_x_source\n",
    "long_y_source = [y[-1] for y in all_y_source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_loss(y_pred, y_true):\n",
    "    loss = torch.nn.BCELoss()\n",
    "    return loss(y_pred, y_true)\n",
    "\n",
    "def get_re_loss(y_pred, y_true):\n",
    "    loss = torch.nn.MSELoss()\n",
    "    return loss(y_pred, y_true)\n",
    "\n",
    "def get_kl_loss(x_pred, x_target):\n",
    "    loss = torch.nn.KLDivLoss(reduce=True, size_average=True)\n",
    "    return loss(x_pred, x_target)\n",
    "\n",
    "def get_wass_dist(x_pred, x_target):\n",
    "    m1 = torch.mean(x_pred, dim=0)\n",
    "    m2 = torch.mean(x_target, dim=0)\n",
    "    v1 = torch.var(x_pred, dim=0)\n",
    "    v2 = torch.var(x_target, dim=0)\n",
    "    p1 = torch.sum(torch.pow((m1 - m2), 2))\n",
    "    p2 = torch.sum(torch.pow(torch.pow(v1, 1/2) - torch.pow(v2, 1/2), 2))\n",
    "    return torch.pow(p1+p2, 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "#     print(f'len(pad_token) is {len(pad_token)}')\n",
    "#     print(f'sents is {sents}')\n",
    "\n",
    "    sents_padded = []\n",
    "\n",
    "    max_length = max([len(_) for _ in sents])\n",
    "    for i in sents:\n",
    "        padded = list(i) + [pad_token]*(max_length-len(i))\n",
    "#         print(f'padded is {padded}')\n",
    "        sents_padded.append(np.array(padded))\n",
    "        \n",
    "    return np.array(sents_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(x, y, lens, batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    # batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    batch_num = len(x) // batch_size if len(x) % batch_size == 0 else len(x) // batch_size + 1\n",
    "    # print(f\"len(x) is {len(x)}, len(y) is {len(y)}, len(lens) is {len(lens)}, batch_size is {batch_size}, batch_num is {batch_num}\")\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        if (i + 1) * batch_size  < len(x):\n",
    "            indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        else:\n",
    "            indices = index_array[i * batch_size: ]\n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx],lens[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "        batch_lens = [e[2] for e in examples]\n",
    "\n",
    "        yield batch_x, batch_y, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_to_mask(length, max_len=None, dtype=None):\n",
    "    \"\"\"length: B.\n",
    "    return B x max_len.\n",
    "    If max_len is None, then max of length will be used.\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1, 'Length shape should be 1 dimensional.'\n",
    "    max_len = max_len or length.max().item()\n",
    "    mask = torch.arange(max_len, device=length.device,\n",
    "                        dtype=length.dtype).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "    if dtype is not None:\n",
    "        mask = torch.as_tensor(mask, dtype=dtype, device=length.device)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class codats(nn.Module):\n",
    "    def __init__(self, common_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(codats, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = common_dim\n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.Conv1d(1, hidden_dim, kernel_size=8, padding=4, bias=False),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Conv1d(hidden_dim, 2*hidden_dim, kernel_size=5, padding=2, bias=False),\n",
    "                nn.BatchNorm1d(2*hidden_dim),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.AdaptiveAvgPool1d(1),\n",
    "            )\n",
    "        \n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.Linear = nn.Linear(self.hidden_dim, 1)\n",
    "        self.output = nn.Linear(self.input_dim, self.output_dim)\n",
    "\n",
    "        # adversal方法中的域分类器  \n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('d_fc1', nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(self.hidden_dim))\n",
    "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
    "        self.domain_classifier.add_module('d_fc2', nn.Linear(hidden_dim, 2))\n",
    "        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.FC_embed = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "        self.to_MMD = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "    def forward(self, input, lens, alpha, is_teacher):\n",
    "        lens = lens.to('cpu')\n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "        \n",
    "        codats_embeded_input = self.layers(input[:,:,0].squeeze().unsqueeze(1)).unsqueeze(1)\n",
    "        # print(f'input[:,:,i].shape is {input[:,:,0].shape}')\n",
    "        for i in range(1, feature_dim):\n",
    "            embeded_input = self.layers(input[:,:,i].squeeze().unsqueeze(1)).unsqueeze(1)\n",
    "            codats_embeded_input = torch.cat((codats_embeded_input, embeded_input), 1)\n",
    "            # print(f'docats_embeded_input.shape is {codats_embeded_input.shape}')\n",
    "        codats_embeded_input = codats_embeded_input.squeeze()\n",
    "        # print(f'codats_embeded_input.shape is {codats_embeded_input.shape}')\n",
    "        # GRU_embeded_input = self.GRUs[0](pack_padded_sequence(input[:,:,0].unsqueeze(-1), lens, batch_first=True))[1].squeeze().unsqueeze(1) # b 1 h\n",
    "        # for i in range(feature_dim-1):\n",
    "        #     embeded_input = self.GRUs[i+1](pack_padded_sequence(input[:,:,i+1].unsqueeze(-1), lens, batch_first=True))[1].squeeze().unsqueeze(1) # b 1 h\n",
    "        #     GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
    "        # print(f\"GRU_embeded_input.shape is {GRU_embeded_input.shape}\")\n",
    "        \n",
    "\n",
    "\n",
    "        if is_teacher: # 来自源数据集\n",
    "            common_input = codats_embeded_input[:, 0, :]\n",
    "            for i in range(1, feature_dim):\n",
    "                common_input = common_input + codats_embeded_input[:, i, :]  \n",
    "            # print(f\"common_input1.shape is {common_input.shape}\")\n",
    "            common_input = torch.squeeze(common_input, 1) # batch * hidden\n",
    "            reverse_input = ReverseLayerF.apply(common_input, alpha)\n",
    "            # print(f\"common_input2.shape is {common_input.shape}\")\n",
    "            domain_output = self.domain_classifier(reverse_input)\n",
    "\n",
    "            posi_input = self.dropout(codats_embeded_input) # batch_size * d_input + d_input_diff * hidden_dim\n",
    "            \n",
    "            contexts = self.Linear(posi_input).squeeze()# b i\n",
    "            output = self.output(self.dropout(contexts))# b 1\n",
    "            output = self.sigmoid(output)\n",
    "            return output, domain_output, contexts\n",
    "        else: # 来自目标数据集，主要是为了混淆domain classifier\n",
    "            common_input = codats_embeded_input[:, 0, :]\n",
    "            for i in range(1, feature_dim):\n",
    "                common_input = common_input + codats_embeded_input[:, i, :]  \n",
    "            common_input = torch.squeeze(common_input, 1) # batch * hidden\n",
    "            reverse_input = ReverseLayerF.apply(common_input, alpha)\n",
    "            domain_output = self.domain_classifier(reverse_input)\n",
    "            return domain_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "def getSplitData(x, lens, y):\n",
    "    train_num =int( len(x) * 0.8) + 1\n",
    "    dev_num =int( len(x) * 0.1) + 1\n",
    "    test_num = len(x) - train_num - dev_num\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    train_len = []\n",
    "    for idx in range(train_num):\n",
    "        train_x.append(x[idx])\n",
    "        train_y.append(int(y[idx][-1]))\n",
    "        train_len.append(lens[idx])\n",
    "\n",
    "    dev_x = []\n",
    "    dev_y = []\n",
    "    dev_len = []\n",
    "    for idx in range(train_num, train_num + dev_num):\n",
    "        dev_x.append(x[idx])\n",
    "        dev_y.append(int(y[idx][-1]))\n",
    "        dev_len.append(lens[idx])\n",
    "\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    test_len = []\n",
    "\n",
    "    for idx in range(train_num + dev_num, train_num + dev_num + test_num):\n",
    "        test_x.append(x[idx])\n",
    "        test_y.append(int(y[idx][-1]))\n",
    "        test_len.append(lens[idx])\n",
    "    return train_x, train_y, train_len, dev_x, dev_y, dev_len, test_x, test_y, test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"load target data\")\n",
    "if target_dataset == 'PD':\n",
    "    data_path = './data/PD/'\n",
    "    all_x_target = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    all_time_target = pickle.load(open(data_path + 'y_z.pkl', 'rb'))\n",
    "    all_x_len_target = [len(i) for i in all_x_target]\n",
    "\n",
    "    subset_idx_target = [0, 2, 3, 4, 5, 7, 8, 9, 12, 16, 17, 19, 20, 56, 57, 58]\n",
    "    other_idx_target = list(range(69))\n",
    "    for i in subset_idx_target:\n",
    "        other_idx_target.remove(i)\n",
    "    for i in range(len(all_x_target)):\n",
    "        cur = np.array(all_x_target[i], dtype=float)\n",
    "        cur_subset = cur[:, subset_idx_target]\n",
    "        cur_other = cur[:, other_idx_target]\n",
    "        all_x_target[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "elif target_dataset == 'TJ':\n",
    "    data_path = './data/Tongji/'\n",
    "    all_x_target = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    all_y_target = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_time_target = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_x_len_target = [len(i) for i in all_x_target]\n",
    "\n",
    "    for i in range(len(all_time_target)):\n",
    "        for j in range(len(all_time_target[i])):\n",
    "            all_time_target[i][j] = all_time_target[i][j][-1]\n",
    "            all_y_target[i][j] = all_y_target[i][j][0]\n",
    "\n",
    "    subset_idx_target = [2, 3, 4, 9, 13, 14, 26, 27, 30, 32, 34, 38, 39, 41, 52, 53, 66, 74]\n",
    "    other_idx_target = list(range(75))\n",
    "    for i in subset_idx_target:\n",
    "        other_idx_target.remove(i)\n",
    "    for i in range(len(all_x_target)):\n",
    "        cur = np.array(all_x_target[i], dtype=float)\n",
    "        cur_subset = cur[:, subset_idx_target]\n",
    "        cur_other = cur[:, other_idx_target]\n",
    "        all_x_target[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "elif target_dataset == 'HM':\n",
    "    data_path = './data/CDSL/'\n",
    "    all_x_target = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    all_y_target = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_time_target = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_x_len_target = [len(i) for i in all_x_target]\n",
    "\n",
    "    for i in range(len(all_time_target)):\n",
    "        for j in range(len(all_time_target[i])):\n",
    "            all_time_target[i][j] = all_time_target[i][j][-1]\n",
    "            all_y_target[i][j] = all_y_target[i][j][0]\n",
    "\n",
    "    subset_idx_target = [5, 6, 4, 2, 3, 48, 79, 76, 87, 25, 30, 31, 18, 43, 58, 66, 40, 57, 23, 92, 50, 54, 91, 60, 39, 81]\n",
    "    other_idx_target= list(range(99))\n",
    "    for i in subset_idx_target:\n",
    "        other_idx_target.remove(i)\n",
    "    for i in range(len(all_x_target)):\n",
    "        cur = np.array(all_x_target[i], dtype=float)\n",
    "        cur_subset = cur[:, subset_idx_target]\n",
    "        cur_other = cur[:, other_idx_target]\n",
    "    #     tar_all_x[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "        all_x_target[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "    \n",
    "if target_dataset == 'PD':\n",
    "    all_x_target = all_x_target\n",
    "    all_y_target = all_time_target\n",
    "elif  target_dataset == 'HM' or target_dataset == 'TJ':\n",
    "    examples = []\n",
    "    for idx in range(len(all_x_target)):\n",
    "        examples.append((all_x_target[idx], all_y_target[idx], all_time_target[idx], all_x_len_target[idx]))\n",
    "    examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    all_x_target = [e[0] for e in examples]\n",
    "    all_y_target = [e[1] for e in examples]\n",
    "    all_time_target = [e[2] for e in examples]\n",
    "    all_x_len_target = [e[3] for e in examples]\n",
    "\n",
    "num_source = len(all_x_source)\n",
    "num_target = len(all_x_target)\n",
    "# print(target_dataset,len(all_x_target), len(all_x_target[0]),len(all_x_target[0][0]))\n",
    "all_x_target_confuse = []\n",
    "all_x_len_target_confuse = []\n",
    "all_y_target_confuse = []\n",
    "all_x_source_confuse = []\n",
    "all_x_len_source_confuse = []\n",
    "all_y_source_confuse = []\n",
    "repeat_times = 0\n",
    "\n",
    "if num_source < num_target:\n",
    "    all_x_target_confuse = all_x_target\n",
    "    all_y_target_confuse = all_y_target\n",
    "    all_x_len_target_confuse = all_x_len_target\n",
    "    while repeat_times * num_source < num_target:\n",
    "        all_x_source_confuse = all_x_source_confuse + all_x_source\n",
    "        all_x_len_source_confuse = all_x_len_source_confuse + all_x_len_source\n",
    "        all_y_source_confuse =  all_y_source_confuse + all_y_source\n",
    "        repeat_times = repeat_times + 1\n",
    "    all_x_source_confuse = all_x_source_confuse[:num_target]\n",
    "    all_x_len_source_confuse = all_x_len_source_confuse[:num_target]\n",
    "    all_y_source_confuse = all_y_source_confuse[:num_target]\n",
    "elif num_target < num_source:\n",
    "    all_x_source_confuse = all_x_source\n",
    "    all_x_len_source_confuse = all_x_len_source\n",
    "    all_y_source_confuse = all_y_source\n",
    "    while repeat_times * num_target < num_source:\n",
    "        all_x_target_confuse = all_x_target_confuse + all_x_target\n",
    "        all_x_len_target_confuse = all_x_len_target_confuse + all_x_len_target\n",
    "        all_y_target_confuse = all_y_target_confuse + all_y_target\n",
    "        repeat_times = repeat_times + 1\n",
    "    all_x_target_confuse = all_x_target_confuse[:num_source]\n",
    "    all_x_len_target_confuse = all_x_len_target_confuse[:num_source]\n",
    "    all_y_target_confuse = all_y_target_confuse[:num_source]\n",
    "\n",
    "# print(f\"len(all_x_source_confuse) is {len(all_x_source_confuse)}, len(all_x_target_confuse) is {len(all_x_target_confuse)}\")\n",
    "\n",
    "#todo 划分train、dev、test \n",
    "# all_x_source_confuse = pad_sents(all_x_source_confuse, pad_token_source)\n",
    "# all_x_target_confuse = pad_sents(all_x_target_confuse, pad_token_target)\n",
    "train_x_source_confuse, train_y_source_confuse, train_len_source_confuse, dev_x_source_confuse, dev_y_source_confuse, dev_len_source_confuse, test_x_source_confuse,\\\n",
    "test_y_source_confuse, test_len_source_confuse = getSplitData(all_x_source_confuse, all_x_len_source_confuse, all_y_source_confuse)\n",
    "\n",
    "train_x_target_confuse, train_y_target_confuse, train_len_target_confuse, dev_x_target_confuse, dev_y_target_confuse, dev_len_target_confuse, test_x_target_confuse,\\\n",
    "test_y_target_confuse, test_len_target_confuse = getSplitData(all_x_target_confuse, all_x_len_target_confuse, all_y_target_confuse)\n",
    "\n",
    "# long_x_source = all_x_source\n",
    "# long_y_source = [y[-1] for y in all_y_source]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_source = np.zeros(34)\n",
    "if target_dataset == 'PD':\n",
    "    pad_token_target = np.zeros(69)\n",
    "elif target_dataset == 'TJ':\n",
    "    pad_token_target = np.zeros(75)\n",
    "elif target_dataset == 'HM':\n",
    "    pad_token_target = np.zeros(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "common_dim = subset_cnt \n",
    "hidden_dim = 64\n",
    "d_model = 64\n",
    "MHD_num_head = 4\n",
    "d_ff = 64\n",
    "output_dim = 1\n",
    "model_student = codats(common_dim = common_dim, hidden_dim = hidden_dim, d_model=d_model, MHD_num_head=MHD_num_head, d_ff=d_ff, output_dim = output_dim).to(device)\n",
    "optimizer_student = torch.optim.Adam(model_student.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskLoss(nn.Module):\n",
    "    def __init__(self, task_num=2):\n",
    "        super(MultitaskLoss, self).__init__()\n",
    "        self.task_num = task_num\n",
    "        self.alpha = nn.Parameter(torch.ones((task_num)), requires_grad=True)\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.kl = nn.KLDivLoss(reduce=True, size_average=True)\n",
    "\n",
    "    def forward(self, opt_student, batch_y, emb_student, emb_teacher, tar_source, tar_tar):\n",
    "        BCE_Loss = self.bce(opt_student, batch_y)\n",
    "        emb_Loss = self.kl(emb_student, emb_teacher)\n",
    "        return BCE_Loss * self.alpha[0] + emb_Loss * self.alpha[1]\n",
    "\n",
    "def get_multitask_loss(opt_student, batch_y, emb_student, emb_teacher):\n",
    "    mtl = MultitaskLoss(task_num=3)\n",
    "    return mtl(opt_student, batch_y, emb_student, emb_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_dataset == 'PD':\n",
    "    data_str = 'pd'\n",
    "elif target_dataset == 'TJ':\n",
    "    data_str = 'covid'\n",
    "elif target_dataset == 'HM':\n",
    "    data_str = 'spain'\n",
    "\n",
    "\n",
    "# if teacher_flag:\n",
    "#     file_name = './model/pretrained-challenge-front-fill-2'+ data_str\n",
    "# else: \n",
    "#     file_name = './model/pretrained-challenge-front-fill-2'+ data_str + '-noteacher'\n",
    "\n",
    "file_name = './model/pretrained-codats'+ data_str;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training dann model\n",
    "# # If you don't want to train Student Model:\n",
    "# # - The pretrained student model is in direcrtory './model/', and can be directly loaded, \n",
    "# # - Simply skip this cell and load the model to validate on Dev Dataset.\n",
    "\n",
    "# logger.info('Training Student')\n",
    "# teacher_flag = False\n",
    "# epochs = 30\n",
    "# total_train_loss = []\n",
    "# total_valid_loss = []\n",
    "# global_best = 0\n",
    "# auroc = []\n",
    "# auprc = []\n",
    "# minpse = []\n",
    "# history = []\n",
    "# # begin_time = time.time()\n",
    "# best_auroc = 0\n",
    "# best_auprc = 0\n",
    "# best_minpse = 0\n",
    "# best_total_loss = 0x3f3f3f3f\n",
    "# loss_domain = torch.nn.NLLLoss()\n",
    "# loss_predict = torch.nn.MSELoss()\n",
    "# loss_embed = nn.KLDivLoss(reduce=True, size_average=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(f'len(train_source_iter) is {len(train_x_source_confuse)}, len(train_target_iter) is {len(train_x_target_confuse)}, steps is {len(train_x_source_confuse) // batch_size + 1}')\n",
    "\n",
    "\n",
    "\n",
    "# for each_epoch in range(epochs):\n",
    "#     train_source_iter = batch_iter(train_x_source_confuse, train_y_source_confuse, train_len_source_confuse, batch_size=batch_size)\n",
    "#     dev_source_iter = batch_iter(dev_x_source_confuse, dev_y_source_confuse, dev_len_source_confuse, batch_size=batch_size)\n",
    "#     test_source_iter = batch_iter(test_x_source_confuse, test_y_source_confuse, test_len_source_confuse, batch_size=batch_size)\n",
    "#     train_target_iter = batch_iter(train_x_target_confuse, train_y_target_confuse, train_len_target_confuse, batch_size=batch_size)\n",
    "#     dev_target_iter = batch_iter(dev_x_target_confuse, dev_y_target_confuse, dev_len_target_confuse, batch_size=batch_size)\n",
    "#     test_target_iter = batch_iter(test_x_target_confuse, test_y_target_confuse, test_len_target_confuse, batch_size=batch_size)\n",
    "#     epoch_loss = []\n",
    "#     counter_batch = 0\n",
    "#     model_student.train()  \n",
    "#     steps = len(train_x_source_confuse) // batch_size + 1 if len(train_x_source_confuse) % batch_size != 0 else len(train_x_source_confuse) // batch_size\n",
    "#     for step in range(steps):\n",
    "#         # -----source_domain--------\n",
    "#         batch_x, batch_y, batch_lens= next(train_source_iter)\n",
    "#         p = float(step + each_epoch * steps) / epochs / steps\n",
    "#         alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "#         optimizer_student.zero_grad()\n",
    "#         batch_x = torch.tensor(pad_sents(batch_x, pad_token_source), dtype=torch.float32).to(device)\n",
    "#         batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "#         batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "#         # batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "#         # opt_student, decov_loss_student, emb_student, tar_result = model_student(batch_x[:,:,:subset_cnt], batch_x[:,:,subset_cnt:], batch_lens, [tar_all_x, tar_all_x_len], True)\n",
    "#         domain_label = torch.zeros(min(batch_size, batch_x.shape[0])).long().to(device)\n",
    "#         opt_student, opt_domain, emb_student = model_student(batch_x[:,:,:subset_cnt], batch_lens, alpha, True)\n",
    "#         emb_student = F.log_softmax(emb_student, dim=1)\n",
    "#         err_predict = loss_predict(opt_student, batch_y)\n",
    "#         err_domain1 = loss_domain(opt_domain, domain_label)\n",
    "#             # loss = get_multitask_loss(opt_student, batch_y.unsqueeze(-1), emb_student, emb_teacher)\n",
    "\n",
    "#         # -----target_domain--------\n",
    "#         batch_x, batch_y, batch_lens = next(train_target_iter)\n",
    "#         p = float(step + each_epoch * len(train_x_source)) / epochs / len(train_x_len_source)\n",
    "#         alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "#         optimizer_student.zero_grad()\n",
    "#         batch_x = torch.tensor(pad_sents(batch_x, pad_token_target), dtype=torch.float32).to(device)\n",
    "#         batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "#         batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "#         # batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "#         # opt_student, decov_loss_student, emb_student, tar_result = model_student(batch_x[:,:,:subset_cnt], batch_x[:,:,subset_cnt:], batch_lens, [tar_all_x, tar_all_x_len], True)\n",
    "#         domain_label = torch.ones(min(batch_size, batch_x.shape[0])).long().to(device)\n",
    "#         opt_domain = model_student(batch_x[:,:,:subset_cnt], batch_lens, alpha, False)\n",
    "#         err_domain2 = loss_domain(opt_domain, domain_label)\n",
    "\n",
    "#         # -----common--------\n",
    "#         loss = err_predict + err_domain1 + err_domain2\n",
    "#         epoch_loss.append(loss.cpu().detach().numpy())\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model_student.parameters(), 20)\n",
    "#         optimizer_student.step()\n",
    "\n",
    "#         if step % 20 == 0:\n",
    "#             print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, loss.cpu().detach().numpy()))\n",
    "#             logger.info('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, loss.cpu().detach().numpy()))\n",
    "\n",
    "#     epoch_loss = np.mean(epoch_loss)\n",
    "#     total_train_loss.append(epoch_loss)\n",
    "\n",
    "\n",
    "#     # dev_source_dataset = MyDataset(dev_x_source_confuse, dev_len_source_confuse, dev_y_source_confuse)\n",
    "#     # dev_target_dataset = MyDataset(dev_x_target_confuse, dev_len_target_confuse, dev_y_target_confuse)\n",
    "#     # dev_source_dataloader = DataLoader(dev_source_dataset, batch_size= batch_size)\n",
    "#     # dev_target_dataloader = DataLoader(dev_target_dataset, batch_size=batch_size)\n",
    "#     #Validation\n",
    "\n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "#     with torch.no_grad():\n",
    "#         steps = len(dev_x_source_confuse) // batch_size + 1 if len(dev_x_source_confuse) % batch_size != 0 else len(dev_x_source_confuse) // batch_size\n",
    "#         for step in range(steps):\n",
    "#             # -----source_domain--------\n",
    "#             batch_x, batch_y, batch_lens= next(dev_source_iter)\n",
    "#             p = float(step + each_epoch * steps) / epochs / steps\n",
    "#             alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "#             optimizer_student.zero_grad()\n",
    "#             batch_x = torch.tensor(pad_sents(batch_x, pad_token_source), dtype=torch.float32).to(device)\n",
    "#             batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "#             batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "#             # batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "#             # opt_student, decov_loss_student, emb_student, tar_result = model_student(batch_x[:,:,:subset_cnt], batch_x[:,:,subset_cnt:], batch_lens, [tar_all_x, tar_all_x_len], True)\n",
    "#             domain_label = torch.zeros(min(batch_size, batch_x.shape[0])).long().to(device)\n",
    "#             opt_student, opt_domain, emb_student = model_student(batch_x[:,:,:subset_cnt], batch_lens, alpha, True)\n",
    "#             # emb_teacher = torch.tensor(dev_teacher_emb[step], dtype=torch.float32).to(device)\n",
    "#             emb_student = F.log_softmax(emb_student, dim=1)\n",
    "#             # err_emb = loss_embed(emb_student, emb_teacher) #todo 是否考虑它\n",
    "#             err_predict = loss_predict(opt_student, batch_y)\n",
    "#             err_domain1 = loss_domain(opt_domain, domain_label)\n",
    "#                 # loss = get_multitask_loss(opt_student, batch_y.unsqueeze(-1), emb_student, emb_teacher)\n",
    "\n",
    "#             # -----target_domain--------\n",
    "#             batch_x, batch_y, batch_lens = next(dev_target_iter)\n",
    "#             optimizer_student.zero_grad()\n",
    "#             batch_x = torch.tensor(pad_sents(batch_x, pad_token_target), dtype=torch.float32).to(device)\n",
    "#             batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "#             batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "#             # batch_mask_x = torch.tensor(pad_sents(batch_mask_x, pad_token), dtype=torch.float32).to(device)\n",
    "#             # opt_student, decov_loss_student, emb_student, tar_result = model_student(batch_x[:,:,:subset_cnt], batch_x[:,:,subset_cnt:], batch_lens, [tar_all_x, tar_all_x_len], True)\n",
    "#             domain_label = torch.ones(min(batch_size, batch_x.shape[0])).long().to(device)\n",
    "#             opt_domain = model_student(batch_x[:,:,:subset_cnt], batch_lens, alpha, False)\n",
    "#             err_domain2 = loss_domain(opt_domain, domain_label)\n",
    "\n",
    "#             # -----common--------\n",
    "#             loss = err_domain1 + err_domain2\n",
    "#             if loss < best_total_loss:\n",
    "#                 best_total_loss = loss\n",
    "#                 state = {\n",
    "#                     'net': model_student.state_dict(),\n",
    "#                     'optimizer': optimizer_student.state_dict(),\n",
    "#                     'epoch': each_epoch\n",
    "#                 }\n",
    "#                 torch.save(state, file_name)\n",
    "#                 print('------------ Save best model - TOTAL_LOSS: %.4f ------------'%best_total_loss)\n",
    "#                 logger.info('------------ Save best model - TOTAL_LOSS: %.4f ------------'%best_total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last saved model is in epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "codats(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(8,), stride=(1,), padding=(4,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (demo_proj_main): Linear(in_features=12, out_features=64, bias=True)\n",
       "  (demo_proj): Linear(in_features=12, out_features=64, bias=True)\n",
       "  (Linear): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (output): Linear(in_features=18, out_features=1, bias=True)\n",
       "  (domain_classifier): Sequential(\n",
       "    (d_fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (d_bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (d_relu1): ReLU(inplace=True)\n",
       "    (d_fc2): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (d_softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (FC_embed): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (softmax): Softmax(dim=None)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       "  (to_MMD): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(file_name, \\\n",
    "                        map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu') )\n",
    "save_epoch = checkpoint['epoch']\n",
    "print(\"last saved model is in epoch {}\".format(save_epoch))\n",
    "logger.info(\"last saved model is in epoch {}\".format(save_epoch))\n",
    "model_student.load_state_dict(checkpoint['net'])\n",
    "optimizer_student.load_state_dict(checkpoint['optimizer'])\n",
    "model_student.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Test Loss = 1.8087\n",
      "\n",
      "==>Predicting on test\n",
      "Test Loss = 1.7845\n",
      "confusion matrix:\n",
      "[[2176    0]\n",
      " [1857    0]]\n",
      "accuracy = 0.5395486950874329\n",
      "precision class 0 = 0.5395486950874329\n",
      "precision class 1 = nan\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.0\n",
      "AUC of ROC = 0.5041367718331273\n",
      "AUC of PRC = 0.5962568058405929\n",
      "min(+P, Se) = 0.4728056004308024\n",
      "f1_score = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/Distcare-adversal/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
     ]
    }
   ],
   "source": [
    "#anchor\n",
    "batch_loss = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    model_student.eval()\n",
    "    test_target_iter = batch_iter(test_x_target_confuse, test_y_target_confuse, test_len_target_confuse, batch_size=batch_size, shuffle=True)\n",
    "    steps = len(test_x_target_confuse) // batch_size + 1 if len(test_x_target_confuse) % batch_size != 0 else len(test_x_target_confuse) // batch_size\n",
    "    for step in range(steps):\n",
    "        # -----target_domain--------\n",
    "        batch_x, batch_y, batch_lens= next(test_target_iter) \n",
    "        optimizer_student.zero_grad()\n",
    "        batch_x = torch.tensor(pad_sents(batch_x, pad_token_target), dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "        batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "        masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "        opt, _, _  = model_student(batch_x[:,:,:subset_cnt], batch_lens, 1, True)\n",
    "\n",
    "        BCE_Loss = get_loss(opt, batch_y.unsqueeze(-1))\n",
    "#             REC_Loss = F.mse_loss(masks * recon, masks * batch_x, reduction='mean').to(device)\n",
    "\n",
    "        model_loss =  BCE_Loss \n",
    "\n",
    "        loss = model_loss\n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        if step % 20 == 0:\n",
    "            print('Batch %d: Test Loss = %.4f'%(step, loss.cpu().detach().numpy()))\n",
    "            logger.info('Batch %d: Test Loss = %.4f'%(step, loss.cpu().detach().numpy()))\n",
    "        y_pred += list(opt.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "print(\"\\n==>Predicting on test\")\n",
    "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "logger.info(\"\\n==>Predicting on test\")\n",
    "logger.info('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "test_res = metrics.print_metrics_binary(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Target Dataset & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.43249781572948887, 0.7734225027254102, 0.11121635247274919, -1.1510759266125783, -0.5775173789921769, -0.894979488306686, 0.6418248141325145, -1.1001333024577382, -0.09626591113773565, 0.07837976568684282, 0.27346416059268763, -0.29216681084789653, -0.20501606288246071, -0.44880109579951655, -0.6600819004124745, -0.5342137257388455, -0.16268638728171492, 1.013400735854239, 1.0, 1.098202336859675, -0.6863245135763378, -0.4670502544450039, -0.41420989908626493, -0.2941064849292665, 0.2534399947977164, 0.6689953308348103, -0.2780944554864925, 1.6237612679911448, -0.016555502218216205, -0.411288788529273, -0.5683812105284773, -0.9512610100808374, -0.9403624977548863, 0.651423723145103, -0.43323556246024986, 0.6921334800493779, 2.9116903104103184, 0.2360670258723392, -0.2674665445678642, 0.4444334033508993, -0.21164668014859825, -0.16135240337065737, -0.7969887859671778, -0.8495988149987506, -0.705221190542043, -1.0534078933590525, 1.3058941843049534, -0.3135827086480343, -0.3167900638717034, -0.24477434302814813, 0.7655720433538256, -0.33782515371340677, -0.18389192944425495, 0.311524270793097, -0.03429036235566567, 1.6532381373162057, -0.6035840289958837, -0.4798165125287964, 1.3136602297615485, -0.38113328114517314, -0.438838853292927, -0.25994688807198424, 1.8115519460700398, 0.6532487251600559, -0.6813987150690228, -0.6881330975707701, -0.8608674113288034, 0.5282372331730917, -0.3927744234337778, -0.2332558526002517, -0.7532798583884561, -1.2230128823047004, 0.4609091575849162, -0.7849239794277927, -1.4109277280424448], [-0.43249781572948887, 0.7734225027254102, 0.11121635247274919, -1.1510759266125783, -0.5775173789921769, -0.894979488306686, 0.6418248141325145, -1.1001333024577382, -0.09626591113773565, 0.07837976568684282, 0.27346416059268763, -0.29216681084789653, -0.20501606288246071, -0.44880109579951655, -0.6600819004124745, -0.5342137257388455, -0.16268638728171492, 1.013400735854239, 1.0, 1.098202336859675, -0.6863245135763378, -0.4670502544450039, -0.41420989908626493, -0.2941064849292665, 0.2534399947977164, 0.6689953308348103, -0.2780944554864925, 1.6237612679911448, -0.016555502218216205, -0.411288788529273, -0.5683812105284773, -0.9512610100808374, -0.9403624977548863, 0.651423723145103, -0.43323556246024986, 0.6921334800493779, 2.9116903104103184, 0.2360670258723392, -0.2674665445678642, 0.4444334033508993, -0.21164668014859825, -0.16135240337065737, -0.7969887859671778, -0.8495988149987506, -0.705221190542043, -1.0534078933590525, 1.3058941843049534, -0.3135827086480343, -0.3167900638717034, -0.24477434302814813, 0.7655720433538256, -0.33782515371340677, -0.18389192944425495, 0.311524270793097, -0.03429036235566567, 1.6532381373162057, -0.6035840289958837, -0.4798165125287964, 1.3136602297615485, -0.38113328114517314, -0.438838853292927, -0.25994688807198424, 1.8115519460700398, 0.6532487251600559, -0.6813987150690228, -0.6881330975707701, -0.8608674113288034, 0.5282372331730917, -0.3927744234337778, -0.2332558526002517, -0.7532798583884561, -1.2230128823047004, 0.4609091575849162, -0.7849239794277927, -1.4109277280424448], [-0.43249781572948887, 1.0626655489546322, -0.2607021557915042, -0.8723303017698648, -0.6987602223992506, 0.42060382604722935, 0.7735163080078745, -0.4422053625222244, -0.09626591113773565, -0.5703381110324975, 0.27346416059268763, 0.4054213944799434, -0.6478420259418122, -0.652648910528702, 1.0582568698308186, 1.3623416964867365, -0.16268638728171492, 0.06953911374846142, 1.0, 1.098202336859675, -0.6863245135763378, -0.4670502544450039, -0.8301874079837086, -0.2941064849292665, 0.23429139098427385, -0.9597305030519863, -0.2780944554864925, 0.44841735124674564, -0.016555502218216205, -0.411288788529273, -0.49230413633903536, -1.2379951878994253, -0.8899655603378251, 0.4144052468488665, -0.43323556246024986, 0.6921334800493779, 2.9116903104103184, 0.07172496731033204, -0.2674665445678642, 1.0100887085497614, -0.21164668014859825, 1.943067011208341, -0.08881508319448383, -0.8495988149987506, 1.7124080848737049, -0.5711764060634537, 0.07961653401158347, -0.3135827086480343, -0.7495061187450142, -0.24477434302814813, 1.0712982894377368, -0.33782515371340677, -0.18389192944425495, 0.1906271826667854, 0.08009979585285867, 0.2295633031960889, -0.6035840289958837, -0.7241072055173139, 0.12678603163309085, -0.38113328114517314, -0.438838853292927, 0.37611362926166203, -0.07561878133196119, 0.3448973731726548, -0.45301547558529076, -0.6881330975707701, -0.8608674113288034, 0.6571388363948929, -0.9767247139266083, -0.2332558526002517, 0.4743340898355563, 0.31603580948316384, 0.4609091575849162, 0.5732318714191863, -0.40170913406717196], [-0.43249781572948887, 0.3395579333815775, -0.8951513757717067, -0.7678006924538472, 0.5406110657619471, -0.13459647175350561, 0.3257652288316494, 0.680026078568982, -0.738540973511107, -0.08843340261241621, 0.27346416059268763, -0.5014432724462485, 2.8390253475185365, -0.170826802986991, 0.7145891157821607, -0.36929586293662087, -0.43897479874595047, 0.28190797872226137, 1.0, 1.098202336859675, -0.5896780760673638, -0.4670502544450039, -0.96884657761619, -0.2941064849292665, 0.08110256047672398, -0.9597305030519863, -0.2780944554864925, -0.32395150832814545, -0.016555502218216205, -0.411288788529273, 2.0182393119125503, -0.9512610100808374, 0.3915565625531523, -0.5505985495001029, -0.43323556246024986, 0.572828751735985, 2.9116903104103184, 0.44736395830920606, -0.2674665445678642, -0.026946017648152392, -0.21164668014859825, 0.9439992083274025, -0.21802572370037915, -0.8495988149987506, -0.302282977972751, 0.721203979888751, -0.4108945261057649, -0.3135827086480343, -0.38890940635058796, 1.1668382976193643, -0.35542419228718275, -0.33782515371340677, -0.5335587241304727, -0.024300974002213524, -1.0066067071281226, 1.247958440011939, -0.6035840289958837, -0.942223895685633, -0.29927137282327887, -0.38113328114517314, -0.438838853292927, 1.0121741465953082, -0.43265108111071765, -0.8173500304721677, -0.583520183861709, -0.5895349223964507, -0.8608674113288034, 0.39933562995129274, -0.9767247139266083, -0.2332558526002517, -0.35194452916137237, -0.3835317776931382, 0.4609091575849162, -0.10584605400430319, -0.7071814287953199], [-0.43249781572948887, 0.2672471718242721, -0.9826616130103564, -0.6284278800324904, -0.40238882740418175, -0.43633576403651375, 0.03604394230585671, -0.017417052954250063, -0.738540973511107, -0.21817697795628416, 0.27346416059268763, 0.19614493288159143, -0.48681440301113876, -0.5229275738828567, 2.4016853629301207, 1.3623416964867365, -0.43897479874595047, 0.022346032643172534, 1.0, 1.098202336859675, -0.5896780760673638, -0.4670502544450039, 0.2790859490761416, -0.2941064849292665, 0.751303693947251, 0.6689953308348103, -0.2780944554864925, 1.0528799370010082, -0.016555502218216205, -0.411288788529273, 0.07827392008177957, -0.9512610100808374, -1.2931410596743127, 0.295896008700747, -0.43323556246024986, 0.572828751735985, 2.9116903104103184, 0.5647511429963535, -0.2674665445678642, 0.7272610559503303, -0.21164668014859825, 3.6648647140457036, -0.287600683972784, 0.972012082109433, 1.1080007660197713, -0.3718540579812729, 0.815383124187605, -0.3135827086480343, -0.3408298446979971, 1.1668382976193643, 1.3307023770240858, -0.33782515371340677, -0.5335587241304727, 1.2787009758035917, -0.7206313116068118, 1.3414845240052313, -0.6035840289958837, -0.9509485632923658, 0.9028191611786214, -0.38113328114517314, -0.438838853292927, 2.0192699657069153, 1.0974873465125259, -0.4615600089482426, -0.09412752782514046, -0.5895349223964507, 1.2819970892257146, 0.9793928444493915, -0.9915082655846547, -0.2332558526002517, -0.21029676590475738, -0.6633588125636588, 0.4609091575849162, -0.10584605400430319, -0.3243743759081472], [-0.43249781572948887, 0.411868694938883, -0.566987986126775, -0.2799958489790985, -0.8469459198967851, -0.46047490741915437, 0.3257652288316494, 0.10508004096767726, -0.8205335346651542, -0.292316163867066, 0.27346416059268763, 1.1378890100741745, -0.3908171662640067, -0.7082437690912071, 1.4644096700701428, 1.3623416964867365, -0.2662945415808034, 0.022346032643172534, 1.0, 1.098202336859675, -1.4111727948936457, -0.4670502544450039, 1.111040966871029, -0.2941064849292665, 1.0768299587757935, -0.14536758610858785, -0.2780944554864925, 0.6834861345956256, -0.016555502218216205, -0.411288788529273, -0.7966124330968032, -0.9512610100808374, -1.0483559350771596, 0.380545464520832, -0.43323556246024986, 2.1237902198100924, 2.9116903104103184, 0.7056157646209292, -0.2674665445678642, 0.25588163495127864, -0.21164668014859825, 3.452297096411461, -0.24287392379766656, 2.3382202549405706, 0.8057971065927999, -0.21753998204668118, 0.5701275941289319, -0.35234396942435836, -0.1485115980876371, -0.4706323655317493, 1.0712982894377368, -0.33782515371340677, -0.47452407048215023, 1.5742271912234647, -0.6062411533982874, 1.2167830786808416, -0.6035840289958837, -0.9160498928654347, 0.8571701535582954, -0.38113328114517314, -0.438838853292927, 1.754244750151229, 0.7914596609878773, -0.7461920261673826, -0.12675370489424503, -1.3783203237910062, 0.21056483894845573, 0.7860404396166896, -0.9915082655846547, -0.2332558526002517, 0.4271181687500135, -0.6633588125636588, 0.4609091575849162, -0.05360929051018861, -0.3243743759081472], [-0.43249781572948887, 0.411868694938883, -0.566987986126775, -0.2799958489790985, -0.8469459198967851, -0.46047490741915437, 0.3257652288316494, 0.10508004096767726, -0.8205335346651542, -0.292316163867066, 0.27346416059268763, 1.1378890100741745, -0.3908171662640067, -0.7082437690912071, 1.4644096700701428, 1.3623416964867365, -0.2662945415808034, 0.022346032643172534, 1.0, 1.098202336859675, -1.4111727948936457, -0.4670502544450039, 1.111040966871029, -0.2941064849292665, 1.0768299587757935, -0.14536758610858785, -0.2780944554864925, 0.6834861345956256, -0.016555502218216205, -0.411288788529273, -0.7966124330968032, -0.9512610100808374, -1.0483559350771596, 0.380545464520832, -0.43323556246024986, 2.1237902198100924, 2.9116903104103184, 0.7056157646209292, -0.2674665445678642, 0.25588163495127864, -0.21164668014859825, 3.452297096411461, -0.24287392379766656, 2.3382202549405706, 0.8057971065927999, -0.21753998204668118, 0.5701275941289319, -0.35234396942435836, -0.1485115980876371, -0.4706323655317493, 1.0712982894377368, -0.33782515371340677, -0.47452407048215023, 1.5742271912234647, -0.6062411533982874, 1.2167830786808416, -0.6035840289958837, -0.9160498928654347, 0.8571701535582954, -0.38113328114517314, -0.438838853292927, 1.754244750151229, 0.7914596609878773, -0.7461920261673826, -0.12675370489424503, -1.3783203237910062, 0.21056483894845573, 0.7860404396166896, -0.9915082655846547, -0.2332558526002517, 0.4271181687500135, -0.6633588125636588, 0.4609091575849162, -0.05360929051018861, -0.3243743759081472]]\n",
      "75\n",
      "361\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Transfer Target Dataset & Model\")\n",
    "if target_dataset == 'TJ':\n",
    "    data_path = './data/Tongji/'\n",
    "    all_x = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    all_y = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_time = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "    for i in range(len(all_time)):\n",
    "        for j in range(len(all_time[i])):\n",
    "            all_time[i][j] = all_time[i][j][-1]\n",
    "            all_y[i][j] = all_y[i][j][0]\n",
    "\n",
    "    tar_subset_idx = [2, 3, 4, 9, 13, 14, 26, 27, 30, 32, 34, 38, 39, 41, 52, 53, 66, 74]\n",
    "    tar_other_idx = list(range(75))\n",
    "    for i in tar_subset_idx:\n",
    "        tar_other_idx.remove(i)\n",
    "    for i in range(len(all_x)):\n",
    "        cur = np.array(all_x[i], dtype=float)\n",
    "        cur_subset = cur[:, tar_subset_idx]\n",
    "        cur_other = cur[:, tar_other_idx]\n",
    "        all_x[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "elif target_dataset == 'HM':\n",
    "    data_path = './data/CDSL/'\n",
    "    all_x = pickle.load(open(data_path + 'x.pkl', 'rb'))\n",
    "    all_y = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_time = pickle.load(open(data_path + 'y.pkl', 'rb'))\n",
    "    all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "    for i in range(len(all_time)):\n",
    "        for j in range(len(all_time[i])):\n",
    "            all_time[i][j] = all_time[i][j][-1]\n",
    "            all_y[i][j] = all_y[i][j][0]\n",
    "\n",
    "    tar_subset_idx = [5, 6, 4, 2, 3, 48, 79, 76, 87, 25, 30, 31, 18, 43, 58, 66, 40, 57, 23, 92, 50, 54, 91, 60, 39, 81]\n",
    "    tar_other_idx = list(range(99))\n",
    "    for i in tar_subset_idx:\n",
    "        tar_other_idx.remove(i)\n",
    "    for i in range(len(all_x)):\n",
    "        cur = np.array(all_x[i], dtype=float)\n",
    "        cur_subset = cur[:, tar_subset_idx]\n",
    "        cur_other = cur[:, tar_other_idx]\n",
    "        all_x[i] = np.concatenate((cur_subset, cur_other), axis=1).tolist()\n",
    "    \n",
    "print(all_x[0])\n",
    "print(len(all_x[0][0]))\n",
    "print(len(all_x))\n",
    "logger.info(all_x[0])\n",
    "logger.info(len(all_x[0][0]))\n",
    "logger.info(len(all_x))\n",
    "\n",
    "long_x = all_x\n",
    "long_y = all_y\n",
    "long_y_kfold = [each[-1] for each in all_y]\n",
    "long_time = all_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n2n_data(x, y, x_len, outcome=None):\n",
    "    length = len(x)\n",
    "    assert length == len(y)\n",
    "    assert length == len(outcome)\n",
    "    assert length == len(x_len)\n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    new_outcome = []\n",
    "    new_x_len = []\n",
    "    for i in range(length):\n",
    "        for j in range(len(x[i])):\n",
    "            new_x.append(x[i][:j+1])\n",
    "            new_y.append(y[i][j])\n",
    "            new_outcome.append(outcome[i][j])\n",
    "            new_x_len.append(j+1)\n",
    "    return new_x, new_y, new_x_len, new_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class target_model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(target_model, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        \n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.Linear = nn.Linear(self.hidden_dim, 1)\n",
    "        self.output = nn.Linear(self.input_dim, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.FC_embed = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv1d(1, hidden_dim, kernel_size=8, padding=4, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(hidden_dim, 2*hidden_dim, kernel_size=5, padding=2, bias=False),\n",
    "            nn.BatchNorm1d(2*hidden_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv1d(2*hidden_dim, hidden_dim, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "        )\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, self.output_dim)\n",
    "        )\n",
    "        self.MLP_outcome = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, self.output_dim)\n",
    "        )\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, lens):\n",
    "        lens = lens.to('cpu')\n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "        # print(f'input.shape is {input.shape},input[:,:,0].squeeze(-1).unsqueeze(1).shape is {input[:,:,0].squeeze(-1).unsqueeze(1).shape}')\n",
    "        codats_embeded_input = self.layers(input[:,:,0].squeeze(-1).unsqueeze(1)).unsqueeze(1)\n",
    "        # print(f'input[:,:,i].shape is {input[:,:,0].shape}')\n",
    "        for i in range(1, feature_dim):\n",
    "            embeded_input = self.layers(input[:,:,i].squeeze(-1).unsqueeze(1)).unsqueeze(1)\n",
    "            codats_embeded_input = torch.cat((codats_embeded_input, embeded_input), 1)\n",
    "            # print(f'docats_embeded_input.shape is {codats_embeded_input.shape}')\n",
    "        codats_embeded_input = codats_embeded_input.squeeze(-1)\n",
    "\n",
    "        codats_input = codats_embeded_input[:, 0, :]\n",
    "        for i in range(1, feature_dim):\n",
    "             codats_input =  codats_input + codats_embeded_input[:, i, :]  \n",
    "        # print(f\"common_input1.shape is {gru_input.shape}\")\n",
    "        codats_input = torch.squeeze(codats_input, 1) # batch * hidden\n",
    "        # print(f\"common_input2.shape is {gru_input.shape}\")\n",
    "\n",
    "        posi_input = self.dropout(codats_input) # batch_size * d_input + d_input_diff * hidden_dim\n",
    "        output = self.MLP(posi_input)\n",
    "        outcome = self.MLP_outcome(posi_input)\n",
    "        outcome = self.sigmoid(outcome)\n",
    "        if self.output_dim != 1:\n",
    "            output = self.softmax(output, dim=1)\n",
    "        return output, outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_gru_dict(pretrain_dict, model_dict):\n",
    "    state_dict = {}\n",
    "    \n",
    "    for k, v in pretrain_dict.items():\n",
    "        model_point_position1 = k.find('.')\n",
    "        model_module_name = k[:model_point_position1]\n",
    "        if \"layers\" == model_module_name:\n",
    "            model_point_position2 = k.find('.', model_point_position1+1)\n",
    "            model_module_idx = int(k[model_point_position1 + 1: model_point_position2])\n",
    "            print(f'model_module_idx is {model_module_idx}')\n",
    "            state_dict[k] = pretrain_dict[k]\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_dataset == 'PD':\n",
    "    input_dim = 69\n",
    "elif target_dataset == 'TJ':\n",
    "    input_dim = 75\n",
    "elif target_dataset == 'HM':\n",
    "    input_dim = 99\n",
    "    \n",
    "cell = 'GRU'\n",
    "hidden_dim = 64\n",
    "d_model = 64\n",
    "MHD_num_head = 4\n",
    "d_ff = 64\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckd_batch_iter(x, y, lens, batch_size, shuffle=False, outcome=None):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        \n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx],  lens[idx], outcome[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "#         batch_name = [e[2] for e in examples]\n",
    "        batch_lens = [e[2] for e in examples]\n",
    "        batch_outcome = [e[3] for e in examples]\n",
    "       \n",
    "\n",
    "        yield batch_x, batch_y, batch_lens, batch_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetMultitaskLoss(nn.Module):\n",
    "    def __init__(self, task_num=2):\n",
    "        super(TargetMultitaskLoss, self).__init__()\n",
    "        self.task_num = task_num\n",
    "        self.alpha = nn.Parameter(torch.ones((task_num)), requires_grad=True)\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, opt_student, los, outcome, outcome_y):\n",
    "        MSE_Loss = self.mse(opt_student, los)\n",
    "        BCE_Loss = self.bce(outcome, outcome_y)\n",
    "        return MSE_Loss * self.alpha[0] + BCE_Loss * self.alpha[1]\n",
    "\n",
    "def get_target_multitask_loss(opt_student, los, outcome, outcome_y):\n",
    "    mtl = TargetMultitaskLoss(task_num=2)\n",
    "    return mtl(opt_student, los, outcome, outcome_y)\n",
    "\n",
    "def reverse_los(y, los_info):\n",
    "    return y * los_info[\"los_std\"] + los_info[\"los_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'los_mean': 6.927731092436975, 'los_std': 5.1253246527009555, 'los_median': 6.0, 'large_los': 26.649999999999977, 'threshold': 4.9562737642585555}\n"
     ]
    }
   ],
   "source": [
    "los_info = pickle.load(open(data_path + 'los_info.pkl', 'rb'))\n",
    "print(los_info)\n",
    "logger.info(los_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 137.2076 ------------\n",
      "Custom bins confusion matrix:\n",
      "[[52 55]\n",
      " [45 13]]\n",
      "Mean absolute deviation (MAD) = 9.520332539871733\n",
      "Mean squared error (MSE) = 137.20756603271136\n",
      "Mean absolute percentage error (MAPE) = 706.3541153119156\n",
      "Cohen kappa score = -0.2788714927918152\n",
      "------------ Save best model - MSE: 137.2076 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/Distcare-adversal/utils/metrics.py:22: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec0 = cf[0][0] / (cf[0][0] + cf[1][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 89.2060 ------------\n",
      "Custom bins confusion matrix:\n",
      "[[16 90  1]\n",
      " [ 3 54  1]\n",
      " [ 0  0  0]]\n",
      "Mean absolute deviation (MAD) = 7.256493629117908\n",
      "Mean squared error (MSE) = 89.20596887143097\n",
      "Mean absolute percentage error (MAPE) = 544.0004731569913\n",
      "Cohen kappa score = 0.07118564559634089\n",
      "------------ Save best model - MSE: 89.2060 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/Distcare-adversal/utils/metrics.py:22: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec0 = cf[0][0] / (cf[0][0] + cf[1][0])\n",
      "/home/zzj/Distcare-adversal/utils/metrics.py:22: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec0 = cf[0][0] / (cf[0][0] + cf[1][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 88.2465 ------------\n",
      "Custom bins confusion matrix:\n",
      "[[19 88]\n",
      " [ 8 50]]\n",
      "Mean absolute deviation (MAD) = 8.153297983348967\n",
      "Mean squared error (MSE) = 88.24654711691046\n",
      "Mean absolute percentage error (MAPE) = 597.5912337675339\n",
      "Cohen kappa score = 0.030124908155767738\n",
      "------------ Save best model - MSE: 88.2465 ------------\n",
      "------------ Save FOLD-BEST model - MSE: 69.6473 ------------\n",
      "Custom bins confusion matrix:\n",
      "[[90 17]\n",
      " [30 28]]\n",
      "Mean absolute deviation (MAD) = 5.713380024883999\n",
      "Mean squared error (MSE) = 69.647332513821\n",
      "Mean absolute percentage error (MAPE) = 198.56325049784772\n",
      "Cohen kappa score = 0.34140127388535024\n",
      "------------ Save best model - MSE: 69.6473 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/Distcare-adversal/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score=2*prec1*rec1/(prec1+rec1)\n",
      "/home/zzj/Distcare-adversal/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 66.9672 ------------\n",
      "Custom bins confusion matrix:\n",
      "[[69 38]\n",
      " [17 41]]\n",
      "Mean absolute deviation (MAD) = 6.0448760772061645\n",
      "Mean squared error (MSE) = 66.96724066393341\n",
      "Mean absolute percentage error (MAPE) = 353.2528238852647\n",
      "Cohen kappa score = 0.32482702179897327\n",
      "------------ Save best model - MSE: 66.9672 ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzj/Distcare-adversal/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "/home/zzj/Distcare-adversal/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "/home/zzj/Distcare-adversal/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "/home/zzj/Distcare-adversal/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score=2*prec1*rec1/(prec1+rec1)\n",
      "/home/zzj/Distcare-adversal/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n",
      "/home/zzj/Distcare-adversal/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1_score=2*prec1*rec1/(prec1+rec1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Save FOLD-BEST model - MSE: 59.9027 ------------\n",
      "Custom bins confusion matrix:\n",
      "[[88 19]\n",
      " [27 31]]\n",
      "Mean absolute deviation (MAD) = 5.345675573162096\n",
      "Mean squared error (MSE) = 59.90270140560714\n",
      "Mean absolute percentage error (MAPE) = 363.72065945114736\n",
      "Cohen kappa score = 0.3685524126455907\n",
      "------------ Save best model - MSE: 59.9027 ------------\n"
     ]
    }
   ],
   "source": [
    "if target_dataset == 'TJ':\n",
    "    n_splits = 10\n",
    "    epochs = 50\n",
    "elif target_dataset == 'HM':\n",
    "    n_splits = 3\n",
    "    epochs = 20\n",
    "\n",
    "teacher_flag = True\n",
    "transfer_flag = True\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "if target_dataset == 'TJ':    \n",
    "    data_str = 'covid'\n",
    "elif target_dataset == 'HM':\n",
    "    data_str = 'spain'\n",
    "\n",
    "if teacher_flag:\n",
    "    file_name = './model/pretrained-challenge-front-fill-2'+ data_str\n",
    "else: \n",
    "    file_name = './model/pretrained-challenge-front-fill-2'+ data_str + '-noteacher'\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "fold_count = 0\n",
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "\n",
    "global_best = 10000\n",
    "mse = []\n",
    "mad = []\n",
    "mape = []\n",
    "auroc = []\n",
    "auprc = []\n",
    "kappa = []\n",
    "history = []\n",
    "\n",
    "pad_token = np.zeros(input_dim)\n",
    "# begin_time = time.time()\n",
    "\n",
    "for train, test in kfold.split(long_x, long_y_kfold):\n",
    "\n",
    "    if reverse:\n",
    "        temp = train\n",
    "        train = test\n",
    "        test = temp\n",
    "    fold_count += 1\n",
    "    # if fold_count < 9:\n",
    "    #     continue\n",
    "    \n",
    "    model = target_model(input_dim = input_dim,output_dim=output_dim, d_model=d_model, MHD_num_head=MHD_num_head, d_ff=d_ff, hidden_dim=hidden_dim).to(device)\n",
    "    \n",
    "    if transfer_flag:\n",
    "        checkpoint = torch.load(file_name, \\\n",
    "                        map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu'))\n",
    "        pretrain_dict = checkpoint['net']\n",
    "        model_dict = model.state_dict()\n",
    "        pretrain_dict = transfer_gru_dict(pretrain_dict, model_dict)\n",
    "        model_dict.update(pretrain_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "#     print(train)\n",
    "\n",
    "    \n",
    "    train_x = [long_x[i] for i in train]\n",
    "    train_y = [long_time[i] for i in train]\n",
    "    train_outcome = [long_y[i] for i in train]\n",
    "    train_x_len = [all_x_len[i] for i in train]\n",
    "    #train_static = [long_static[i] for i in train]\n",
    "    \n",
    "    train_x, train_y, train_x_len, train_outcome = get_n2n_data(train_x, train_y, train_x_len, outcome=train_outcome)\n",
    "    if len(train_x) % 256 == 1:\n",
    "        print(len(train_x))\n",
    "        print('wrong squeeze!')\n",
    "    \n",
    "    test_x = [long_x[i] for i in test]\n",
    "    test_y = [long_time[i] for i in test]\n",
    "    test_outcome = [long_y[i] for i in test]\n",
    "    test_x_len = [all_x_len[i] for i in test]\n",
    "    #test_static = [long_static[i] for i in test]\n",
    "    \n",
    "    test_x, test_y, test_x_len, test_outcome = get_n2n_data(test_x, test_y, test_x_len, outcome=test_outcome)\n",
    "    \n",
    "    if not os.path.exists('./model/'+data_str):\n",
    "        os.mkdir('./model/'+data_str)\n",
    "        \n",
    "    if transfer_flag:\n",
    "        target_file_name = './model/'+data_str+'/dann-trans-'+str(n_splits)+'-fold-LOS-regression' + str(fold_count)#4114\n",
    "    else:\n",
    "        target_file_name = './model/'+data_str+'/dann-no-trans-'+str(n_splits)+'-fold-LOS-regression' + str(fold_count)#4114\n",
    "    \n",
    "    fold_train_loss = []\n",
    "    fold_valid_loss = []\n",
    "    best_mse = 10000\n",
    "    best_mad = 0\n",
    "    best_auroc = 0\n",
    "    beat_auprc = 0\n",
    "    best_mape = 0\n",
    "    best_kappa = 0\n",
    "    \n",
    "    for each_epoch in range(epochs):\n",
    "       \n",
    "        \n",
    "        epoch_loss = []\n",
    "        counter_batch = 0\n",
    "        model.train()  \n",
    "        \n",
    "        for step, (batch_x, batch_y, batch_lens, batch_outcome) in enumerate(ckd_batch_iter(train_x, train_y, train_x_len, batch_size, shuffle=True, outcome=train_outcome)):  \n",
    "            optimizer.zero_grad()\n",
    "            batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "            batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "            batch_outcome = torch.tensor(batch_outcome, dtype=torch.float32).to(device)\n",
    "\n",
    "            masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "            # print(f'batch_x.shape is {batch_x.shape}')\n",
    "\n",
    "            opt, outcome = model(batch_x, batch_lens)\n",
    "            # print(f'opt.shape is {opt.shape}, outcome.shape is {outcome.shape}')\n",
    "            # print(f'batch_y.shape is {batch_y.shape}, batch_outcome.shape is {batch_outcome.shape}')\n",
    "\n",
    "#             MSE_Loss = get_re_loss(opt, batch_y.unsqueeze(-1))\n",
    "            pred_loss = get_target_multitask_loss(opt, batch_y.unsqueeze(-1), outcome, batch_outcome.unsqueeze(-1))\n",
    "\n",
    "            model_loss = pred_loss\n",
    "\n",
    "            loss = model_loss\n",
    "\n",
    "            epoch_loss.append(pred_loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 50 == 0:\n",
    "                # print('Fold %d Epoch %d Batch %d: Train Loss = %.4f'%(fold_count,each_epoch, step, loss.cpu().detach().numpy()))\n",
    "                logger.info('Fold %d Epoch %d Batch %d: Train Loss = %.4f'%(fold_count,each_epoch, step, loss.cpu().detach().numpy()))\n",
    "            \n",
    "        epoch_loss = np.mean(epoch_loss)\n",
    "        fold_train_loss.append(epoch_loss)\n",
    "\n",
    "        #Validation\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_pred_flatten = []\n",
    "        y_true_flatten = []\n",
    "        outcome_pred_flatten = []\n",
    "        outcome_true_flatten = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            valid_loss = []\n",
    "            valid_true = []\n",
    "            valid_pred = []\n",
    "            for batch_x, batch_y, batch_lens, batch_outcome in ckd_batch_iter(test_x, test_y, test_x_len, batch_size, outcome=test_outcome):\n",
    "                batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "                batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "                batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "                batch_outcome = torch.tensor(batch_outcome, dtype=torch.float32).to(device)\n",
    "                masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "               \n",
    "                opt, outcome = model(batch_x, batch_lens)\n",
    "                \n",
    "#                 MSE_Loss = get_re_loss(opt, batch_y.unsqueeze(-1))\n",
    "                pred_loss = get_target_multitask_loss(opt, batch_y.unsqueeze(-1), outcome, batch_outcome.unsqueeze(-1))\n",
    "                \n",
    "                valid_loss.append(pred_loss.cpu().detach().numpy())\n",
    "\n",
    "                y_pred_flatten += [reverse_los(x, los_info) for x in list(opt.cpu().detach().numpy().flatten())]\n",
    "                y_true_flatten += [reverse_los(x, los_info) for x in list(batch_y.cpu().numpy().flatten())]\n",
    "                outcome_pred_flatten += list(outcome.cpu().detach().numpy().flatten())\n",
    "                outcome_true_flatten += list(batch_outcome.cpu().numpy().flatten())\n",
    "            \n",
    "\n",
    "            valid_loss = np.mean(valid_loss)\n",
    "            fold_valid_loss.append(valid_loss)\n",
    "            ret = metrics.print_metrics_regression(y_true_flatten, y_pred_flatten, verbose=0)\n",
    "            ret_outcome = metrics.print_metrics_binary(outcome_true_flatten, outcome_pred_flatten, verbose=0)\n",
    "            history.append((ret, ret_outcome))\n",
    "            #print()\n",
    "\n",
    "            if each_epoch % 10 == 0:\n",
    "                # print('Fold %d, epoch %d: Loss = %.4f Valid loss = %.4f MSE = %.4f AUROC = %.4f' % (\n",
    "                #     fold_count, each_epoch, fold_train_loss[-1], fold_valid_loss[-1], ret['mse'], ret_outcome['auroc']), flush=True)\n",
    "                logger.info('Fold %d, epoch %d: Loss = %.4f Valid loss = %.4f MSE = %.4f AUROC = %.4f' % (\n",
    "                    fold_count, each_epoch, fold_train_loss[-1], fold_valid_loss[-1], ret['mse'], ret_outcome['auroc']))\n",
    "                # metrics.print_metrics_regression(y_true_flatten, y_pred_flatten)\n",
    "                \n",
    "            cur_mse = ret['mse']\n",
    "            if cur_mse < best_mse:\n",
    "                print('------------ Save FOLD-BEST model - MSE: %.4f ------------' % cur_mse, flush=True)\n",
    "                logger.info('------------ Save FOLD-BEST model - MSE: %.4f ------------' % cur_mse)\n",
    "                metrics.print_metrics_regression(y_true_flatten, y_pred_flatten)\n",
    "                best_mse = cur_mse\n",
    "                best_mad = ret['mad']\n",
    "                best_auroc = ret_outcome['auroc']\n",
    "                best_auprc = ret_outcome['auprc']\n",
    "                state = {\n",
    "                    'net': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': each_epoch\n",
    "                }\n",
    "                torch.save(state, target_file_name + '_' + str(fold_count))\n",
    "\n",
    "                if cur_mse < global_best:\n",
    "                    global_best = cur_mse\n",
    "                    state = {\n",
    "                        'net': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'epoch': each_epoch\n",
    "                    }\n",
    "                    torch.save(state, target_file_name)\n",
    "                    print('------------ Save best model - MSE: %.4f ------------' % cur_mse, flush=True)\n",
    "                    logger.info('------------ Save best model - MSE: %.4f ------------' % cur_mse)\n",
    "\n",
    "        # print('Fold %d, mse = %.4f, mad = %.4f' % (fold_count, ret['mse'], ret['mad']), flush=True)\n",
    "        logger.info('Fold %d, mse = %.4f, mad = %.4f' % (fold_count, ret['mse'], ret['mad']))\n",
    "\n",
    "    mse.append(best_mse)\n",
    "    mad.append(best_mad)\n",
    "    auroc.append(best_auroc)\n",
    "    auprc.append(best_auprc)\n",
    "    total_train_loss.append(fold_train_loss)\n",
    "    total_valid_loss.append(fold_valid_loss)\n",
    "\n",
    "\n",
    "print('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "print('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "print('auroc %.4f(%.4f)' % (np.mean(auroc), np.std(auroc)))\n",
    "print('auprc %.4f(%.4f)' % (np.mean(auprc), np.std(auprc)))\n",
    "logger.info('mse %.4f(%.4f)' % (np.mean(mse), np.std(mse)))\n",
    "logger.info('mad %.4f(%.4f)' % (np.mean(mad), np.std(mad)))\n",
    "logger.info('auroc %.4f(%.4f)' % (np.mean(auroc), np.std(auroc)))\n",
    "logger.info('auprc %.4f(%.4f)' % (np.mean(auprc), np.std(auprc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
